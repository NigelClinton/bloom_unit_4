{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Create Assignment",
    "colab": {
      "name": "Copy of LS_DS_431_RNN_and_LSTM_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsrwhKw4ohgW"
      },
      "source": [
        "# 1. Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) -- Prepare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et2y0gP7IM19"
      },
      "source": [
        "\n",
        "\n",
        "![](https://wiki.tum.de/download/attachments/22578349/GATES.gif?version=1&modificationDate=1486083227237&api=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BOMScPtIM1-"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe How Neural Networks are used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text classification problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IizNKWLomoA"
      },
      "source": [
        "-----\n",
        "## Overview\n",
        "\n",
        "### Let's start with sequences \n",
        "\n",
        "A sequence is a collection of numbers, taking into account their order; repetition is allowed. \n",
        "\n",
        "Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list and is different from `[1, 2, -1, 2]`. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "## 1.1 Recursion (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX_WLYHrIM1_"
      },
      "source": [
        "\n",
        "\n",
        "Before we dive into the inner workings of an LSTM model, let's try to understand and appreciate **recursion** in sequences. <br>A **recursive sequence** is a sequence in which the next number can be computed from one or more of the previous numbers via a [**recurrence relation**](https://en.wikipedia.org/wiki/Recurrence_relation). Recursion occurs in both pure mathematics and in the physical world in which we find ourselves embedded. <br><br>\n",
        "The root word is **recur**, which means \"to occur repeatedly\". Given a few consecutive values, the rest of a recursive sequence can be generated by repeatedly applying its recursion relation! \n",
        "\n",
        "\n",
        "As usual, we attempt to understand a concept from at least 3 different perspectives:\n",
        "- Algebraic\n",
        "- Geometric\n",
        "- Coding an example\n",
        "\n",
        "A famous example of a recursive sequence in mathematics is the [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number). Fibonacci was an Italian mathematician, who wrote about these numbers in **The Book of Calculation**, in 1202 AD. Although the sequence is named after him, it was known long before his time in India.\n",
        "\n",
        "The Fibonacci numbers are an infinite sequence of integers, beginning with $[0, 1]$ in which the $ith$ number (for $i>1$) is the sum of the two previous numbers.\n",
        "\n",
        "Here is the algorithm for generating the numbers in the Fibonacci sequence: \n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$\n",
        "\n",
        "You need a **base case** $F_0=0$ and $F_1=1$ to get the sequence started.\n",
        "\n",
        "Starting from the base case, the recursion relation generates the entire sequence:\n",
        "\n",
        "$F_0=0,~~  F_1=1 $<br><br>\n",
        "\n",
        "$F_2 = F_{1} + F_{0} ~=~ 1 + 0 ~=~ 1$<br><br>\n",
        "\n",
        "Then\n",
        "\n",
        "$F_3 = F_{2} + F_{1} ~=~ 1 + 1 ~=~ 2$<br><br>\n",
        "\n",
        "Then \n",
        "\n",
        "$F_4 = F_{3} + F_{2} ~=~ 2 + 2 ~=~ 3$<br><br>\n",
        "\n",
        "Then \n",
        "\n",
        "$F_5 = F_{4} + F_{3} ~=~ 3 + 2 ~=~ 5$<br><br>\n",
        "\n",
        "etc.\n",
        "\n",
        "Get the idea?\n",
        "\n",
        "Try: what are $F_{6}$ and $F_{7}$?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ954kRjHI0C"
      },
      "source": [
        "def fibo(n):\n",
        "    \"\"\"\n",
        "    Calculate and return the next number in the Fibonacci sequence\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    n: int or float\n",
        "        The nth number in the sequence (think of it as an index for a list)\n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    F_n: the next number in the sequence generated from the previous two numbers in the sequence \n",
        "    \"\"\"\n",
        "    \n",
        "    if n <= 1: # this is the base case\n",
        "        return n\n",
        "    else: # this is the recursive part \n",
        "        # notice how the function calls itself!\n",
        "        #  F_n =       F_n-1 + F_n-2\n",
        "        return(fibo(n-1) + fibo(n-2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBBvMSOTHobA",
        "outputId": "d58cc946-ed7d-4df1-8be6-2732dc8fb6eb"
      },
      "source": [
        "r = range(10)\n",
        "for i in r:\n",
        "  print(fibo(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "8\n",
            "13\n",
            "21\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpoASUlBvhEK"
      },
      "source": [
        "### Before coding up the Fibonacci sequence, let's take a moment to appreciate its beauty, and how important and ubiquitous it is in nature!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCO2jNOjuH03"
      },
      "source": [
        "#### **Contruction of the [\"Golden Spiral\"](https://en.wikipedia.org/wiki/Golden_spiral)**\n",
        "![](http://www.davidbeahm.com/wp-content/uploads/2011/11/fibonacci-1024x637.jpg)\n",
        "\n",
        "#### **Snail Shells**\n",
        "![](https://i.pinimg.com/originals/32/d7/47/32d747bea24f4756dc4c5ffe61b36efd.jpg)\n",
        "\n",
        "#### **The Mona Lisa**\n",
        "![](https://i.pinimg.com/originals/f2/cb/34/f2cb3452dd774bab87bbee2b8a77d4bb.png)\n",
        "\n",
        "#### **A Spiral Galaxy**\n",
        "![](https://f4.bcbits.com/img/a3628582449_10.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-HQ2GEp9uB7"
      },
      "source": [
        "#### **Take Away:** \n",
        "- There are often surprising connections between mathematics and physical phenomena\n",
        "- The world contains many examples of recursive sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObIXp1Wh9uB7"
      },
      "source": [
        "### Coding the Fibonacci Sequence using a recursive function\n",
        "*This is a standard problem that comes up in interviews for software engineering jobs!*<br><br>\n",
        "\n",
        "A recursive function is a function that can call itself!<br>\n",
        "For a recursive function to be defined, there must be a base case that the function eventually reaches by repeatedly calling itself.\n",
        "\n",
        "For the Fibonacci sequence, the base case is<br>\n",
        "$$F_0=0 ~\\text{and}~ F_1=1$$\n",
        "Again, here is the algorithm for the Fibonacci numbers.  \n",
        "\n",
        "\n",
        "$$F_n = F_{n-1} + F_{n-2}$$<br>\n",
        "\n",
        "So we want a recursive function that, given an integer $n$ computes the $nth$ Fibonacci number by repeatedly calling itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DS5sFTX9uB8"
      },
      "source": [
        "def fibo(n):\n",
        "    \"\"\"\n",
        "    Calculate and return the next number in the Fibonacci sequence\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    n: int or float\n",
        "        The nth number in the sequence (think of it as an index for a list)\n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    F_n: the next number in the sequence generated from the previous two numbers in the sequence \n",
        "    \"\"\"\n",
        "    \n",
        "    if n <= 1: # this is the base case\n",
        "        return n\n",
        "    else: # this is the recursive part \n",
        "        # notice how the function calls itself!\n",
        "        #  F_n =       F_n-1 + F_n-2\n",
        "        return(fibo(n-1) + fibo(n-2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b31ecb0aaf3ace76",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-J9V1xC9uB-",
        "outputId": "6069b801-84ce-4dae-ebf1-674070668cb3"
      },
      "source": [
        "# Using our recursive function, generate the first 10 values of the Fibonacci Sequence\n",
        "###BEGIN SOLUTION\n",
        "[fibo(n) for n in range(10)]\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomC-EGf9wK6",
        "outputId": "a0eb7eb2-2fda-4e85-c78a-b5f305eb8501"
      },
      "source": [
        "fibo(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6765"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKYapjUQbPNV"
      },
      "source": [
        "Factorial "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n535PNAebN8W"
      },
      "source": [
        "def factorial(n):\n",
        "  if n == 0 or n==1:\n",
        "    return 1\n",
        "  else:\n",
        "    return n*factorial(n-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gwyty7ddE2h",
        "outputId": "cb786052-58d2-4ca6-f424-e7d3edf274ab"
      },
      "source": [
        "factorial(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPQASrwt9uB_"
      },
      "source": [
        "**Take Away:** \n",
        "\n",
        "Recursive algorithms have as input their previous output. <br>\n",
        "In other words, the output at time step $t - 1$, becomes the input for the following time step $t$.<br><br> \n",
        "This key idea of recursion underlies the construction of a Recurrent Neural Network, specifically the LSTM model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-zlyhan9uCA"
      },
      "source": [
        "-----\n",
        "\n",
        "## 1.2 Introduction to Recursive Neural Networks (RNNs) \n",
        "\n",
        "\n",
        "The nice thing about spending time to understand the Fibonacci Sequence is that we can then build on the intuition we gained to help us understand how the LSTM works. \n",
        "\n",
        "Recurrent Neural Networks (RNNs) have a recursive loop in their architecture. The RNN model was first formulated in the original [backpropagation paper](https://chsasank.com/classic_papers/learning-representations-back-propogating-errors.html#) by Rumelhart et al. in 1986, based on the standard Fully-Connected Feed-Forward (FCFF) model: \n",
        "\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "This type of RNN had severe limitations! \n",
        "\n",
        "- It didn't have long-term memory capacity to learn long input sequences \n",
        "- It suffered from the [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).<br><br>\n",
        "\n",
        "To mitigate against these limitations, Hochreiter and Schmidhuber invented the [LSTM model](https://papers.nips.cc/paper/1215-lstm-can-solve-hard-long-time-lag-problems.pdf) in 1996.<br>\n",
        "The LSTM model ditched the FCFF architecture in favor of the following architecture\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "Wow! Ok! There's a lot going on here, isn't there? Well, don't worry, we are going to break this model down bit-by-bit so we can understand what is happening. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M49uor5E9uCB"
      },
      "source": [
        "_____\n",
        "\n",
        "\n",
        "## 1.2 Theory of the LSTM\n",
        "\n",
        "[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah presents a beautifully clear and concise explaination the model's archtecture and the mathematics. This article will serve as our main resource for understanding how LSTMs work. \n",
        "\n",
        "Below are the equations for each of the gates that are explained in the article. \n",
        "\n",
        "Although, you will not be held responsible for the equations in any quiz, module assignment, or Sprint Challenge - it is still instructive to have a look at the machinery inside the black box.\n",
        "\n",
        "First thing to notice is that each gate equation (not the cell states) has the form of a perceptron. \n",
        "\n",
        "Remember the perceptron? It's the fundamental building block of neural networks - it's not going away! \n",
        "\n",
        "Once you understand that, it will hopefully become gradually clear that each gate is a perceptron with a different job to do. \n",
        "\n",
        "That's it. \n",
        "\n",
        "It's just 4 perceptrons, each with a different job to do. \n",
        "\n",
        "Fortunately, you already know about perceptrons (you built one from scratch in `Sprint 2 Module 1`). \n",
        "\n",
        "____\n",
        "\n",
        "### **LSTM Gates**\n",
        "\n",
        "#### Forget Gate\n",
        "This neuron's job is to use the current input to learn what information the cell state should forget regarding long-term dependencies. \n",
        "\n",
        "\n",
        "$$f_t = \\sigma(W_f \\cdot [h_{t-1},x_t]~+~b_f)$$\n",
        "\n",
        "#### Input Gate\n",
        "This neuron's job is to use the current input to learn what new information to include in the cell state. \n",
        "\n",
        "\n",
        "$$i_t = \\sigma(W_i \\cdot [h_{t-1},x_t]~+~b_i)$$\n",
        "\n",
        "#### Candidate Cell State \n",
        "This neuron's job is to use the current input to create a candidate cell state.\n",
        "\n",
        "This new candidate cell state will be used to update the model's final cell state.\n",
        "\n",
        "$$\\tilde{C}_t = \\text{tanh}(W_C \\cdot [h_{t-1},x_t]~+~b_C)$$\n",
        "\n",
        "#### New Cell State\n",
        "This is where the candidate and old cell state are combined to create a new cell state.\n",
        "\n",
        "This is where output from the forget gate $f_t$ is used to scale the old cell state\n",
        "\n",
        "- If $f_t$ is closer to $0.0$, then less information from the previous cell state is retained.\n",
        "- If $f_t$ is closer to $1.0$, then more information from the previous cell state is retained. \n",
        "\n",
        "\n",
        "This is also where the output of the input gate $i_t$ is used to scaled the candidate cell state. \n",
        "- If $i_t$ is closer to $0.0$, then less information from the candidate cell state is retained\n",
        "- If $i_t$ is closer to $1.0$, then more information from the candidate cell state is retained. \n",
        "\n",
        "Finally, you form a linear combination of the cell state $C_{t-1}$ from the previous time step with the candidate cell state $\\tilde{C}_{t}$ from the current time step to form the model's new cell state $C_{t}$ of the model. \n",
        "\n",
        "It is $C_t$ that will be passed into the next training step and used by the output to make a final prediction. \n",
        "\n",
        "$$C_t = f_t*C_{t-1} + i_t*\\tilde{C}_t$$\n",
        "\n",
        "#### Output Gate\n",
        "This is where the actual output of the model is calculated. \n",
        "\n",
        "This neuron's job is to take the current input and make a prediction. \n",
        "\n",
        "$$o_t = \\sigma(W_o \\cdot [h_{t-1},x_t]~+~b_o)$$\n",
        "\n",
        "Next, the cell state is used to inform the final prediction. \n",
        "\n",
        "Recall that $o_t$ is the output of a sigmoid activation function, so its value is somewhere between 0 and 1. \n",
        "\n",
        "$o_t$ is used to scale $\\text{tanh}(C_t)$, which contains the current cell state. <br><br>\n",
        "The model's final output is \n",
        "$$h_t = o_t*\\text{tanh}(C_t)$$<br><br>\n",
        "\n",
        "Recall that the tanh activation maps numbers on the real line to numbers on the interval $[-1,1]$.<br>\n",
        "So the presence of the factor $\\text{tanh}(C_t)$ makes it possible to have positive **or  negative** values for the model's final output. <br>\n",
        "Sigmoids don't allow for the posibility of negative values, but tanh does. \n",
        "\n",
        "\n",
        "The article denotes the model's pre-scaled output as $o_t$ and the final output as $h_t$. <br>\n",
        "To be clear, $h_t$ is the model's final prediction, while  $o_t$ is an intermediate step. <br>\n",
        "We are familiar with the notation $y$ to denote a model's prediction instead of using $h$. <br>\n",
        "In the LSTM, they both mean the same thing - the model's final prediction. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgvXhCKV9uCB"
      },
      "source": [
        "_________\n",
        "\n",
        "##1.3 Applications of LSTMs\n",
        "\n",
        "So why are LSTMs cool? \n",
        "\n",
        "One compelling application is **language modeling** - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.<br><br>\n",
        "\n",
        "A language model is simply a model that, given some text, predicts the most likely next word, or character.<br><br>\n",
        "Language models are essentially self-supervised -- the \"label\" or \"target\" for any text string is the next word (or character). <br>\n",
        "The data set already has the answers!\n",
        "\n",
        "Another interesting application of LSTMs is to text classification problems such as the sentiment classification problem we encountered in Unit 4, Sprint 1.\n",
        "\n",
        "For our purposes, we'll TensorFlow and Keras to train LSTMs with natural language. \n",
        "\n",
        "Resources:\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSytcRhoIM2A"
      },
      "source": [
        "# 2. Sentiment Classification with RNN/LSTM -- Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "_____________\n",
        "\n",
        "RNNs and LSTMs are great for modeling any kind of data that comes in ordered sequences. <br>\n",
        "There are an astonishing variety of sequences in our world, such as \n",
        "* words in a document\n",
        "* musical notes or chords in a song\n",
        "* sounds in an audio recording\n",
        "* daily stock prices\n",
        "* DNA base pairs\n",
        "* medical sensor time series data, such as voltage measurements in an EKG\n",
        "* etc.!<br>\n",
        "\n",
        "Can you think of other examples of sequence data?<br>\n",
        "\n",
        "To illustrate the power of Neural Networks for modeling sequences,<br>\n",
        "we'll focus on text data, and apply LSTMs to a simple sentiment classification task.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESoxKIrKkd_w"
      },
      "source": [
        "The [Internet Movie Database (IMDb)](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data) is a database of movie reviews in text format, along with the sentiment label(positive or negative), coresponding to each review.\n",
        "\n",
        "The movie review labels are binary:\n",
        "* $1 \\rightarrow$ the review expresses positive sentiment\n",
        "* $0 \\rightarrow$ the review expresses negative sentiment\n",
        "\n",
        "In this exercise, we will train a **sentiment classification** model that can predict from the text whether a movie review is \"thumbs-up\" or \"thumbs-down\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti23G0gRe3kr"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "scrolled": true,
        "id": "bt77ZoUo9uCD",
        "outputId": "0f44214c-4cec-46e7-a69e-7b733b2d9757"
      },
      "source": [
        "# load in dataset \n",
        "\n",
        "# maximum number of words in vocab\n",
        "max_features = 20000\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68GZlbBc3B_u"
      },
      "source": [
        "#### What does the data look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE0AUO-Lz5c6",
        "outputId": "5a1c2895-78b3-42e9-c92a-edf7f4d7bda5"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(len(x_train[0]))\n",
        "print(len(x_train[101]))\n",
        "print(np.max(x_train[101]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n",
            "218\n",
            "145\n",
            "19205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxW8zFVcNMxp",
        "outputId": "b558a93d-c171-4870-b7d1-e9031c022b29"
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg1Ydf44DIVI",
        "outputId": "79894fc8-4fed-4cee-aabb-03060270927d"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73hiyEIh0rat"
      },
      "source": [
        "### What's the length of the longest review in the training set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8tSZcLO0YcF",
        "outputId": "3a296a02-9d89-447c-f1c9-c896c4ec8922"
      },
      "source": [
        "np.max( [len(x_train[i]) for i in range(len(x_train))] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2494"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLX_bFuV3_jq"
      },
      "source": [
        "#### What's the number of words in the training data vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SbZ0xkb34DL",
        "outputId": "3bc9a996-a5a8-413c-f765-940bd249e5e8"
      },
      "source": [
        "np.max( [np.max(x_train[i]) for i in range(len(x_train))] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0awRJCnIM2G",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fb23c1d7d1168a73",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "9f85f90b-3179-43fc-e72a-ea6c6b643f0f"
      },
      "source": [
        "# although there are some implementations of LSTM models that can handle variable length samples, this is not one of those models\n",
        "# so we need to standardize the length of our movie reviews\n",
        "# by truncating reviews that are longer than maxlen\n",
        "# reviews that are shorter than maxlen are padded with 0s (or some other value that you provide) to increase their length to maxlen \n",
        "\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "print('Pad Sequences (samples x time)')\n",
        "# default padding and truncation is 'pre'\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen,padding='pre',truncating = 'pre')\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen, padding='pre',truncating = 'post')\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z78PHr5yFOeB"
      },
      "source": [
        "#### each review is truncated to the first 80 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrwFDoliEJMd",
        "outputId": "ac998fb4-5bb6-43cf-ac0d-24a71e7986ac"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WeUXgQF2uht"
      },
      "source": [
        "#### What are the \"labels\" (or \"targets\")?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1GFlKzck5zW",
        "outputId": "0b3dd3ff-24ad-4a5e-f02b-5a171e51fdc9"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZFdt-TB9uCF"
      },
      "source": [
        "### Build a 1 hidden layer LSTM language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD_NjHw-pcJS",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9c285c5d84213905",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "ae2d6d6e-fdcf-4654-9ccd-5ffc85604e9b"
      },
      "source": [
        "# build a 1 layer LSTM language model \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# specify learning rate and optimizer\n",
        "opt = Adam(learning_rate=1.e-7)\n",
        "\n",
        "###BEING SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class \n",
        "model = Sequential()\n",
        "\n",
        "# input layer \n",
        "# adding an Embedding layer \n",
        "model.add(Embedding(input_dim=max_features, output_dim=128))\n",
        "\n",
        "# hidden layer 1 \n",
        "model.add(LSTM(128, dropout=0.2, return_sequences=False))\n",
        "\n",
        "# output layer \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dioHuVz-jObs"
      },
      "source": [
        "### Use learning rate schedule to find best learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63yPeX0VhXp-",
        "outputId": "2e768344-5f4f-4780-cd60-5f14cd887c16"
      },
      "source": [
        "%%time\n",
        "# specify batch size\n",
        "batch_size = 32\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "     lambda epoch: 1e-7 * 10**(epoch / 4))\n",
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size, \n",
        "                      epochs=20, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 24s 22ms/step - loss: 0.6934 - accuracy: 0.4859\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6933 - accuracy: 0.4868\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6933 - accuracy: 0.4919\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6932 - accuracy: 0.4922\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6931 - accuracy: 0.5029\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6929 - accuracy: 0.5134\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6925 - accuracy: 0.5427\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6915 - accuracy: 0.5814\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6431 - accuracy: 0.6588\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.5327 - accuracy: 0.7368\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4432 - accuracy: 0.8008\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.3650 - accuracy: 0.8490\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.3122 - accuracy: 0.8699\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.2703 - accuracy: 0.8900\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.2428 - accuracy: 0.9041\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.2264 - accuracy: 0.9093\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.2253 - accuracy: 0.9093\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.2176 - accuracy: 0.9139\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.2311 - accuracy: 0.9071\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.2275 - accuracy: 0.9090\n",
            "CPU times: user 4min 48s, sys: 23 s, total: 5min 11s\n",
            "Wall time: 5min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "yVpTOFgAiXBN",
        "outputId": "180a9aaf-9a32-4533-84a2-c9dad8dc37f8"
      },
      "source": [
        "plt.semilogx(results_one_layer.history[\"lr\"], results_one_layer.history[\"loss\"])\n",
        "plt.axis([1e-7, 1e-2, 0, 1])\n",
        "plt.xlabel('learning Rate')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUGjJpuxjxNY"
      },
      "source": [
        "# build a 1 layer LSTM language model \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# specify learning rate and optimizer\n",
        "#opt = Adam(learning_rate=0.0003)\n",
        "opt = Adam(learning_rate=5.e-5)\n",
        "\n",
        "###BEING SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class \n",
        "model = Sequential()\n",
        "\n",
        "# input layer \n",
        "# we are explicitly declaring the dimension of the input layer here by adding an Embedding object \n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# hidden layer 1 \n",
        "model.add(LSTM(128, dropout=0.2, return_sequences=False))\n",
        "\n",
        "# output layer \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQAKkBGd9uCF",
        "outputId": "850fa28e-ff1e-4937-fa03-8307db795fa2"
      },
      "source": [
        "%%time\n",
        "# specify batch size\n",
        "# Try additional batch sizes\n",
        "batch_size = 32\n",
        "\n",
        "results_one_layer = model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size, \n",
        "                      epochs=5, \n",
        "                      validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 8s 9ms/step - loss: 0.6022 - accuracy: 0.6652 - val_loss: 0.5265 - val_accuracy: 0.7358\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4068 - accuracy: 0.8201 - val_loss: 0.4826 - val_accuracy: 0.7790\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3275 - accuracy: 0.8646 - val_loss: 0.4618 - val_accuracy: 0.7859\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.2811 - accuracy: 0.8855 - val_loss: 0.4712 - val_accuracy: 0.7883\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.2436 - accuracy: 0.9044 - val_loss: 0.4657 - val_accuracy: 0.7881\n",
            "CPU times: user 46.8 s, sys: 4.99 s, total: 51.8 s\n",
            "Wall time: 35.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZQj7QXr9uCG"
      },
      "source": [
        "### Build a 1 hidden layer Bidirectional LSTM language model\n",
        "\n",
        "A Bidirectional LSTM, or biLSTM, is a sequence processing model that consists of two LSTMs: **one taking the input in a forward direction**, and **the other in a backwards direction**. BiLSTMs effectively increase the amount of information available to the network, improving the context available to the algorithm (e.g. knowing what words immediately follow and precede a word in a sentence).\n",
        "\n",
        "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKyGb4TzIM2O",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-706b7be103484984",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "26c0cbb7-b3ac-4081-8cfb-44308226f837"
      },
      "source": [
        "# build a 1 layer Bidirectional LSTM language model \n",
        "\n",
        "###BEING SOLUTION\n",
        "# as usual, we begin to build our model by instantiating a Sequential class \n",
        "model = Sequential()\n",
        "\n",
        "# input layer 1\n",
        "# we are explicitly declaring the input layer here by add an Embedding object \n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# hidden layer 1\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
        "\n",
        "# output layer \n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 2,823,425\n",
            "Trainable params: 2,823,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E-lL5kB9uCH",
        "outputId": "fdbb574b-65a0-4fea-841e-a17e22538ada"
      },
      "source": [
        "%%time\n",
        "results_biLSTM = model.fit(x_train, y_train,\n",
        "                      batch_size=256, \n",
        "                      epochs=5, \n",
        "                      validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "98/98 [==============================] - 7s 35ms/step - loss: 0.5025 - accuracy: 0.7405 - val_loss: 0.4410 - val_accuracy: 0.7922\n",
            "Epoch 2/5\n",
            "98/98 [==============================] - 3s 27ms/step - loss: 0.2936 - accuracy: 0.8794 - val_loss: 0.4699 - val_accuracy: 0.7925\n",
            "Epoch 3/5\n",
            "98/98 [==============================] - 3s 27ms/step - loss: 0.2090 - accuracy: 0.9240 - val_loss: 0.5073 - val_accuracy: 0.7838\n",
            "Epoch 4/5\n",
            "98/98 [==============================] - 3s 27ms/step - loss: 0.1505 - accuracy: 0.9467 - val_loss: 0.5940 - val_accuracy: 0.7667\n",
            "Epoch 5/5\n",
            "98/98 [==============================] - 3s 27ms/step - loss: 0.1067 - accuracy: 0.9628 - val_loss: 0.7499 - val_accuracy: 0.7573\n",
            "CPU times: user 17.5 s, sys: 2.24 s, total: 19.7 s\n",
            "Wall time: 17 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "RZx3Zs7tIM2Q",
        "outputId": "8cda1350-881e-42ed-f316-7a8c2047591c"
      },
      "source": [
        "# Plot training & validation loss values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epoch_list = np.arange(1,6)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.grid()\n",
        "plt.xticks(epoch_list)\n",
        "# results for 1-layer lstm model\n",
        "plt.plot(epoch_list, results_one_layer.history['loss'], \"--\", label=\"1 layer LSTM Train\")\n",
        "plt.plot(epoch_list, results_one_layer.history['val_loss'], \"--\", label = \"1 layer LSTM Test\")\n",
        "\n",
        "# results for bi-lstm model\n",
        "plt.plot(epoch_list, results_biLSTM.history['loss'], label=\"1 layer biLSTM Train \")\n",
        "plt.plot(epoch_list, results_biLSTM.history['val_loss'], label = \"1 layer biLSTM Test\")\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeVzVVf748dfhsu+yuaGCSy6IYCqkqKFiWpmZZommmaNOi07ZtDgzzmTT1KjZZptlpt8c00kbtZ9WJiiVkppllqamKCq5gAtwL7JcLuf3x4dFFBUKuCzv5+NxH9z7Wd8fPihvzjmf91Faa4QQQgghRO1ysHcAQgghhBCNkSRhQgghhBB2IEmYEEIIIYQdSBImhBBCCGEHkoQJIYQQQtiBJGFCCCGEEHYgSZgQosFTSoUopbRSyrES205USm39vccRQojrkSRMCFGnKKVSlVIFSqmAy5bvLk6AQuwTmRBCVC9JwoQQddFRIL7kg1IqHHC3XzhCCFH9JAkTQtRFy4AJl3y+H/jg0g2UUj5KqQ+UUhlKqWNKqVlKKYfidSal1Hyl1Fml1BHg9gr2XayUOqWU+lUp9S+llKmqQSqlWiilPlFKnVdKHVZKTblkXZRSapdSKlspdUYp9XLxclel1H+UUueUUplKqW+VUk2rem4hRP0nSZgQoi7aDngrpToXJ0djgP9cts3rgA/QFrgZI2l7oHjdFGAY0B3oCdx92b5LgUKgffE2twCTf0OcK4E0oEXxOV5QSg0sXvca8JrW2htoB3xUvPz+4rhbAf7Ag0Dubzi3EKKekyRMCFFXlbSGDQb2A7+WrLgkMfuL1tqstU4FXgLGF29yD/Cq1vqE1vo88O9L9m0K3AY8prXO0VqnA68UH6/SlFKtgBjgaa11ntb6B+A9ylrwrEB7pVSA1tqitd5+yXJ/oL3W2qa1/k5rnV2VcwshGgZJwoQQddUyYCwwkcu6IoEAwAk4dsmyY0DL4vctgBOXrSvRpnjfU8XdgZnAO0BQFeNrAZzXWpuvEsMfgBuAA8VdjsMuua6NwEql1Eml1DyllFMVzy2EaAAkCRNC1Ela62MYA/RvA/532eqzGC1KbS5Z1pqy1rJTGN19l64rcQLIBwK01r7FL2+tdVgVQzwJ+CmlvCqKQWt9SGsdj5HczQVWK6U8tNZWrfWzWusuQB+MbtMJCCEaHUnChBB12R+AgVrrnEsXaq1tGGOsnldKeSml2gCPUzZu7CPgT0qpYKVUE2DmJfueAr4AXlJKeSulHJRS7ZRSN1clMK31CSAZ+HfxYPtuxfH+B0ApdZ9SKlBrXQRkFu9WpJQaoJQKL+5SzcZIJouqcm4hRMMgSZgQos7SWqdorXddZfV0IAc4AmwFPgTeL163CKPLbw/wPVe2pE0AnIGfgQvAaqD5bwgxHgjBaBVbAzyjtU4oXjcU2KeUsmAM0h+jtc4FmhWfLxtjrNuXGF2UQohGRmmt7R2DEEIIIUSjIy1hQgghhBB2IEmYEEIIIYQdSBImhBBCCGEHkoQJIYQQQtiBJGFCCCGEEHbgaO8AqiogIECHhITU6DlycnLw8PCo0XOIuknufeMl977xknvfeNXGvf/uu+/Oaq0DK1pX75KwkJAQdu26Wtmg6pGUlERsbGyNnkPUTXLvGy+5942X3PvGqzbuvVLq2NXWSXekEEIIIYQdSBImhBBCCGEHkoQJIYQQQthBvRsTVhGr1UpaWhp5eXnVcjwfHx/2799fLccSdYurqyvBwcE4OTnZOxQhhBCNXINIwtLS0vDy8iIkJASl1O8+ntlsxsvLqxoiE3WJ1ppz586RlpZGaGiovcMRQgjRyDWI7si8vDz8/f2rJQETDZdSCn9//2prMRVCCCF+jwaRhAGSgIlKkZ8TIYQQdUWDScLsbdKkSQQFBdG1a9erbjN79mzmz59fazElJSUxbNiwK5avX7+e7t27ExERQZcuXXjnnXd4/vnniYyMJDIyEpPJVPp+wYIFzJ49G6UUhw8fLj3Gq6++ilLqipptd911F5GRkbRv3x4fH5/S4yQnJ1cq5j59+vy+ixZCCCHqiQYxJqwumDhxItOmTWPChAl2i6GwsBBHx2vfUqvVytSpU9m5cyfBwcHk5+eTmppKx44d+dvf/gaAp6cnP/zwQ+k+s2fPJjw8nJUrVzJr1iwAVq1aRVhY2BXHX7NmDWAkgPPnz2f9+vVVirGyyZoQQghR30lLWDXp378/fn5+ld5+0aJF9OrVi4iICEaNGsXFixcxm82EhoZitVoByM7OLv2ckpLC0KFD6dGjB/369ePAgQOAkfw9+OCDREdH89RTT133vGazmcLCQvz9/QFwcXGhY8eO191vxIgRrFu3DoCUlBR8fHwICAio1LUuXbqU4cOHM3DgQAYNGoTFYmHQoEHceOONhIeHlx4XjAQQyqoY33333XTq1Ilx48ahta7U+YQQQoj6oEG2hN37zjdXLBvWrTnje4eQW2Bj4pKdV6y/u0cwo3u24nxOAVOX7cFkMpWu++8fe1d7jCNHjmTKlCkAzJo1i8WLFzN9+nRiY2PZsGEDI0aMYOXKlYwcORInJyemTp3KwoUL6dChAzt27ODhhx9m8+bNgPF0aHJycrmYr8bPz4/hw4fTpk0bBg0axLBhw4iPj8fB4dr5uLe3N61atWLv3r2sW7eOe++9lyVLllT6er///nt+/PFH/Pz8KCwsZM2aNXh7e3P27Fluuukmhg8ffsV4rd27d7Nv3z5atGhBTEwM27Zto2/fvpU+pxBCCFGXSUuYnezdu5d+/foRHh7O8uXL2bdvHwCTJ08uTW6WLFnCAw88gMViITk5mdGjRxMZGckf//hHTp06VXqs0aNHVyoBK/Hee++RmJhIVFQU8+fPZ9KkSZXab8yYMaxcuZK1a9dy1113VeFqYfDgwaUthVpr/vrXv9KtWzfi4uL49ddfOXPmzBX7REVFERwcjIODA5GRkaSmplbpnEIIIcTVWL7+GpWdbdcYGmRL2LVartycTddc7+fhzJLxETVeJ2zixImsXbuWiIgIli5dSlJSEgAxMTGkpqaSlJSEzWaja9euZGdn4+vrW26c1qV+ywzw4eHhhIeHM378eEJDQ1m6dOl19xk2bBhPPvkkPXv2xNvbu0rnuzTG5cuXk5GRwXfffYeTkxMhISEVlo1wcXEpfW8ymSgsLKzSOYUQQojL5R86xJm588jZuhX3oUNh+HC7xSItYXZiNptp3rw5VquV5cuXl1s3YcIExo4dywMPPAAYXYGhoaGsWrUKMFqS9uzZ85vOa7FYShM+gB9++IE2bdpUal93d3fmzp1bOoD/t8rKyiIoKAgnJye2bNnCsWNXnWBeCCGEqBaFFy5w+p//5MiIu8jds4egp58mZ9jtdo1JkrBqEh8fT+/evTl48CDBwcEsXrz4mts/99xzREdHExMTQ6dOncqtGzduHBcuXCA+Pr502fLly1m8eDERERGEhYWVG8x+LYmJiQQHB5e+du/ezbx58+jYsSORkZE888wzlWoFKzFmzBhuvPHGSm9fkXHjxrFr1y7Cw8P54IMPrrh+IYQQorroggLOvb+ElFuGcOG/H9Hk3ntp98VG/B+YCNepKFDTVH174qxnz5768tpU+/fvp3PnztV2DntPW7R69WrWrVvHsmXL7BZDQ3atn5eSpzJF4yP3vvGSe98waa0xJySQ/uJ8rMeP49G/H02fegqX9u1Lt6mNe6+U+k5r3bOidQ1yTFh9Nn36dD777DM+/fRTe4cihBBC1Et5P//MmTlzubhzJ87t29Fq0bt49utn77CuIElYHfP666/bOwQhhBCiXrKmp5Px2mtk/W8NJh8fmv7j7zS55x6Unbsdr6ZuRiWEEEIIUUlFeXmcX7qUs+8uQlut+E2cSMBDD2Kq4pP8tU2SMCGEEELUS1prsjd8SvrLL1F48hReg+MIeuIJnCv51L+9SRImhBBCiHon94cfOPPvOeTu2YNLl860+PccPKKj7B1WlUgSJoQQQoh6w3ryJOkvv0L2+vWYAgNo/vzz+Iy4E1WFmWPqCqkTVk0mTZpEUFAQXbt2veo2s2fPZv78+bUWU1JSEsOGDbti+fr16+nevTsRERF06dKFd955h+eff57IyEgiIyMxmUyl7xcsWMDs2bNRSnH48OHSY7z66qsopbi8XMhdd91FZGQk7du3x8fHp/Q4ycnJlYo5NTWVDz/88PdduBBCiAanKCeH9NdeI+XW2zBv2oT/g3+k3Wef4ztqZL1MwEBawqrNxIkTmTZtGhMmTLBbDIWFhThe5wkQq9XK1KlT2blzJ8HBweTn55OamkrHjh1LK+F7enqWmyJp9uzZhIeHs3LlSmbNmgXAqlWrCAsLu+L4a9asAYwEcP78+axfv75K11CShI0dO7ZK+wkhhGiYdFERWWvWkvHqqxRmZOB9++0E/flxnFq0sHdov5u0hFWT/v37l05QXRmLFi2iV69eREREMGrUKC5evIjZbCY0NBSr1QpAdnZ26eeUlBSGDh1Kjx496NevHwcOHACM5O/BBx8kOjqap5566rrnNZvNFBYW4u/vDxjzM3bs2PG6+40YMaK0Sn9KSgo+Pj4EBARU6lozMjIYNWoUvXr1olevXmzbtg2AL7/8srSlrHv37pjNZmbOnMnXX39NZGQkr7zySqWOL4QQomHK2bmTo3ffzam//Q3HFs1ps+JDWr40v0EkYNBQW8KWVDAXVNgIiJoCBRdh+egr10eOhe7jIOccbv8dC6ZLvjUPbKj2EEeOHMmUKVMAmDVrFosXL2b69OnExsayYcMGRowYwcqVKxk5ciROTk5MnTqVhQsX0qFDB3bs2MHDDz/M5s2bAUhLSyM5ORlTJZpj/fz8GD58OG3atGHQoEEMGzaM+Ph4HByunY97e3vTqlUr9u7dy7p167j33ntZsmRJpa710UcfZcaMGfTt25fjx48zZMgQ9u/fz/z583nzzTeJiYnBYrHg6urKnDlzflMLmhBCiIaj4Phx0l+cj3nTJhybN6fFiy/iPex2lFL2Dq1aNcwkrB7Yu3cvs2bNIjMzE4vFwpAhQwCYPHky8+bNY8SIESxZsoRFixZhsVhITk5m9Oiy5DE/P7/0/ejRoyuVgJV47733+Omnn0hISGD+/Pls2rSpUvNHjhkzhpUrV7Jx40YSExMrnYQlJCTw888/l37Ozs7GYrEQExPD448/zrhx4xg5ciTBwcGVvgYhhBANj81s5uzbC7mwbBk4ORH46J/wmzgRBzc3e4dWIxpmEnatlitn92uv9/An997VNT535MSJE1m7di0REREsXbqUpKQkAGJiYkhNTSUpKQmbzUbXrl3Jzs7G19e33DitciF7eFT5/OHh4YSHhzN+/HhCQ0MrlYQNGzaMJ598kp49e+JdhQJ4RUVFbN++HVdX13LLZ86cye23386nn35KTEwMGzdurOplCCGEaAB0YSGZq1aRseB1bJmZ+Nx1F4GPPopT0yB7h1ajZEyYnZjNZpo3b47VamX58uXl1k2YMIGxY8fywAMPAEZXYGhoKKtWrQKM4nR79uz5Tee1WCylCR/ADz/8QJtKFrVzd3dn7ty5pQP4K+uWW24pNx1TSTKZkpJCeHg4Tz/9NL169eLAgQN4eXlhNpurdHwhhBD1l+XrrRy96y5OP/tPXNq1I2T1Klq88HyDT8BAkrBqEx8fT+/evTl48CDBwcEsXrz4mts/99xzREdHExMTQ6dOncqtGzduHBcuXCA+Pr502fLly1m8eDERERGEhYWVDpK/nsTERIKDg0tfu3fvZt68eXTs2JHIyEieeeaZSrWClRgzZgw33nhjpbcHWLBgAbt27aJbt2506dKFhQsXAkaZi65du9KtWzecnJy49dZb6datGyaTiYiICBmYL4QQDVh+SgrH//hHTkyZQlFePi0XvEbrZR/gVsGT9w2V0lrbO4Yq6dmzp768NtX+/fvp3LlztZ3DbDbXeHfktaxevZp169axbNkyu8XQkF3r5yUpKYnY2NjaDUjUCXLvGy+597Wr8MIFzr7xJhdWrsTBzY2Ahx6iyfj7cHB2rvVYauPeK6W+01r3rGhdwxwTVo9Nnz6dzz77jE8//dTeoQghhBDVRhcUcP7DDzn71tsUWSz43nsPgdOn41iF8k4NTY0mYUqpocBrgAl4T2s957L1rwADij+6A0Faa9+ajKmuu3TslBBCCFHfaa2xbN5M+rwXKTh2DI+YGJrOfBqXDh3sHZrd1VgSppQyAW8Cg4E04Ful1Cda69JaBVrrGZdsPx3oXlPxCCGEEKJ25R04wJk5c7m4fTvObdvS6p2FePTv3+Dqff1WNdkSFgUc1lofAVBKrQTuBH6+yvbxwDM1GI8QQgghakFhRgYZCxaQufpjTN7eNJ01iyb33oNycrJ3aHVKTSZhLYETl3xOA6Ir2lAp1QYIBTZfZf1UYCpA06ZNy5VYAPDx8anWsgY2m03KJDRgeXl5V/wMlbi8hIdoPOTeN15y76uR1Yp7YiIen32Oslq5OHAgObfdykkPDyiesq4usfe9rysD88cAq7XWtopWaq3fBd4F4+nIy59k2L9/f7U+zWjvpyNFzXJ1daV794p7vuUpqcZL7n3jJff+99NaY/7sM9Lnv4T15Ek8Bw2i6ZNP4BwSYu/Qrsne974m64T9CrS65HNw8bKKjAFW1GAsNW7SpEkEBQXRtWvXq24ze/Zs5s+fX2sxLV26lGnTplW4rk+fPgCkpqZWGPP27duJjo4mMjKSzp07M3v2bJYsWVI64bazszPh4eFERkYyc+ZMli5dilKKhISE0mOsXbsWpRSrV68ud+xHHnmEyMhIunTpgpubW+kxL9/uam677TYyMzMr+20QQghRg3J/+olj4+7j18f/jIOXF62XLqHVm2/U3QQs3wxp39k7CqBmW8K+BToopUIxkq8xwNjLN1JKdQKaAN/UYCw1buLEiUybNo0JEybYLYbCwkIcHSt3S5OTk6+5/v777+ejjz4iIiICm83GwYMH6dKlS2kV/5CQELZs2UJAQABgJHzh4eGsXLmSuLg4AFasWEFERMQVx37zzTcBIwEcNmzYFdMxXe86pHyHEELYn/X0adJffpnsT/4fpoAAmj33T3xHjkRVYS7jWlFkg5O7IWULpGyGtJ3g6ApPp9o7spprCdNaFwLTgI3AfuAjrfU+pdQ/lVLDL9l0DLBS17eqsZfp378/flWodbJo0SJ69epFREQEo0aN4uLFi5jNZkJDQ7FarYAx0XXJ55SUFIYOHUqPHj3o168fBw4cAIzk78EHHyQ6OpqnnnrqivOcOHGC2NhYOnTowLPPPlu63NPT85rxpaen07x5cwBMJhNdunS57jX169ePnTt3YrVasVgsHD58mMjIyEp9P5KSkujXrx/Dhw8vPdeIESPo0aMHYWFhvPvuu6XbhoSEcPbsWVJTU+ncuTNTpkwhLCyMW265hdzc3EqdTwghxG9TdPEiGQteJ2XorZg/34j/1Km0+/xzmoweXXcSsAupUJhvvP/qRXhvEGz5F1hzoPc0GPMhYP8nNGt0TJjW+lPg08uW/eOyz7Or85xzd87lwPkDv+sYNpsN0yU/SJ38OvF01NO/N7RyRo4cyZQpUwCYNWsWixcvZvr06cTGxrJhwwZGjBjBypUrGTlyJE5OTkydOpWFCxfSoUMHduzYwcMPP8zmzcZzDGlpaSQnJ5eLucTOnTvZu3cv7u7u9OrVi9tvv52ePSss3FvOjBkz6NixI7GxsQwdOpT777//igm4L6eUIi4ujo0bN5KVlcXw4cM5evRopb8n33//PXv37iU0NBSA999/Hz8/P3Jzc+nVqxejRo3C39+/3D6HDh1ixYoVLFq0iHvuuYePP/6Y++67r9LnFEIIUTm6qIisTz4h4+VXKExPx/u2Wwl8/M84B7e0d2iQmwmpXxstXSlb4MJRuO9/0H4QhI0E//bQNhY8AuwdaTl1ZWB+o7N3715mzZpFZmYmFouFIUOGADB58mTmzZvHiBEjWLJkCYsWLcJisZCcnMzo0aNL98/Pzy99P3r06AoTMIDBgweXJi4jR45k69atlUrC/vGPfzBu3Di++OILPvzwQ1asWFGpJ0jGjBnDggULyMrK4qWXXuKFF1647j4loqKiShMwMOacXLNmDWC06B06dOiKJCw0NLS0ta1Hjx6kpqZW+nxCCCEq5+KuXZyZM5e8vXtxDQ+n5auv4F7FeYSrlc0KBRZwawLpB+Dt3qCLwNkTQvrCTQ9BUHEPTuANxqsOanBJWHW0WNXG05ETJ05k7dq1REREsHTp0tIEJyYmhtTUVJKSkrDZbHTt2pXs7Gx8fX2vGDtVwsPD46rnubwgXlUK5LVr146HHnqIKVOmEBgYyLlz565Igi4XFRXFTz/9hLu7OzfcULUf+kuvIykpiYSEBL755hvc3d2JjY0lLy/vin1cXFxK35tMJumOFEKIalSQlkb6i/Mxb9yIY7NmtJg3F+9hw1AONflcXwW0hnMpcKR4XNfRryFiDNw+HwI6wM1PQ2h/aNkTHGt/DsrfqsElYfWF2WymefPmWK1Wli9fTsuWZc25EyZMYOzYsfz9738HwNvbm9DQUFatWsXo0aPRWvPjjz9WOOj9cps2beL8+fO4ubmxdu1a3n///UrFt2HDBm677TaUUhw6dAiTyYSvb+VmlJozZ851uy6vJysriyZNmuDu7s6BAwfYvn377zqeEEKIyrNZLJxbuJDz//cBODoSMH0a/pMm4eDmVntBFOaDY/Ef2osHQ9q3xnvf1hA+CjrdZnx2MEHszNqLqxpJElZN4uPjSUpK4uzZswQHB/Pss8/yhz/84arbP/fcc0RHRxMYGEh0dHS54rDjxo1j1qxZxMfHly5bvnw5Dz30EP/617+wWq2MGTOmUklYVFQUo0aNIi0tjfvuu6/CrsiDBw8SHBxc+vmVV17h448/ZsaMGbi7u+Po6Mjy5cuv2uV5uVtvvbVS213L0KFDWbhwIZ07d6Zjx47cdNNNv/uYQgghrk3bbGSu/piM117Ddv48PiNGEDjjMZyaNq35kxfmw4mdZa1dOefgsR9BKeh6t9Hy1XYA+LU1ljUAqr49lNizZ0+9a9eucsv2799P586dq+0c9i7Wunr1atatW8eyZcvsFkNDdq2fF3sX7hP2I/e+8ZJ7b8hJTubMnLnk//ILbj160HTmTNzCr1778ncryT+Ugh3vQMJssF4EZYLgXtBuIPSdUaPdi7Vx75VS32mtKxyMLS1hdcz06dP57LPPpBaWEEKIWpF/5Cjp8+ZhSUrCKTiYlq++iteQW2pmkm1LBhxJMlq6jmyBsR9B827GuK7IcUbiFdIXXL2r/9x1kCRhdczrr79u7xCEEEI0ArbMTDLefIsLK1bg4OJC0BN/psn48Thc8sBTtTl7CFY/AKd/Mj67NYHQm8u6FdsNNF6NjCRhQgghRCOirVYurFhJxptvUmQ24zt6NIF/mo7jdZ5+r5SiIkjfV1advm0s9H0MvJqDmx8M+ocxrqt5hDGgvpGTJEwIIYRoBLTWWJKSSJ/3IgVHj+LRpzdBT8/EtWM11dD65E9w8FPIyTA+B3YG5+LSQy6ecP8n1XOeBkSSMCGEEKKByzv4C+lz55CT/A3OoaEEv/0WnrGxv23cV0EOHEs2WrosZ+Du4tJHhflGy1e7gcZX7xbVdwENlCRhQgghRANVeO4cGa8tIHP1ahy8vGj617/SJH4Mysmp6gfb//+MpxhP7ABbAZhcICTGqF5vcoKR71T/BTRwtVzytuGaNGkSQUFBdO169cd5Z8+ezfz582stpqVLlzJt2rQK1/Xp0weA1NTUCmPevn070dHRREZG0rlzZ2bPns2SJUuIjIwkMjISZ2dnwsPDiYyMZObMmSxduhSlFAkJCaXHWLt2LUopVq9eXe7YjzzyCJGRkXTp0gU3N7fSY16+3dVkZmby1ltvVfbbIIQQjU5RQQHn3nuPlFuGkPm//9HkvnG03/g5fhPGVy4ByzwO3/0frJoI2SeNZZZ0Y47G6Adh/BqYecz4avoNCZ0ApCWs2kycOJFp06YxYcIEu8VQWFiIo2PlbmlycvI1199///189NFHREREYLPZOHjwIF26dOGBBx4AICQkhC1bthAQYEyGunTpUsLDw1m5ciVxcXEArFixosKCsm+++SZgJIDDhg276nRMV1OShD388MNV2k8IIRo6rTXmjV+QPn8+1rQ0PAcMIOjJJ3FpG3r9nTNPwLbXjNIR5w4byzybwYVUo2ux5yTodfUi5KLqpCWsmvTv3x8/P79Kb79o0SJ69epFREQEo0aN4uLFi5jNZkJDQ7FarQBkZ2eXfk5JSWHo0KH06NGDfv36ceDAAcBI/h588EGio6N56qmnrjjPiRMniI2NpUOHDjz77LOlyz09Pa8ZX3p6Os2bNweMORm7dOly3Wvq168fO3fuxGq1YrFYOHz4cOnk2teTk5PDpEmTiIqKonv37qxbtw6Affv2ERUVRWRkJN26dePQoUPMnDmTlJQUIiMjefLJJyt1fCGEaOhy9+7j2Pjx/PrYYzi4u9P6/cW0evutihMwWyGc+BaS5sKBDcYy5QA/LIcmoTDk3/DwdvjzAWjTp3h9w6hSX5c0uJaw0y+8QP7+A7/rGIU2G+cvmaLHpXMnmv31r783tHJGjhzJlClTAJg1axaLFy9m+vTpxMbGsmHDBkaMGMHKlSsZOXIkTk5OTJ06lYULF9KhQwd27NjBww8/zObNmwFIS0sjOTm5wmmFdu7cyd69e3F3d6dXr17cfvvtFU5ddLkZM2bQsWNHYmNjGTp0KPfff/9154NUShEXF8fGjRvJyspi+PDhHD16tFLfj+eff56BAwfy/vvvk5mZSVRUFHFxcSxcuJBHH32UcePGUVBQgM1mY86cOezdu7fKLWhCCNEQWc+cIePlV8hatw6Tvz/Nnn0W37tHoS7/naA1fLcUUhLhyFeQnwUo6P0IdLodfFrC08fq1QTY9V2DS8Lqi7179zJr1iwyMzOxWCwMGTIEgMmTJzNv3jxGjBjBkiVLWLRoERaLheTkZEaPHpM9RWQAACAASURBVF26f35+fun70aNHX3Vex8GDB+NfXPtl5MiRbN26tVJJ2D/+8Q/GjRvHF198wYcffsiKFStISkq67n5jxoxhwYIFZGVl8dJLL/HCCy9cdx+AL774gk8++aR0zFxeXh7Hjx+nd+/ePP/886SlpTFy5Eg6dOhQqeMJIURDV5Sby7n33+fce4uhsBD/KZPx/+MfMZX0dORegKNfQfYpuOlBoyXruyVw8TyE3WnU6wq9GTwuqQ8mCVitanBJWHW0WNXG3JETJ05k7dq1REREsHTp0tIEJyYmhtTUVJKSkrDZbHTt2pXs7Gx8fX2v2vLj4eFx1fNc/vhxVR5HbteuHQ899BBTpkwhMDCQc+fOlSZ0VxMVFcVPP/2Eu7s7N9xQ+dozWms+/vhjOnbsWG55586diY6OZsOGDdx222288847tG3bttLHFUKIhkYXFZG9fj3pL79C4enTeA0dStATf8Y5OBhO/Qg7PzGKpZ78HnQReARB1BSjOOqEdeDqK12LdYSMCbMTs9lM8+bNsVqtLF++vNy6CRMmMHbs2NJB8N7e3oSGhrJq1SrASFj27NlTqfNs2rSJ8+fPk5uby9q1a4mJianUfhs2bKBkcvdDhw5hMpnw9fWt1L5z5sypdAtYiSFDhvD666+XnnP37t0AHDlyhLZt2/KnP/2JO++8kx9//BEvLy/MZnOVji+EEA3Bxe93k3rvGE4+9TSO/v60eeMFguM74RxY/P/zwU/h65eMJKv/k/DA5/D4z2XV6d2aSAJWh0gSVk3i4+Pp3bs3Bw8eJDg4mMWLF19z++eee47o6GhiYmLo1KlTuXXjxo3jwoULxMfHly5bvnw5ixcvJiIigrCwsNKB69cTFRXFqFGj6NatG6NGjaqwK7Ik5pLXqlWrWLZsGR07diQyMpLx48ezfPnyq3Z5Xu7WW29lwIABldq2xN///nesVivdunUjLCyMv//97wB89NFHdO3alcjISPbu3cuECRPw9/cnJiaGrl27ysB8IUSjUJD2K2kzZnBs7FgK01Jpfk9nQvr8jPvWifDZU5C209gwaio8dRQmJ8CAv0Kb3lJCog5TJS0P9UXPnj31rl27yi3bv38/nTt3rrZz1EZ35LWsXr2adevWsWzZMrvF0JBd6+clKSmJ2NjY2g1I1Aly7xuvunzvbZnnOPfSc5xftxkcTPjfezv+OW/g4OltjOdqNxDaDYAmIfYOtV6qjXuvlPpOa13hYOwGNyasvps+fTqfffYZn376qb1DEUIIUdu0hvT96EMJZK5ZS0bir9jyHPC+sTlBL3+IU1AQnBwBLbrLBNgNgCRhdczrr79u7xCEEELUJvMZoyBq62gAcuaN4sw2K/mZTriF+NP0kQm43TIOXIp7aIKv/4S7qB8kCRNCCCFqU8FFOJ5sPMGYsgXS94FnMwpGfc6ZF+dj2QxOzYJp+crTeA0d+tsm2Rb1QoNJwrTW8oMqrqu+jYEUQjQARUVw5ido2tXoQkx4Bna+CyZnaH0Ttt5/4exX6Zy/YzgOLi4EPv44fvdPwMHFxd6RixrWIJIwV1fX0hpWkoiJq9Fac+7cuetW/hdCiN8t61djDsaULXAkCS6ehSmboWUP6DEROgxBt+jFhTXrOfuP17FlZ+N7990EPvonHIvn5BUNX4NIwoKDg0lLSyMjI6NajpeXlye/qBsoV1dXgoOD7R2GEKKhybeArQDc/SB1Gyy9zVjuEQTtBxnV6f2MQtM6qAs5B85y5tGxFBw5gvtNN9F05tO4XlauSDR8DSIJc3JyIjS0EjPEV1JSUhLdu3evtuMJIYRoYIpscPIHOLIZUpLgxA7o+xgMnAUtb4Rb/mWUjwjqUq44av6hQ5yZM5ecbdtwbtOG4LfexHPAAOnFaaQaRBImhBBC1Li8bHD1NspIvBYJWceN5c26GZNgd7zV+OzkBn2ml9u18Px5MhYsIPOjVTh4etL0LzNpEh+Pcpa5GhszScKEEEKIiuRlwdGvi8d2bQZHN3g42WjZ6v0weARC21jwuPoYrqKCAi4s+w9n336botxcmowdS8AjD+PYpEmtXYaouyQJE0IIIQBshWAq/rW4+V/w9cugbeDkASF9je5FrY0k7KaHrnkorTXmTZtIn/8S1uPH8bi5P02fegqXdu1q4UJEfSFJmBBCiMbHmgfZv0JeJi1+/RRWvAtHv4KHtkGTNsZTjH1nGIlXcC9wrHy3Ye6+faTPmcvFb7/FpUN7Wr33Hp59Y2rwYkR9JUmYEEKI+qOkJcqaB2cPGuO08rIgP9t4H9oPmobBuRRIfPbK9Xe8Bp1ug2Nb4T+jALgBwLc1hI8CXWScp+OtZWO8Ksmank7Gq6+RtWYNJl9fms1+Bt+770Y5yq9aUTH5yRBCCFE7imxgs4KTq/H++PbyCVJeljElT7sBcPE8fDy5eF2WsT4/Gwb81Rj0npUG7/S/8hy3zTeSsKJCSD9gDKR3a2JMcO3qDV5Nje2ahsNd74CLNzuOZBJ9a3y5pxirdFl5eZxfsoSzi95DW634TXqAgAcfxOTl9du/V6JRkCRMCCHE9RUVQYHZSJ7c/YxlhxMg51xZopSfDYGdITLeWL/kdqNIaUkCVWCBXpPh9peMFqeSWlqXinnUSMJMzpCXCS7e4N0CXH2M980jje28W8C9y43EysXbWF+yDUBgR5i28+rX49UUIsYAkHs66TclYFprstdvIP3llyk8dQqvwYMJevIJnFu3rvKxROMkSZgQQjR0WhsJUF62UVDUr7iu4qEEyEwtS5LyssGrOdz8pLH+wzFw+idjXb4Z0NB+MNy32lj/yaOQnVZ2HpMzdL27LAlz8wX3JsXJkY+RMLUsnnza5AT3/z9w9iyfQJWMvXLxNCrMX42zO3QeVl3foSrL/eEHTv/73+Tt+RHXLl1oMXcOHlFRdotH1E+ShAkhRF2mNVgvXtKalGMUAwU4nFiWJJWsd3CCEW8a69c8BAc3GAlUyVgn/w4wfZfxfuvLcGyb8d7B0UiCgnuVnTugg9GV5+pT1uLk375s/biPjMSrJIFyumymkTHLr31toRV0J9Zx1pMnSX/pZbI3bMAxMJDmL7yAz4g7UQ4O9g5N1EOShAkhRE3RGgrzyrc05WdBm75Gi8/Rr+Hol5etz4bxa41SCV/Mgu1vG+ObSjg4wd8zjO6zvR/DD8tBOZR1yXm3LNu25Y1Gi1JJkuTqDZ5Ny9aPXGTs6+pjFBi9vEvulueufX1Nw37/96ieKMrJ4eyiRZxfshSAgIcfwv8Pf8DBw8O+gYl6rUaTMKXUUOA1wAS8p7WeU8E29wCzAQ3s0VqPrcmYhBCi0myFkHuhOEHKLEuSQvoZ46LSvoOfVpUfE5WXDfd8YJQ5+OYNI5G63IyfwaclHP8Gvppf3Mp0SWtTYR6YPKF1H6OlqSSBKkm0Sp4QHPpvuHUeOHtUPKYpasq1r8+n5bXXC7TNRtbataS/+iq2jLN433EHQY/PwKl5c3uHJhqAGkvClFIm4E1gMJAGfKuU+kRr/fMl23QA/gLEaK0vKKWCaioeIYS4QtavRmtSxkG6HfsJfjEZidSwV41SBwc3wEcTrtzvgc+gTR84f8Roibo0SfIMKuv6a90HBj1zZZLl7m+s7zsD+j0BV+vK6nSb8boaV5/fd/3imnJ27OTMnDnk79+PW2QkTd94A7eICHuHJRqQmmwJiwIOa62PACilVgJ3Aj9fss0U4E2t9QUArXV6DcYjhGhsioog8xhkHISMA2WvPn+CriPBcho2/R08m+KofMC9tVHKwLm4i6l5hFHyoFxLlDf4tTXWdxttvK4muIfxuhqTU7Vdqqg+BceOcebFF7EkJOLYojktXpqP9223ySTbotrVZBLWEjhxyec0IPqybW4AUEptw+iynK21/rwGYxJCNERFRcZTfiXJVmBn6DgUctJhQWTZdl7NjdIFTm7G52bd4Kmj4O7H90lJxMbGlj9uk5Drd+mJBsOWnc3Ztxdy/j//wcHJicDHHsNv4v04uLpef2chfgOlta6ZAyt1NzBUaz25+PN4IFprPe2SbdYDVuAeIBj4CgjXWmdedqypwFSApk2b9li5cmWNxFzCYrHg6elZo+cQdZPc+zpO23DLPYNDUQE5niGgNd13P42n5SimooLSzdJa3s7hDlNBa5qdTuSie0suurei0Onq91bufeNlycoicPcPeK5fj8rJIa93byx3DqfIR7p7G7ra+Hc/YMCA77TWPStaV5MtYb8CrS75HFy87FJpwA6ttRU4qpT6BegAfHvpRlrrd4F3AXr27Kmv+Gu1miVV9BexaBTk3tcRJQPPAXYuMiqrZxyEs7+ALd8YGD9svbHe0gecB0Ngp+JXR4JdvQkuPdiASp1S7n3jU5SXh+XLrzj26ms4njqFe1QUTWc+jWuXLvYOTdQSe/+7r8kk7Fugg1IqFCP5GgNc/uTjWiAeWKKUCsDonjxSgzEJIeqaC6lwao+RZKXvN76i4eFvjPW/fA4ZvxjdiO1ijUSrWXjZ/ne8aoegRX1ly87G8uWXmDclYNm6FX3xIgQGEvzG63gOGiTjvkStqrEkTGtdqJSaBmzEGO/1vtZ6n1Lqn8AurfUnxetuUUr9DNiAJ7XW52oqJiGEnRQWwPmU4oHxB+HcYbjrXeOpwK/mw+5lxna+bYwkq2lYWWtY/H+NmllC/EbWM2cwJyZiSUgkZ+dOKCzEMTAQnzuH4xUXx668PMIHDbJ3mKIRqtH/2bTWnwKfXrbsH5e818DjxS8hRH1XmA/nipOtDoPBxQu2L4Qv/nZJwVFlDHjPvQAe/sZkzL3+AAE3lD2VeClJwMRvkH/kKOaEBMyJCeTt+REA55AQ/B+YiFdcHK7h4WVV7pOS7BeoaNTkfzchRNVZ84yvTq7w6/fw9UtGC9f5I6BtxrpJG6H1TdAi0piUuXi8FgE3lD2dCMYyIX4nrTV5e/di3pSAOSGBgiPGyBbX8HACH3sMr8FxuLRrZ+cohShPkjAhxLXlZcEvX0DG/rISEOePwKj3oOsoo4Ur46CRTIWNKBsgH3CDsX/rm4yXENVMW61c/PZbzAmJmBMTKTxzBkwm3KN60WTcWLwGDpTK9qJOkyRMCAEFF40nDzMOliVbnYZB93GQmwn/mwzKBP7tIKgLhI00Ei2AVlFlE0ILUcOKLl7EsnUrlsREzElfUpSVhXJ1xbNfX7ziZuB5882YfH3tHaYQlSJJmBCNSb6lLNlya2IUNC0sgDmtysZsOTiCf3sozDU++7SCh74xljk62y920WgVXriAZUsS5oQEcrZtQ+fnY/LxwWvAALwGx+HRpw8Obm7XP5AQdYwkYUI0RPlmyMkom15nzYNwbBtkHi/bpv1gIwlzdIZbngevZkbrln+78tPpODhAU6mbJGqX9eRJo5sxIYGL330HNhuOzZvjO3o0XnFxuPfsgXKUX2GifpOfYCEagoOfQerWshIQWSeMbsOSWlsmJwjuBd0nGGO3gjpDk9Cy/W960D5xC1FMa03+oUNGN+OmBPJ+NqYZdunQHv+pU/AaFIdrWBep4yUaFEnChKgP8rLLJp9OL/5qPgUPJRu1tPatgZ/XQUAHaN0bAidC065l+w9/3W6hC3E1uqiI3B/2YE40nmi0HjNaat0iIwl68gm8Bg3COSTEvkEKUYMkCROiLsm9UPYEYvoBGDgLXDxh68uw9RVjG0dX48nDZuFQmGeUe7htPox4GxxM9o1fiOvQBQXk7NhhlJLYvBnb2bPg5IRHdDT+D0zCc+AAnIKC7B2mELVCkjAh7OHieSPRCuwE7n6wfz1s+DNYTpdt4+QOPe43ug7D74FW0cb2vq2vTLZcvWs3fiGqwGbJIefrr4ypgr76iiKLBQd3dzz698crLg7Pm/tj8vKyd5hC1DpJwoSoSUU2I2G6cAySXy/rUszJMNbfuxw6DwPvFtB+kDFeq6TOlk8rY1A8GAPjZXC8qEcKz57FvGWLMbA++Ru01YrJzw/vW4fiOWgQHr174+DiYu8whbArScIqYCvS9g5B1DeFBXBie/lJqDP2w80zIXoq2KywZ6WRZN0wpCzRatnD2L/ljdDyLftegxC/U8GJE6VPNOZ+/z1ojVNwME3GjcMrbhBu3bujTNJlLkQJScIq8PEhK0uP7uDJIR3pFixF/0QxrcGSXvYEYsZ+aB4BPSaCrQD+7w5jOxcfI9nqdDsEFleN928HfzlhDKIXooHQWpN/4IAxvisxkfyDBwFw6dSJgEceMaYKuuEGeaJRiKuQJKwC/m6Kb1KzGP7GNm7t2ow/39KR9kGe9g5L1BatwXzaSLa0DdrHGctfv9GYrqeEq48xQTUYg+cnbgC/dka9rct/6cgvIdFAaJuN3O+/NybHTkjE+uuv4OCA+403EjTzabzi4nAODrZ3mELUC5KEVWBQayeeuieG974+yntfH2HjvtM8OzyM8b1D7B2aqE7WXCPZ8iuul5U0l+7f/w+2nzLmSwRoHlmWhPWYaDyZWDJuy7Np+eQqpG+thi9EbSnKzycnORlzQgKWzVuwXbiAcnbGo08fAh56EM8BA3D097d3mELUO5KEXYWXqxMzBt/AhN5teGPLYaJCjf9gzmTn4WRywM9Dpm+pF2yFYCr+MT+wAQ4nwrnDcC4FstPAIxCePGyst5xGKxN0vdtIsoI6lc2PCBDzaO3HL4Sd2LKzsXz5JeaERCxff42+eBEHT088Y2PxihuER99+mDw97B2mEPWaJGHX4e/pwjN3hJV+/teG/Ww5kM7kfqFM7tcWTxf5FtYZGQfh6FdGgnU+xUi2stJg5glwcoXUbbB3Nfh3gJAYYy5E/3ZG96NSMOwVfkhKIjY21t5XIoRdWM+kY9mciDkhkZwdO6CwEMfAQHyG34FX3GA8onqhnOUPUCGqi2QQVfTooPZYC4t4NeEQH3xzjEcGtGdcdGtcneSJnxqXlwVn9pW1ZJ07bIzRil8BTULg0Cb44m9GfS3/dtCsG4SNNAbNO7nC4GdhyPMyPkuIS+QfPWp0MyYkkrtnDwDObdrgP/F+vOLicO3WDVVSKkUIUa0kCaui9kFeLBzfgx9OZPLixgM8t/5nLuQU8MSQjvYOrWHIzSzfknUuBfpMhxaRkLIZVk00tnNwMsZy+bc3yj8ARI6FrqMqHhgP5SelFqKR0lqTt3df8cD6BApSUgBwDQsj8LFHjYH17drJE41C1AJJwn6jyFa+LJ98E1sPnaVjM+MJue+PXyA9O48hYc3kP7BrKcgxWrBKWrNC+kHraEjbBe8NKttOORgFS0sKm7bpC/d9bDyB6NOqbKxXCXe/2rsGIeoRbbVycdcuo4ZXYiKFp0+DyYR7r140GTMGr7hBODVvbu8whWh0JAn7nfp2CCh9v+ybY6zZ/SsRrXx5akhHYtoHXGPPBq6wADKPGUmWRxAE9zCm6lnYF7J/Lb9t3GwjCQvoAIOfM7oS/dsbXYyOl1TU9gwse1JRCHFNRbm5WLZuxZKQiDkpiaKsLJSrKx59Y/B69FE8Y2/GsUkTe4cpRKMmSVg1evHubvRu58+rm35h3Hs7iGnvz9NDOzXcgq9FNmPge2G+UZRUa1gRb9TXyjxu1NgC6H6fkYS5+kLbAUZyVZJo+bU1amyBUXcr5k92uxwh6rvCCxewJH2JOSGBnG3b0Hl5OPj44BUbi9fgODxiYnBwc7N3mEKIYpKEVSNHkwP39GzF8IgWLN9xnDe3HGbn0fP1OwnTGvKzjQQJYOsrRrdhyaB4WwG0Gwjj1xjjsJSDMX4r/O7iJKsdBLQ39nVwgBFv2u9ahGiArCdPYk7cbMzRuGsX2Gw4NmuG76hReA2Ow71HD5STjIcUoi6SJKwGuDqZ+EPfUO7pGYyTyXiqaM3uNL5JOcejcTfQ0rcO/yV6OAGOby//9KF3S5i201ifug2yThjJVYdbjBatpl3L9o//0D5xC9FIaK0pOHwYc2Ii5k0J5O3bB4Bz+3b4T55sPNHYNUzGpQpRD0gSVoO8XMv++jyTnc/a3SdZu/sk993UhkcGtMPf0+Uae9eQC6lwcnfxk4dHjK+WM/DoHqMl66fV8ON/wbe10ZLVurdRtLTEuFVS4kGIWqaLisjdswdLceJVcOwYAG4REQT++XG84uJwCQ21c5RCiKqSJKyWPHhzO+6IaMFrCb+wNPko//32OH+7vQtjo1tX74kKC4xE69zhstf5I3Dvf8DNF75fBl/PN7b1amG0ZLUbaIzrcnKFof+GOxaA41UKMkoCJkSt0AUF5OzYaZSS2JyILeMsODriER2N3wMT8RwwEKemQfYOUwjxO0gSVota+rox7+4IpvZvy0tf/EITd6OlLM9qDGCvdMHXIpvRJVhatDQFbnrIqJv1w39g/Yyybd39jRatvCwjCetxP4SNMAbEO1cw5YibPC0lhL3YLDnkbP0a86YELF9+SZHFgnJ3x7NfP7zi4vC8uT8mb297hymEqCaShNlB+yAv3r6vR+nnd786wsqdx3ks7gZG3tgSR5ODMSDefLq4JSsFWvcxnkA8+jX8p7gKfAlnL+h0m5GEtY2Fu94tnpKn7ZVJlW81t7wJIX6XwnPnsGzZgnlTAjnffIMuKMDUpAleQ27BKy4Ojz59cHCxw9AFIUSNkyTM3i6eZ4DHMX52P8dTH+fxv6TtvOv4El4Xj6OsOWXbDZ1rJGF+bY1Wr5InD/3bg2dQWTehX1vjJYSoswrS0jBvSsCcmEDu97uhqAinli1pEh+PV9wg3G68EWWSqdCEaOgkCasN+RawXjSSpcIC+GR6WQtX7gXCgbd7T2fjoGm8vvFHvjvvjFuz27mpV1RZPS3vlsaxfFrC4H/a9XKEEFWjtSb/4MHixCuR/AMHAHDp2JGAhx7CK24QLp06yRONQjQykoRVl6Iiow4WwI534cxPlzx9eNqY0/Du940B72f2GlPshN1V2pqlmnVlqE8z4joH8b/dnenS3Bta+nAqK5f07HwifOWvYiHqE22zkbt7d2niZU1LA6Vwu/FGgp5+Gq+4QTi3amXvMIUQdiRJ2G9x7Bs4taesNevcYWMuwwc+NdZ//wGYTxktWO0HGa1ZLcvGgPHQtqseuqTga4mFSSn83zfHGBrWjCeG3ED7IK+auiohxO9UlJ9PzjffYE5IwLJ5C7bz51FOTrj36Y3/H6fiNXAgjv7+9g5TCFFHSBJWAaeCTDj6VfmnD605cP//MzbY9ir88jm4eBsJVnAUtOhedoDJCUa5h2rw5NBO+Hm4sOjrI3zx82lG3RjMY4PreMFXIRoRm9lsTBWUmEjOV19RdPEiDp6eeN58M15xg/Do1x+TZwVPIgshGj1JwioQkroCkj83Pji6GgPdAzqUdTneOheGvw4egRXXzaqmBAzA08WRR+M6ML53G97acpgPth/D0aT498hu1XYOIUTVWNPTsWzejDkhkZwdO8BqxRQYgPcdd+AVNwj36GgcnK9Sa08IIYpJElaBky2G0nLQg2UD4kvGepVoElLrMfl5ODNrWBcm9Q3F0WQkfntOZJJ4IJ0p/ULLVecXQlS/gtRUo3DqpgRy9+wBwKlNa/wmjMcrLg63iAjU5f9XCCHENUgSVoEcz1BoF2vvMCrU4pJuyK2Hz7Ig8RDLvknlkQHtue+mNpUv+CqEuCatNXl792FOTMCckEDB4RQAXMPCCHz0T3jFxeHcvr080SiE+M0kCavHHhnQnn4dAnhx40H+tWE/7289ytO3duLOyJb2Dk2IekkXFnJx1y7MCYmYExMpPHUKTCbce/akyT334hU3CKcWLewdphCigZAkrJ7rFuzLsj9Ek3z4LHM3HuT4uYuA8Vc8IH+lC3EVuqiIwjNnKDh+AuuJ43iv38Chp2diy8pCubjg0bcvXtOn4zkgFscmMp2XEKL61WgSppQaCrwGmID3tNZzLls/EXgR+LV40Rta6/dqMqaGqk/7ANa286ewyEi+Pv3pNO98lcKTQzrSt32AJGOiUSrKz8ealkbB8eNYT5woTrhOUHDiBNa0NHRB2fRfLu5ueA4ejGdcHJ4xMTi4u9sxciFEY1BjSZhSygS8CQwG0oBvlVKfaK1/vmzT/2qtp9VUHFVVpIvYn7ufWGLtHUqVKaVwKh6072RSnLMUMH7xTvq08+epoZ2IbOVr5wiFqH62zEwKTpwon2gdP05BWhqFZ84Y87AWc3B3x6l1a1zatcNzQCzOrVrj3LoVTq1bk3zwIGGDBtnxSoQQjU1NtoRFAYe11kcAlFIrgTuBy5OwOuWTlE94K/0tTief5i9Rf8HVsfrKTdSmW8KacXPHQD7ccZw3Nh9mxJvbmNgnhNnDw+wdmhBVom220m7DghPHsR4vbskqTrSKsrPLbe8YGIhTq1Z4REfj1LoVzq1b49zKSLRMTZpcvVX48OFauBohhChTk0lYS+DEJZ/TgOgKthullOoP/ALM0FqfqGCbWjOs7TC+/ulr/nfof+w9u5eXY1+mjXcbe4b0m7k4mnggJpTRPVvx/tajtA00CkbmWW2cteQT3ES6W0TdUJSXV9xtaIzPujThsv76K9pqLdvYyQnnFi1watUKn8gInEpas1q1wjk4WLoRhRD1htKXNNVX64GVuhsYqrWeXPx5PBB9adejUsofsGit85VSfwTu1VoPrOBYU4GpAE2bNu2xcuXKGom5hMVi4ZjpGB+c/YAiXcRY/7F09+h+/R3ric+OWvn4lwIGtHbkjrbOeLvIeLESFosFT09Pe4fR8GiNysnBlHEWx7MZmDIyMGWcLf6agSkrq9zmRa6u2AIDsQUEGF8Dja+FAYEU+TW5snZfNZB733jJvW+8auPeDxgw4Dutdc+K1tVkEtYbmK21HlL8+S8AWut/X2V7E3Bea+1zreP27NlT79q1q7rDLScpKYnY2FhO55zmz1/+mR8zfiS+UzxP9HwCZ1P9r4J9MjOXBYmH+GjX+KgITwAAIABJREFUCVydTEzu11YKvhYrufei6rTNhvXUaaxp5cdnlbRoFVks5bZ3DAoyugtbtcapVXC58VkmX99af5hE7n3jJfe+8aqNe6+UumoSVpPdkd8CHZRSoRhPP44Bxl4WWHOt9anij8OB/TUYT5U182jG0iFLeeX7V1j28zJ+yviJ+bHzaelZv+twtfB1Y86obkzp35aXv/iFBYmH2PtrFu9P7GXv0EQdV5SbW/pkYcHxy8ZnnTwJl3cbtmyJU+tWuHe/0Ui0SsZnBQfj4CbznwohGrcaS8K01oVKqWnARowSFe9rrfcppf4J7NJaf8L/b+/Ow6Os7v6Pv88syWSd7HsghJ0QdpFFIKBWFJfqU6g/W/vUx2qtW21R61q1deFRoGrrY2srtlYrVWtbF9RaJah1YxPC5gaRJEASwIQ96/n9McOQYVFUJneWz+u6uMjcc0/yHW4SPpzzvc+BK40xZwLNwHbg+5Gq56vyur1ce9y1jMwYyU3/uYkZz83gzhPuZFL+JKdL+9p6p8fzwHdGcEllfWgLzNqdDby6tppvjczD49YWLN2NtZaWzz4LhKr9Szm0CVrNtbVh57sSEojKzyd64EASvvGN4MhW4JcnKwvj1g4OIiJHEtF1wqy1C4AFBx37eZuPrweuj2QNx8qJPU+kX3I/Zi6ayeWvXc4Fgy/gyuFX4nF1/vVui/MOzAA/s6ySu15cx0NvrGfmyf05dXAWLpd6xroS29xM05YtgaC1sSI4fXggaLXu3h12viczk6j8fOImTDjQAJ8f+N2JaUMRka6i8yeIdpSfmM+fT/szd793N4+seoQVNSu4e+LdZMZlOl3aMXPxxEIK0uKY/fIHXPaXZRTn+rl2an8m9E13ujT5Elr37KGxojJ0p+GBoLWRpqpN0NwcOtd4vXjz8gLThiNHhgetvDxcvs65TIuISEenEPYlRbujuXnszYzIHMFtb9/GjOdncNeEuxiXM87p0o4JYwynFGVx0sBM/rG8irmvfMhTSyoVwjoYay0t27cftBL8RhorKmms2EhL7daw812JiUTl5+MbNIjEU6YGg1agEd6TkaFpQxERByiEfUXTCqcxMGUgMxfN5JJXLuGSoZfwwyE/xO3qGv+YuV2G/xqZx+lDs9nT0ALAui07mPuvD7n6lP70y0xwuMKuzzY307R582GDVtPGjbTu2XPgZGNC04bxEyceuNMw+Lvb/7k3HYuIiAMUwr6GwqRCHj/tce549w4eXPEgy2uWM2vCLFJjUp0u7ZiJ9riJ9gSC5Sc1u3n7k22ccu/rnDM8j6tO6kt+ihbG/Dpad++mMexOw+DvlZU0bTpo2jAqCm9eHlH5+cQed1xwFfjAivDe3Fxc0dEOvhMREfmyFMK+plhvLLePv52RmSO58907mfHcDO6edDcjM0c6XdoxN21INuN6p/Lgok/441vlPLuiih9MKORnUwc4XVqHZa2lZdu2w64E31hRQcu2bWHnu/1+vD16EDO4iMRTTz3Qn9WjR2DaMAKLlIqIiDMUwo4BYwzn9D2HotQiZi6ayYUvX8iVI67k+0Xfx2W61j+ayXFR3HDaQC4YX8D9r36EJ3jnpLWW3Y0txEd3v79StqkpOG14mKBVWYk9eNowO4uo/B7hG0jvnzZMTHTujYiISLvqfv9iRlD/lP7MnzafW966hV8t/RXLqpdxxwl34I/uev042f4Y7jpnCPt3XCj9oJafPPk+l5X04fyxPfF5u0Zv3H4tu3YfshJ86M7DzZuhpSV0romODq0AHzvm+LCg5c3LxRXV+XddEBGRr08h7BiLj4pn9qTZPLHuCe5Zcg8znpvB7EmzKU4vdrq0iNi/RlR2ko8heUncsWAtD7+5gatO6tupFny1TU0019bi/fhj6urqwleCr6igZfv2sPPdSUmBacOhQ0k843Si8vJDW+540tM1bSgiIl9IISwCjDGcN/A8itOKuXrR1Xzvpe9x9airOW/AeV12YcsBWYk8+j+jefuTbdz98jque6aMf76/iScuHuNoXdZaWnfsoKm6mubqGpprqtt8XENzdTVNNTWB3ixrSQE2A7hceLOy8PboQcKJJ4ZWgt/fn+VO0N2hIiLy9SiERVBxejFPnvEkN755I7Pem8Wy6mXcNu424qMiu2O7k8b2TuWZH43j32traG5pBaCxuZXF5dsZ1zv1mIZQ29hIc20tTcFw1VxdHfi4uprmmhqaagJhy+7bd8hr3cnJeDIz8WRm4CsqwpORgSczg7U1NYycNo2o3FyMpg1FRCSCFMIizB/t5/4p9/PH1X/k/mX388FnHzBn0hz6p/R3urSIMcZw8qADuwj8Y3kV1/5tJWMKU7h26gBG9Ej+3Ndba2mtrz8oXAVHr6qraaqtobm65pA7CyGwjMP+cBVTNBjPlEw8GRl4MzOCxwOPj9SX1VhaSnSvXl/vD0BEROQoKIS1A5dx8T+D/4eh6UO5dtG1fGfBd7jh+Bs4u8/ZXXZ6sq1vDs9lb1MLv37tY2b85nXOyovi4kEJZDftDA9XNdU019TSXF2NbWg45PO4U1LwZGbizcggZnBxaPTK2yZcaS9DERHpLBTC2tHIzJE8ecaTXPfGddzy1i0srV7KjcffSKy38y94aq2lpa7uQJ/VQeFqQnUNY6praP0s0ODeClQFX2uiow+Eq+JiPCedhCcjvU24ysSTka67CkVEpEtRCGtnqTGp/Pak3/LQyod4cMWDrNm2hjmT5lCYVOh0aUfU2tgYClfhfVfhPVi2sfGQ17pTUwOjVVlZxAwdiicjncakVHYlpNCzfwF7EpN5cGkNF0/qQ3qCVnwXEZHuQyHMAW6Xmx8N+xFDM4Zy/RvXc+4L53LL2FuYVjitXesIjV5VH9R3VRM+ktVSV3fIa43PFwhXGZnEDBsW3neVkRn4OD39C5vbS1dtYd5bn/L4exVceEIvLppYSKLPG6m3LCIi0mEohDloXM44njz9Sa59/Vque+M6llUv49rR1xLt/vojQq0NDUecGmxuO3rV1BT+QmNwp6bizcjAm5NDzPD9ASs4LRjswXIlJh6T3qupg7P4908nMedfH/Dr1z7mz+98yqUlvbloQqF6u0REpEtTCHNYZlwmD5/yML9e/mvmrZpH2dYy5kyaQ35i/mHPt62todGrI4ar6mpa6usPea2JicGbERitihkxIjBalZERFq486ekYb/uORPVKi+M3543gkkn13PPyBywu/4yLJx7YDklhTEREuiKFsA7A4/Lwk5E/Ybi/iHtf/jk3P3AOF2d/i/4t6eF9V9XVNNfWHn70Ki0Vb0Ym3rw8YkaOCAaqQODaP03oSkjo0IFmcK6fP/3PaPY1BbYA2rB1Nxc/uoQrT+zLtOJsXK6OW7uIiMiXpRDWDmxrKy3btwcWED1C31VTTQ2Z9fXcFXrVH6khOHoVvEswZtTIw4YrT1pau49eRdL+fSfr9zbhMoYrnljObxd9wjWn9GdSv/QOHSRFRESO1lGFMGNMHLDXWttqjOkHDABetNY2fcFLu7zWvXtDIerw4aqa5tqtcPDolcuFJzU1EKZ69CD2uFHBpRgyID2Fx2oX8GjtC/TLG8jskjlkxWU58wYdNCw/iQU/nsCzK6qY868P+f4ji5nQN40/XTBao2IiItLpHe1I2OvABGNMMvAvYDHwbeA7kSrMaba1lZZt24Krth8arvZPE7bu2HHIa12xsaHV2eOOOy7Yc5UZvvZVWhrGc+Q//suZRN/yKdzy1i1Mf246d55wJxPyJkTyLXdIbpfh7OF5TCvOYf7ijXy2uykUwCq27yE/pfOvsSYiIt3T0YYwY63dY4y5EPg/a+3dxpj3I1mYU3a98QZp19/Aup07obk5/EmXC09aWmD0qmdPYo8bHdoiZ3/DuyczE3f8sdkb8pSCU+if3J+Zi2Zy6auXclHxRVw67FI8ru43ixzlcfG9sQWhx29/so3z/vAO3xyWy09O6kePVIUxERHpXI46hBljxhIY+boweMwdmZKc5UlLo7F/P/KGDMUTvHswNHqVmvq5o1eRUOAv4PHTHmfWe7P4fdnveb/2ff53wv+SHpvernV0NAOzE7h4YiF//E85z6/cxP8b3YPLp/QhI8HndGkiIiJH5WgTxVXA9cDfrbWrjTGFwMLIleUc38CB7Pj+98koKXG6lBCfx8et425leMZwbn/ndqY/N527J97N6OzRTpfmmKTYKK4/dSAXjOvF/a99xOPvbuTVtTW8fu1k3OoXExGRTsB1NCdZaxdZa8+01v6vMcYFbLXWXhnh2uQgZ/U5i79M+wuJ0Ylc9MpFPLTyIVptq9NlOSrL7+POs4v5908ncfs3B+N2GVpaLY+/+yl7G1ucLk9EROSIjiqEGWP+YoxJDN4luQpYY4y5JrKlyeH0Te7L/GnzmVowlV8v/zWXvnopn+37zOmyHNcrLY7JAzIAePPjrdz491WUzF7I4+9+SlNL9w6qIiLSMR1VCAMGWWt3AN8EXgR6AedHrCr5XLHeWGZNmMXNY27mvc3vMf256bxf0yXvk/hKJvVL568XjyEvOZYb/76Kk+cu4tkVm2httU6XJiIiEnK0IcxrjPESCGHPBtcH079oDjLGMKP/DB477TG8Li8XvHQBf1r9J6zVZQE4vjCVpy8Zy8P/PQqf1819//6QVv3ZiIhIB3K0Iex3QDkQB7xujOkJHLpAlrS7QamD+OsZf2VS/iRmL5nNVQuvYkejLg0EguqJAzN54coJ/PnC4/G4XexqaObiR5ew9NPtTpcnIiLd3NE25t9vrc211p5mAz4FJke4NjlKiVGJ/KrkV1wz6hper3ydGc/NYPW21U6X1WG4XYacpBgAPqnZxbKNdfzXg2/zgz8tZt0WBVYREXHG0Tbm+40xc40xS4K/5hAYFZMOwhjD94q+xyNTH6G5tZnzF5zPkx88qenJgwzNT+L1a0u45pT+vLthO6fe9wZXzV9OQ7PupBQRkfZ1tNOR84CdwIzgrx3AI5EqSr66YRnDeOqMpzg++3h++c4v+dkbP2N3026ny+pQYqM8XDa5D29cO5kfTuzNroYWoj2BtYcbWhRaRUSkfRztYq29rbX/1ebxbV1126KuINmXzAMnPsDDZQ/zm/d/w9pta5lbMpe+yX2dLq1DSYqN4rpTB4RGC6vq9nL5q3vIf7+UIbl+Buf6GZKXxODcRGKjut9WUSIiEllHOxK21xhzwv4HxpjxwN7IlCTHgsu4uGjIRfz+5N+zs3En571wHv/8+J9Ol9UhGRNYYd9l4IzeXnqnx/Puhu3c/sJaZvzubV5atQWAjdv2MO/NDSwp386exubP+5QiIiJf6Gj/e38J8Kgxxh98/Bnw35EpSY6l0dmjefrMp7n29Wu56T83saxmGdePvh6fR3ssHizbH8OZvaMoKRkFQM3OfayqqmdwbuCv/Xvl2/nF82uAQGDrkxFPcW4SV5/Sj2x/jGN1i4hI53RUIcxauwIYaoxJDD7eYYy5ClgZyeLk2EiLSeOhkx/iwRUP8tDKh1i1dRVzJs2hwF/gdGkdWkaCjykDDoTVb43MY0LfNMoq61lZVU9ZZR2LPqzlpmkDAfi/0o959v1NDMnzU5zrpzgviQFZCfi8XXKvexER+Zq+VKNLcNX8/X4K3Htsy5FI8bg8XDH8CoZnDOf6N67n3BfO5dZxtzK1YKrTpXUqmYk+Mgf5OGlQJgDW2tB0Zm5SDJmJPv69toYnl1QCkBDt4f1bvoHbZVhcvp1oj4v+WQmhGwFERKT7+jrdxuYLTzBmKnAf4Ab+YK2ddYTz/gt4GjjOWrvka9QkX+CE3BN46oynuHrR1Vyz6BqWVS/j6lFXE+WOcrq0Tml/AAM4a1guZw3LxVrLpvp9lFXWUbuzAbcrcM6dC9ayfGMdXrdhQFYig3P9jOudyhlDc5wqX0REHPR1Qtjn3stvjHEDDwAnA5XAYmPMs9baNQedlwD8GHj3a9QiX0JWXBaPTH2Ee5fey6NrHqWstozZJbPJjc91urQuwRhDblIMuUnhfWL3nzucsqp6VlbWU1ZVxwsrN7FtV0MohF306BIyEqKD05lJ9M2Mx+s+2ntnRESks/ncEGaM2cnhw5YBvqgTeTTwsbV2ffBzzQfOAtYcdN4vgf8FrjmaguXY8Lq8XHPcNYzIGMHN/7mZ6c9N584T7qQkv8Tp0rqs/JRY8lNiOa04GwhMZe5qCNxl2djcyq59zbzzyTYef3cjAFEeFz8+sS+XTe5DS6vlo5qd9EmPx6NgJiLSJXxuCLPWJnyNz50LVLR5XAkc3/YEY8wIIN9a+4IxRiHMASf2PJF+yf2YuWgmV7x2BRcMvoArhl+B1+V1urQuzxhDgi/w5xzlcfHExWNobbWUb9tNWVU9ZZX1DMwOfAuur93F1HvfwOd1UZQTbPzP9TOhXxoZCbrTVUSkMzKR2tbGGPMtYKq19gfBx+cDx1trLw8+dgGvAd+31pYbY0qBqw/XE2aMuRi4GCAzM3Pk/PnzI1Lzfrt27SI+Pj6iX6OjabJNPLP9Gd7c9SaF0YVckHYBSZ4kp8tqdx312u9usqyobaG8voXyHa18uqOVhhb48Yhohmd4KK9v4a1NzRT43RQkusiKM7jMF7ZtShsd9dpL5Onad1/tce0nT5681Fo76nDPRTKEjQVutdaeEnx8PYC19q7gYz/wCbAr+JIsYDtw5uc1548aNcouWRLZ3v3S0lJKSkoi+jU6qhfWv8Btb9+Gz+1j1sRZjMsZ53RJ7aqzXPuWVsv62l1kJ8UQH+3h78sruf6ZMvY1tQIQH+2hKCeRe88dRrY/hr2NLUR7XLhcCmZH0lmuvRx7uvbdV3tce2PMEUNYJPdiWQz0Ncb0AqqAc4Hz9j9pra0H0toUWcoRRsKk/UwrnMbA1IHMLJ3JJa9cwiVDL+GHQ36I26UlFToSt8vQN/NAt8DZw/M4Y0gOn9TuZmVlHWVV9azetIPk2MBdr3Nf+YD571VQlJvIkLyk0HRmz9TYsDs8RUSk/UQshFlrm40xlwMvE1iiYp61drUx5hfAEmvts5H62vL1FPoLefy0x7nj3Tt4cMWDLK9ZzqwJs0iNSXW6NPkcHndgDbL+WQlMH5Uf9ty4PmnsbWqhrLKeP/6nnMaWVlLjolhy00kAPLdiE26XoTjXT15yjIKZiEg7iOiuxNbaBcCCg479/AjnlkSyFvlyYr2x3D7+dkZljuKOd+9g+nPTuWfSPYzMHOl0afIVTO6fweT+GUDgTswPq3dSu7MhFLYeWPgx67bsBCAp1ktxrp+TBmby3+MKnCpZRKTLi2gIk87NGMPZfc9mUOogZi6ayYUvX8gVwwN3ULqMlknorKI8rtB+mPv98/LxfLhlFyur6gLbMlXWs25LYIMMay0nzl1EfnIsQ/L8DM71MyTPT1aiTyNmIiJfg0KYfKH+Kf2ZP20+t7x1C/cuu5flNcu544Q78Ef7v/jF0ilEe9wU5/kpzvOHFpLZf9PO3qYWRvVMZmVlPf9XupWW1sDxq07qy1Un9WNfUwtvfLSVIXl+MhO1XIaIyNFSCJOjEh8Vz+xJs3li3RPcs+Qepj83nTmT5lCcXux0aRIh+0e5YqM83P2toQDsa2phzeYdlFXWMzQ/sITJ6k31XPRo4H6ativ+nz08lx6psc4ULyLSCSiEyVEzxnDewPMYkj6EmaUz+d5L3+PqUVdz3oDzNC3VTfi8bkb0SGZEj+TQsaIcP09fMpaVlfWsqqpnZVU9r66rYWzvVHqkxvL6h7X8+Z1PGZLrZ3Be4K7MtPhoB9+FiEjHoBAmX9rgtME8ecaT3PTmTcx6bxbLqpdx27jbiI/SYofdkc/rZlRBCqMKUkLHdjU0E+0J9A3u2NfEJzW7eGVNdej5HL+Pf1w+nowEH1vq9xHtcZEcp03kRaR7UQiTr8Qf7ef+Kffzx9V/5L5l97Fu+zrmlsylf0p/p0uTDiA++sCPltOH5HD6kBx27GtiddUOVlXVs3bLDtLiAqNhv3rlQ/66pIK85JhQ4//QvCTG90k70qcXEekSFMLkKzPGcMHgCxiaPpRrFl3DeS+cxw3H38A5fc/R9KQcItHnZWzvVMb2Dl9v7rzje1CYHsfK4H6ZC8q20CstjoVXlwDw20WfYIDiYEBL9GlfUxHpGhTC5GsbkTmCJ894kuveuI5b376VpdVLuWnMTcR61ZQtX2xoflKoyR+gbk8j1TsaQo9fWrWF9yvqQo97pcVx9vBcrjyxLwB7G1uIidKODiLS+SiEyTGRGpPKb0/6LQ+tfIgHVzzImm1rmFsyl8KkQqdLk04mKTaKpNgD/WH/uGw823c3UlYVbPyvrMMd3AOzsbmVYb/4F7nJMYHG/1w/Q/KSKMpJJC5aP95EpGPTTyk5ZtwuNz8a9iOGZQzjujeu49wXzuWWsbcwrXCa06VJJ5cSF8WkfulM6pcedryxpZXLJvdhZWU976zfzj/e3wTAz6YO4EclvflsdyP/eL+KIXl+BmX7NWImIh2KQpgcc2NzxvLUGU9xzaJruO6N61havZSfjf4Z0W4tSyDHVny0JzQtCVCzYx9lVfX0yQjcqVtWVc9tz60BwGWgb0YCxXl+LpnUO3SOiIhTFMIkIjJiM3j4lIf59fJfM2/VPFZtXcWcSXPIT8z/4heLfEUZiT5ObLNq/8R+6bx7w4msrKynrLKOsqp6Fq6r4aIJgWnyZ5ZV8vs3NlCcm4h3VxP2gxp6pcbRIyUWl0s3l4hIZCmEScR4XB5+MvInjMgYwQ1v3sCM52fwy/G/5KSeJzldmnQjmYk+Th7k4+RBmcCB7ZggcMdmekI0r6yp5rM9TTy+bjEAK37+DfyxXv6+vJIVFfX0SoujIC2OXqlx5CbHhHrSRES+DoUwibhJ+ZN48ownubr0an5S+hO+O/C7/HTkT/G6tdSAtL+2y6ecNCiTkwZlYq3l2X+VktN/KBXb9+CPDfzdXLd5J08uqWBPY0voNUmxXpbffDLGGJ5dsYn6vU30So2jIC2WHH+MRtBE5KgphEm7yI3P5dFTH2XO0jk8tvYxVm5dyeyJs8mOz3a6NBGMMfijDccVpHBcm5X/rz9tINedOoCanQ2Ub91N+bbd7GpoCQW5J97dyNvrt4XOj/K4mNAnjYe/fxwAr66tJibKTa+0ODITfApoIhJGIUzajdft5brR1zEiYwQ/f+vnTH9+OnedcBcT8iY4XZrIERljyEz0kZno4/jC8IVmH//B8VTv3MeGrbsp37qH8m27SfQd+LH683+upqpuLwA+r4ueKXGcVpzNj08K3EywfONn5CTFkJEQrQWORbohhTBpd98o+Ab9U/ozs3Qml756KRcVX8Slwy7F49JfR+lcXC5Dtj+GbH8M43of+vxffziG8q172LBtd2Akbetu9g+GNbe0Mv23b9PcaomNctMzNY5eabGcOTSHqYOzsdaydVcjafFRCmgiXZT+1RNH9EzsyWOnPcas92bx+7Lfs7xmOXdPvJv02PQvfrFIJ5GXHEteciwn9D38Ppjzvn8c5dt2B0fSdrNu806G5e8BoGZnA8ff+Srx0R4K0mIpSI2jV1ocUwdnUZTjD91goIAm0nkphIljfB4ft467lRGZI7j9nduZ/tx07p54N6OzRztdmkjEedwuJvZLZyKH/49HtMfFLWcMCvai7aGsqp4XVwX21SzK8bO8oo7/nvde4M7N1DgKUmMpSItjQt900hO0Jp9IZ6AQJo47s/eZDEoZxMxFM7nolYu4dOilXDTkIlzG5XRpIo5Jio3igvG9wo41NrdiCYyAJfq8nD08lw1bd7O84jOeX7mJVgtPXDSG9IRoXltXzX2vfkyvYDjbH9YGZCcQ7dHOASIdgUKYdAh9kvvwxLQn+MU7v+A37/+G5TXLuWvCXST7kp0uTaTDiPIc+I9Jn4x4fnHW4NDjhuYWKrbvJTcpBgCXMcRHu1lc/hn/XLGJ/cujlV5dQkFaHC+s3Myr66qDy2sEQlrP1FgSfFo6RqS9KIRJhxHrjeWuE+5iZOZIZr07i+nPTWf2pNkMyxjmdGkiHV60xx22FVNJ/wxK+mcAsK+phY3b97Bh627ykgMhbcuOfbz18TaeWVYVeo0xsPYXU/F53Ty3YhMbt+8JTHUGe9K0KbrIsaXvKOlQjDFM7zedotQiZpbO5IKXLuCqkVfxvUHfUwOyyFfk87rpl5lAv8yE0LELT+jFhSf0Ym9jC59uD9wYUL2jAZ83MFW5cF0NzyyvCvs8A7ISeOmqiQD8a/UWWq2lIDjNuf91InL0FMKkQxqUOognz3iSm/9zM7OXzGZp9VJuP+F2EqMSnS5NpEuJiXIzICuRAVnh31tzvz2MX35zMOXbDqyB1nbLp/te/YjVm3aEHmf7fUwekMGdZxcD8M76baTERdEjJVYBTeQIFMKkw0qISuBXJb/isbWPMXfJXGY8N4M5JXMoSi1yujSRbiEu2kNRjp+iHP8hz82/+NA10NLiokLP/+ixpXy2pwljIMcfQ0FaLKcOzua7Y3oCsGHrbnKTYsL63ES6G4Uw6dCMMZw/6HyGpA/h6kVXc/6C8/nZcT9jRv8Zmp4UcVCCz0txnp/ivEMDmrWWP14wOmwNtA3b9rB1VwMAextbmDy7FJeB3OSY0Bpopw7OZmzvVFpbLS3W4nUroEnXphAmncLQ9KE8dfpTXP/m9dz+7u0srVnKLWNvIc4b53RpInIQYwxD85MYmp90hOdh7oyhoXBWvnU3f19WRUFqHGN7p/Lp9j2cNHcReW0CWs/UWKYMyKBnqr7npetQCJNOI8mXxAMnPsC8VfP49fJfs3bbWuaUzKFfcj+nSxORL8HndXPOiLywY9ZaWloDPWcxXjeXlvQOjKJt283STz9jV0MzWYk+eqbG8e76bVz3TFlogdr9a6AN75GkJTakU1EIk07FZVz8oPgHDE381PMOAAAgAElEQVQfyrWvX8t3XvgON465kW/2+abTpYnI12CMweMOtBhk+X3M/Eb/0HP799GMiw40+Ed73QzMTmDD1j28s347e5taAPjHZeMZlp/Ev9dUM3/xxuDyGgdG0nL8MbhcamOQjkMhTDql47KO46kznuJnr/+Mm/9zM8uql3H98dcT44lxujQROcaMMWFbMQ3LT+L/vjMSCAS0mp0NbNi6m/7BJTh2NzZTsX0vb3y0lYbm1tDr3rvhRDISfSwo28z7FXWhNdBq97TS1NKqHjRpdwph0mmlxaTx0MkP8eCKB3lo5UOs2raKuZPmUuAvcLo0EWknxhgyE31kJvpCx84alstZw3JpbbVs2bGP8m27+XTbnlCQW1VVzx/fKqexTUC7+e2XWfuLqRhjePzdT9lQu5ucpJjgLx85STGkxWtPTjm2FMKkU3O73Fw+/HKGZQzj+jeu59vPf5vbxt3G1F5TnS5NRBzmcplQkBrX+8Dxa6cOYOY3+rO5fi/lW/fw6jvLyS3oHbrj+v2NdTy7YlPYKFqPlFhev3YyAHe9uJbanQ3kBj93tj/Qq9YrTTcNyJejECZdwgm5J/DUGU9xzaJruOb1a1havZRrjruGKHfUF79YRLodt8uQlxxLXnIszVVeSiYUhp67Z/pQ7v7WED7b08Smur1sqttLa5uFarfU7+O9Ddup3rGP4L0EHN8rhb/+cCwAFz+6hKaW1lAAzPb76J+VcNj11qR7UwiTLiMrLot5U+dx39L7+NOaP1G2tYzZk2aTl5D3xS8WEWnDGENKXBQpcVEMzg0PT/edOxyA5pZWqnc2sLlub1jDv8/rpqpuL+9X1PHZniYAvjksh3vPHY61lilzFpEY4yU3yUe2PxDSRhWkMCw/CWst1qIbCLoJhTDpUrwuL1cfdzXDM4dz85s3M+P5Gdwx/g4m95jsdGki0sV43C5yk2LITQq/Iej+/zc89PHexhY21e/FEwxVza2W0QUpbKrfywdbdrJwXS17m1r4UUlvhuUnsWNfM6NufyUUznKTYshO8nHSwEyG90imuaWVPU0tJGopji5BIUy6pBN7nEi/M/px9aKruXLhlVxQdAFXjLgCr0s/uESk/cREuemdHh967HW7+N9vDQk9ttZSv7cp7PGFJxSyqW4vm+v38u6G7WzZsY+sRB/DeyTzSe1uTrn3deKjPeQER9Jyknz8v9E9GJKXxO6GZrbuaiDL7yPaoz07OzqFMOmy8hPyefTUR7ln8T08svoR3q99n7sn3k1WXJbTpYmIAIFpz6TYA72rSbFRXHfqgLBzWlotza2BmwSSY73ceNpAqoK9apvr97Gqqp6TBmYC8F75di54ZDEAafHRwaAWWHetX2YCNTv2UVm3l9zg3Z5uTXs6KqIhzBgzFbgPcAN/sNbOOuj5S4DLgBZgF3CxtXZNJGuS7iXaHc1NY25iRMYIbn37VmY8N4NZE2YxLnec06WJiBwVt8vgdgVGtTISfVw0sfCI5w7MSmT29KGhkbSqun2sr90durHg32truOHvZQB4XIYsv48cfwxzvz2UvORYPqreycbte8j2B6ZZE2M82qc3giIWwowxbuAB4GSgElhsjHn2oJD1F2vtb4PnnwnMBbS2gBxzpxWexoDUAcwsnckl/76EHw79IZcMuST0g01EpCvI8vv41sgj34x00sAMsvyjqKrbx+bgaNqm+n3ERwfiwLMrNvHr1z4OnR8b5Sbb7+Ofl59AfLSHtz/ZRuVne8Lu/PR59XP0q4rkSNho4GNr7XoAY8x84CwgFMKstTvanB8HWEQipNBfyF+m/YU73rmD3674LctrljNrwizSYtKcLk1EpF1kJPqY0mZh24P9z/heTBmQweb6fcHlOfZRvXMfcVGBoPX00kr+tqwy7DW5STG8+bPJGGP4x/IqqnfsC1vkNiPBp2nPI4hkCMsFKto8rgSOP/gkY8xlwE+BKGBKBOsRIcYTw+0n3M7IzJHc8e4dzHhuBndPvJtRWaOcLk1ExHHJcVEkx0Ux/AjP33nOYK48sQ+b6vaFpjz3NbWGpiyfXbGJ19bVhL2mMD2O12aWAPDAwo/Zsa+JHP+BkbS85JiwvrjuxFgbmcEnY8y3gKnW2h8EH58PHG+tvfwI558HnGKt/e/DPHcxcDFAZmbmyPnz50ek5v127dpFfHz8F58onVpVYxXzauextXkrpyedzomJJ7Jn9x5d+25K3/fdl679sbWnybJ9n2X7vla27bW4XDApL3Bn+j2L9/LB9laa20SPgSkufjY6sMzHw2UNAKT4DKkxhhSfi6w4Q1pMZPb1bI9rP3ny5KXW2sP+Tz+SI2FVQH6bx3nBY0cyH3jwcE9Yax8CHgIYNWqULSkpOUYlHl5paSmR/hrSMZzVeBa3vn0rz5Y/S118HafFnKZr303p+7770rVvPyUl0Npq2ba7MTSSFhPlYVK/dAB+9+E7fFK7i9pNDewfI/qvEXnMOXUo1lrOefAtUuOigqNogSnPwbn+sGVAvgynr30kQ9hioK8xpheB8HUucF7bE4wxfa21HwUfTgM+QqQdxUfFc8/EexiVOYq7F9/NMpax9O2llOSXcHz28US7tWGviMix5HIZ0hOiSU+IZmh+UthzT1w8BoDG5laqdwSmPBOCC9M2NLeSHBtF5Wd7eW/Ddnbsawbgiil9mPmN/tTtaWTqvW8EluUILqKb7fdxQp80+mYmsH/mryPd7RmxEGatbTbGXA68TGCJinnW2tXGmF8AS6y1zwKXG2NOApqAz4BDpiJFIs0Yw7kDzqU4vZhZr83i+fXP89SHTxHriWV87ngm509mQu4EknxJX/zJRETka4vyuMhPiSU/JTZ0zOd1M+/7x4Ue72poZnPdXuJ9gSjT1GIZ3yeNzfV7WV1VzytrqmlsbuWOswfTNzOBNZt3cM7/vRXqRRtbmEqxwzd2RnSdMGvtAmDBQcd+3ubjH0fy64t8GUWpRVyYfiFjJ4zlvc3vsbBiIaUVpbzy6Su4jZvhGcOZnD+ZyT0mk5+Q/8WfUEREIiY+2kPfzITQ4/SEaObMGBp6bG1g2jPaE+gnS/R5+e9xBVTV7WVz3V627NhHcXK7lx1GK+aLHCTaHc2EvAlMyJvATWNuYs22Nby28TUWVizkniX3cM+Se+iT1CcQyPInU5RWhMtEpmlURES+GmMMafEHWkryU2K54bSBYeeUlpa2c1XhFMJEPofLuBicNpjBaYO5csSVVOysoLSilIUVC5m3ah6/L/s96THpTMqfxOT8yeojExGRo6YQJvIl5Cfkc/6g8zl/0PnUN9TzeuXrLKxYyIL1C3j6w6eJ8cQwPmc8k3tMZmLuRPWRiYjIESmEiXxF/mg/Z/Q+gzN6n0FDSwPvbX6P0opSSitK+ffGf4f6yEryS5iSP4X8RPWRiYjIAQphIsdA2z6yG8fcGOojK60sZfaS2cxeMjvUR1aSX8LgtMHqIxMR6eYUwkSOsSP1kZVWlKqPTEREQhTCRCJMfWQiInI4CmEi7ahtH1ljSyPvbXmPhRsXhvrIXMYVWo9MfWQiIl2bQpiIQ6LcUZyQewIn5J7AjWNuZO22tbxWEViPbH8fWW9/byb3CKxHpj4yEZGuRSFMpANwGRdFaUUUpRVxxfArqNxZGVqP7JFVj/CHsj+QFpPGpLxJTOkxRX1kIiJdgEKYSAeUl5DHdwd9l+8O+m6oj6y0opQXN7zI3z76W6iPrCS/hIl5E0n2Obz3hoiIfGkKYSId3OH6yPaPkh3cRzY5fzI9Ens4XbKIiBwFhTCRTiSsj+z44HpkFa9RWlF6SB9ZSX4JxWnF6iMTEemgFMJEOiljzGH7yEorSg/bRzY6azQ+j8/pskVEJEghTKSLOLiP7I2qN1i4cWFYH9m4nHFMzp+sPjIRkQ5AIUykC/JH+zm98HROLzydxpZGFm9ZzMKKhSysWMirG1/FZVwMSx/GlB5T1EcmIuIQhTCRLi7KHcX43PGMzx0f6CPbvoaFGxeGrUdW6C8MNPb3mKw+MhGRdqIQJtKNGGMoSi2iKLWIy4dfTuXOShZVLmLhxoX8cfUfeXjVw6T6UinJLwnta6k+MhGRyFAIE+nG8hLy+M7A7/Cdgd8J9ZGVVpTyUvlLYX1kJfklTMqbpD4yEZFjSCFMRIAv10dWkl9Cz8SeTpcsItKpKYSJyCG+TB9ZSX4JQ9KHqI9MRORLUggTkc91cB9Z1a6qwIr96iMTEflaFMJE5EvJjc8N6yN7s+pNFlYsDOsjG5s9lsk9JquPTETkcyiEichX5o/2M61wGtMKp9HY0siSLUtC2yi9VvFaqI9s//IX6iMTETlAIUxEjokodxTjcscxLndcqI9s/7TlnKVzmLN0DoX+wtC0pfrIRKS7UwgTkWOubR/ZZcMuO9BHVrGQR1c/yrxV80jxpYQC2ZjsMeojE5FuRyFMRCLucH1kpRWl/Kv8Xzzz0TOhPrKS/BIm5U8ixZfidMkiIhGnECYi7aptH1lTSxOLtyw+bB/Z/lGyAn+B0yWLiESEQpiIOMbr9ob1ka3dvjawQOzGhcxdOpe5S+fSy98r0NivPjIR6WIUwkSkQzDGMCh1EINSB3HZsMvYtGtTaMV+9ZGJSFekECYiHVJOfE6oj2xH4w7erAysR7a/j8zn9jE2ZyyT8yerj0xEOiWFMBHp8BKjEjmt8DROKzwt0EdWvTi0jdLCioUYDMMyhoWmLdVHJiKdgUKYiHQqXreXcTnjGJczjhuOv4G129eGlr9o20dWkl/ClPwpFKcV43a5nS5bROQQCmEi0mm17SO7dNiloT6y0opS/rz6zzyy6hFSfClMypsU6CPLGUOMJ8bpskVEAIUwEelCDtdHVlpRyiufvsLfP/57WB/ZxLyJpMakOl2yiHRjCmEi0iUdqY+stLL0kD6ykvwSp8sVkW5IIUxEurywPjJ7A+u2rws19e/vI0v1pDJ60WgGpw2mOL2YgSkDtQSGiESUQpiIdCvGGAamDmRg6kAuHXYpm3dtZmHFQl5c9SLLa5fzYvmLAHiMh77JfSlOKw4Es7Rievl7qclfRI6ZiIYwY8xU4D7ADfzBWjvroOd/CvwAaAZqgf+x1n4ayZpERNrKjs/mvIHnkVOdQ0lJCbV7ainbWsaqraso21rGgg0LePLDJwGI88ZRlFpEcVpxKJxlxmU6/A5EpLOKWAgzxriBB4CTgUpgsTHmWWvtmjanLQdGWWv3GGN+BNwNfDtSNYmIfJH02HSm9JjClB5TAGi1rZTvKGfV1lWsrF3Jqq2r+NOaP9Hc2gxARmxGKJANSRvCoNRBxEfFO/kWRKSTiORI2GjgY2vtegBjzHzgLCAUwqy1C9uc/w7w3QjWIyLypbmMi0J/IYX+Qs7sfSYADS0NrNu+LiyYvbrxVQAMhkJ/IcXpxaERsz7JffC6vE6+DRHpgIy1NjKf2JhvAVOttT8IPj4fON5ae/kRzv8NsMVae/thnrsYuBggMzNz5Pz58yNS8367du0iPl7/k+2OdO27r6977Xe37ObTxk/5tOFTyhvL2diwkV2tuwDwGi95UXkURBXQM7onPaN6kupJxRhzrMqXr0Hf991Xe1z7yZMnL7XWjjrccx2iMd8Y811gFDDpcM9bax8CHgIYNWqULSkpiWg9paWlRPprSMeka999Hetrb62lalcVZVvLQj1mb217i4U7AxMAydHJoTsxi9OKGZw6mCRf0jH7+nL09H3ffTl97SMZwqqA/DaP84LHwhhjTgJuBCZZaxsiWI+ISLsxxpCXkEdeQh6n9joVgKbWJj7+7OOwYPZm1ZtYAjMSPRJ6hO7ELE4vZkDKAKLd0U6+DRGJoEiGsMVAX2NMLwLh61zgvLYnGGOGA78jMG1ZE8FaREQc53V5Q8tjzOg/A4BdjbtYs20NK7cGesuWVC9hwYYFAHhcHvon9w8LZgWJBbiMy8m3ISLHSMRCmLW22RhzOfAygSUq5llrVxtjfgEssdY+C9wDxANPBXsjNlprz4xUTSIiHU18VDyjs0czOnt06Fj17urQEhllW8t47pPn+OsHfwUgwZtAUVrRgTsy04eQFpPmVPki8jVEtCfMWrsAWHDQsZ+3+fikSH59EZHOKDMuk8y4TE7seSIALa0tlO8oD92JWba1jHmr5tFiWwDIissKW7usKLWIWG+sk29BRI5Ch2jMFxGRI3O73PRO6k3vpN6c3fdsAPY172Pd9nVhweyVT18BAstq9E7qHQpmxWnF9E7qjcelH/kiHYm+I0VEOiGfx8ewjGEMyxgWOrZ93/awacxXN77KMx89A0CMJ4aBKQMDo2XpgYVls+OytUyGiIMUwkREuogUXwoT8yYyMW8iEFgmo2JnRehOzJVbV/LEuidoXNMYOr/taFlRWhH+aL+Tb0GkW1EIExHpoowx9EjsQY/EHkwrnAZAU0sTH372YWi0rGxrGYsqF4VeU5BYcOBuzLRi+qf0J8od5dRbEOnSFMJERLoRr9tLUVoRRWlFnMu5AOxs3Mnqbaspqw2Esnc2v8Pz658PnO/yMiBlQFgw65nYU9OYIseAQpiISDeXEJXAmOwxjMkeAwSmMav3VAdGyoLB7B8f/4Mn1j0ROr/tpuWD0waTGpPq5FsQ6ZQUwkREJIwxhqy4LLLisji558lAYJmMT+o/Cdu0/A9lf6DVtgKQE5dzYAumtMEMSh1EjCfGybch0uEphImIyBdyu9z0S+5Hv+R+nNP3HAD2NO1h7fa1B+7IrC3j5fKXA+cbN32S+oQFs97+3rhdbiffhkiHohAmIiJfSaw3lpGZIxmZOTJ0bOveraFQtmrrKl4uf5mnP3waCCyTUZRaFNqCqTitmMzYTPWXSbelECYiIsdMWkwaJfkllOSXANBqW9m4Y2PYpuWPrX2MptVNAKTHpIftjVmUWkRCVIKD70Ck/SiEiYhIxLiMiwJ/AQX+As7ofQYAjS2NfLD9g7BgtrBiYeg1vfy9Dqxfll5Mv6R+eN1ep96CSMQohImISLuKckcFpiPTi0PH6hvqWb11dSiYvVn1Js9+8mzgfFcUA1IHhO7ELE4rJj8hX9OY0ukphImIiOP80X7G5Y5jXO44ILBMxubdm1m5dSWragM9Zk9/+DSPrX0sdH7bJTIGpw0mxZfi5FsQ+dIUwkREpMMxxpATn0NOfA5TC6YC0NzazCd1nwSCWbD5/3crfxdaJiMvPu/A+mXpQxiQMgCfx+fk2xD5XAphIiLSKXhcHvqn9Kd/Sn+m95sOwO6m3azZtiYUypbXLufF8hcD5xsPfZP7hgWzXv5euIzLybchEqIQJiIinVacN47jso7juKzjQsdq99SGbVq+YMMCnvzwydD5oWUy0sL70kTam0KYiIh0Kemx6UzpMYUpPaYAgWUyyneUh7ZgKttaxp9W/4lm2wxAvCuefi/2ozCpkEJ/4Fcvfy+y4rI0aiYRpRAmIiJdmsu4QuHqrD5nAdDQ0sC67esoqy3j9bWvs499vPLpK9Q31IdeF+OJoSCx4JBw1iOhh5bMkGNCIUxERLqdaHc0Q9OHMjR9KHk1eZSUlGCtZfu+7ayvX8+G+g1sqN/A+vr1LK1eygvrXwi91mM85CXkBYJZ0oFw1svfizhvnIPvSjobhTARERECd2SmxqSSGpMa1mMGgX0y94ey/b+vr1/P65Wvh6Y1ATJjM0PhrFdir8Dv/l6k+lK1rpkcQiFMRETkC8R6YylKK6IorSjseFNrExU7K9hQdyCYra9fzzMfPcPe5r2h8xKjEg8bznLicrSpeTemECYiIvIVeV3eUL/YiZwYOt5qW6nZU8P6uvVh4ay0opRn9j0TOi/aHR3oO9s/pZnUi0J/IQWJBUS5o5x4S9KOFMJERESOMZdxkRWXRVZcVmgXgP3q9tWxYceGsIC2cutKXip/CYsNvT4vPi+s32x//5k2OO86FMJERETaUZIvieG+4QzPGB52fG/zXj7d8WlYONtQv4H/bPoPTa1NofPSY9IDo2X+grCbA9Jj0tV31skohImIiHQAMZ4YBqQMYEDKgLDjza3NVO2qCgtn5fXlvLD+BXY17QqdF++NDw9nwYCWG5+Lx6V/7jsiXRUREZEOzOPy0DOxJz0TezKZyaHj1lpq99YGglndgWU13t70Ns9+8mzoPK/LS8/EnoEpzTbhrCCxQHtrOkwhTEREpBMyxpARm0FGbAZjsseEPbejcUdgKY269WzYsYENdRv4YPsHvLrx1dCG54bAJukHh7NCfyH+aL8Tb6nbUQgTERHpYhKjEkOL0bbV0NIQ6DvbvyBtcGmNxVsW09DSEDovxZcSHs6CAS0zNlN9Z8eQQpiIiEg3Ee2Opl9yP/ol9ws73tLawqbdm8J2Clhft56Xy19mR+OO0HkxnphDwlkvfy/yE/PxurSV05elECYiItLNuV1u8hPyyU/IZ2LexNBxay3b9m07JJwt3rKY59c/HzrPYzzkJ+aHBbP9v8d6Y514S52CQpiIiIgcljGGtJg00mLSDtnKaXfTbsrryw8sRlu3nk/qPqG0opQW2xI6LysuKyyc7Q9oKb6Ubj+1qRAmIiIiX1qcN+7wWzm1BLZyartTwPq69fyt5m9hWzn5o/2HDWc58Tm4jKu9344jFMJERETkmPG6vYG7LJMKw4632laqd1cfEs4WVizkbx/9LXSez+2jwF8QNqVZ6C+kZ2LPLreVk0KYiIiIRJzLuMiOzyY7PpvxuePDnqvbVxcWzjbUb2Bl7Upe3PBi6By3cZOXkBc2arY/pHXWrZwUwkRERMRRSb4kRvhGMCJzRNjxvc17w/rO9t8g8GbVmzS3NofOy4jJoFdSL3olHthjs9BfSFpMWofuO1MIExERkQ4pxhPDwNSBDEwdGHa8ubWZyp2Vh4Sz59Y/x+6m3aHzErwJhw1nufG5uF3u9n47h1AIExERkU7F4/JQ4C+gwF/AFKaEjltrqdlTEwpmbTdB/+cn/wydt38rp7HusZRQ4sA7CIhoCDPGTAXuA9zAH6y1sw56fiJwLzAEONda+3Qk6xEREZGuyxhDZlwmmXGZjM0ZG/bcjsYdYXtsrq9fT9Q+Zxv9IxbCjDFu4AHgZKASWGyMedZau6bNaRuB7wNXR6oOERERkcSoRIZlDGNYxrDQsdLSUucKIrIjYaOBj6216wGMMfOBs4BQCLPWlgefa41gHSIiIiIdTiRDWC5Q0eZxJXD8V/lExpiLgYsBMjMzI55cd+3a5Xg6Fmfo2ndfuvbdl6599+X0te8UjfnW2oeAhwBGjRplS0pKIvr1SktLifTXkI5J17770rXvvnTtuy+nr30k9wWoAvLbPM4LHhMRERHp9iIZwhYDfY0xvYwxUcC5wLMR/HoiIiIinUbEQpi1thm4HHgZWAs8aa1dbYz5hTHmTABjzHHGmEpgOvA7Y8zqSNUjIiIi0pFEtCfMWrsAWHDQsZ+3+XgxgWlKERERkW4lktORIiIiInIECmEiIiIiDlAIExEREXGAQpiIiIiIAxTCRERERBygECYiIiLiAGOtdbqGL8UYUwt8GuEvkwZsjfDXkI5J17770rXvvnTtu6/2uPY9rbXph3ui04Ww9mCMWWKtHeV0HdL+dO27L1377kvXvvty+tprOlJERETEAQphIiIiIg5QCDu8h5wuQByja9996dp3X7r23Zej1149YSIiIiIO0EiYiIiIiAMUwtowxswzxtQYY1Y5XYu0L2NMvjFmoTFmjTFmtTHmx07XJO3DGOMzxrxnjFkRvPa3OV2TtB9jjNsYs9wY87zTtUj7McaUG2PKjDHvG2OWOFaHpiMPMMZMBHYBj1prBztdj7QfY0w2kG2tXWaMSQCWAt+01q5xuDSJMGOMAeKstbuMMV7gTeDH1tp3HC5N2oEx5qfAKCDRWnu60/VI+zDGlAOjrLWOrg+nkbA2rLWvA9udrkPan7V2s7V2WfDjncBaINfZqqQ92IBdwYfe4C/977QbMMbkAdOAPzhdi3RPCmEiBzHGFADDgXedrUTaS3BK6n2gBnjFWqtr3z3cC1wLtDpdiLQ7C/zLGLPUGHOxU0UohIm0YYyJB/4GXGWt3eF0PdI+rLUt1tphQB4w2hijdoQuzhhzOlBjrV3qdC3iiBOstSOAU4HLgu1I7U4hTCQo2A/0N+Bxa+0zTtcj7c9aWwcsBKY6XYtE3HjgzGBv0HxgijHmMWdLkvZira0K/l4D/B0Y7UQdCmEihJqzHwbWWmvnOl2PtB9jTLoxJin4cQxwMrDO2aok0qy111tr86y1BcC5wGvW2u86XJa0A2NMXPAGLIwxccA3AEdWRVAIa8MY8wTwNtDfGFNpjLnQ6Zqk3YwHzifwv+H3g79Oc7ooaRfZwEJjzEpgMYGeMC1XINJ1ZQJvGmNWAO8BL1hrX3KiEC1RISIiIuIAjYSJiIiIOEAhTERERMQBCmEiIiIiDlAIExEREXGAQpiIiIiIAxTCRKRLMca0tFlm5H1jzHXH8HMXGGMcWU9IRLoej9MFiIgcY3uDWxCJiHRoGgkTkW7BGFNujLnbGFNmjHnPGNMneLzAGPOaMWalMeZVY0yP4PFMY8zfjTErgr/GBT+V2xjze2PMamPMv4Kr7IuIfGkKYSLS1cQcNB357TbP1Vtri4HfAPcGj/0a+JO1dgjwOHB/8Pj9wCJr7VBgBLA6eLwv8IC1tgioA/4rwu9HRLoorZgvIl2KMWaXtTb+MMfLgSnW2vXBzdq3WGtTjTFbgWxrbVPw+GZrbZoxphbIs9Y2tPkcBQS2NeobfPwzwGutvT3y70xEuhqNhIlId2KP8PGX0dDm4xbUWysiX5FCmIh0J99u8/vbwY/fAs4Nfvwd4I3gx68CPwIwxriNMf72KlJEugf9D05EupoYY8z7bR6/ZK3dv0xFsjFmJYHRrP8XPHYF8Igx5hqgFrggePzHwEPGmAsJjHj9CDYKApYAAABbSURBVNgc8epFpNtQT5iIdAvBnrBR1tqtTtciIgKajhQRERFxhEbCRERERBygkTARERERByiEiYiIiDhAIUxERETEAQphIiIiIg5QCBMRERFxgEKYiIiIiAP+P0fkXgKeAghaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Ps3CauIM2S"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pETWPIe362y"
      },
      "source": [
        "--------\n",
        "# 3. LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeG4BPnJ9uCI"
      },
      "source": [
        "Using sequential models to generate text data is a very popular application of recursive deep learning models. A couple of popular applications are [**chat bots**](https://hackernoon.com/deep-learning-chatbot-everything-you-need-to-know-r11jm30bc) and language translators such as [**google translate**](https://ai.googleblog.com/2020/06/recent-advances-in-google-translate.html). \n",
        "\n",
        "In order to properly build a chat bot or translater you need to use multiple lstm models in an encoder & decoder framwork known as a [**sequence 2 sequence model**](https://keras.io/examples/nlp/lstm_seq2seq/) .\n",
        "\n",
        "\n",
        "![](https://jeddy92.github.io/images/ts_intro/seq2seq_lang.png)\n",
        "\n",
        "Also, now a days, using a standard LSTM isn't enough. You also have to use a version of lstm seq2seq models known as [**transformers**](https://towardsdatascience.com/transformers-141e32e69591). Transformers give seq2seq models the capacity to pay attention to specific portions of the input sequence, the most relevent portion in order to make a prediction. Yes, that's right, humanity has figured out how to convert attention into an algorithm. Next stop, self-awareness! \n",
        "\n",
        "The above mentions of sequence 2 sequence models and transformers are for a larger contextual understanding of the landscape of language models and how LSTMs fit into this landscape. Although **we will cover the encoder/decoder framework in a future lesson, transformers are outside the scope of Unit 4**. However, once you learn about LSTMs and encoder/decoder frameworks, you will have all necessary information to then go on and learn about transformers on your own. At that point, the only really new bit you'll be learning is the [**attention mechanism**](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f). \n",
        "\n",
        "\n",
        "As a first pass at text generation, we'll stick to standard LSTM models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK-GrUGvIM2T"
      },
      "source": [
        "-----\n",
        "# Text Generation using LSTMs\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. <br>\n",
        "For this exercise, we'll use news articles from the [newspaper](https://github.com/codelucas/newspaper/)  database.\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q64qHEYIIM2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4defe25-45e7-4021-a1c3-e8bb27a73b2a"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# import a custom text data preparation class\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
        "from data_cleaning_toolkit_class import data_cleaning_toolkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 17:48:12--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/data_cleaning_toolkit_class.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6666 (6.5K) [text/plain]\n",
            "Saving to: data_cleaning_toolkit_class.py\n",
            "\n",
            "data_cleaning_toolk 100%[===================>]   6.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-11 17:48:12 (70.4 MB/s) - data_cleaning_toolkit_class.py saved [6666/6666]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "MxcXsdsSIM2W",
        "outputId": "1b325ed1-1546-4b99-cb0d-7082c5b70be2"
      },
      "source": [
        "# load text data (articles)\n",
        "df = pd.read_json('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/main/module1-rnn-and-lstm/wp_articles.json')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Contributing columnist\\n\\nThe House is on fire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When President Trump announced his decision to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Russian President Vladimir Putin speaks at a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>The Queens Speech is designed to acknowledg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Like an aging rock star, the president is now ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               article\n",
              "0    Contributing columnist\\n\\nThe House is on fire...\n",
              "1    When President Trump announced his decision to...\n",
              "10   Russian President Vladimir Putin speaks at a s...\n",
              "100  The Queens Speech is designed to acknowledg...\n",
              "101  Like an aging rock star, the president is now ..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOYH4CjWJRk"
      },
      "source": [
        "How many articles are in the database?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjXfqs1IPyoS",
        "outputId": "d6729a66-5c3a-496a-e558-af8aa256383d"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHz9fsXBXz4a"
      },
      "source": [
        "Clean the documents<br>\n",
        "Chop them into text strings of length 20 characters<br>\n",
        "Create X and y split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-292d1e2b08c74976",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Ku2t609uCK",
        "outputId": "91641755-9ddc-4fb4-d447-06c33c18cd9d"
      },
      "source": [
        "###BEGIN SOLUTION \n",
        "# instantiate data cleaning toolkit\n",
        "dctk = data_cleaning_toolkit()\n",
        "\n",
        "# use regex to clean documents\n",
        "df[\"clean_data\"] = df.article.apply(lambda text: dctk.clean_data(text))\n",
        "\n",
        "# move docs to array\n",
        "#data = df['article'].values\n",
        "data = df['clean_data'].values\n",
        "\n",
        "# amount of chars in each doc vector \n",
        "doc_len = 20\n",
        "\n",
        "# numerically encode documents\n",
        "dctk.create_char_sequences(data, doc_len)\n",
        "\n",
        "# create X and Y split\n",
        "x, y = dctk.create_X_and_Y()\n",
        "###END SOLUTION "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 168985 sequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u85xmG7QcYp2"
      },
      "source": [
        "Here is the first article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "wfbpmXNZOrS3",
        "outputId": "11d0ec46-8642-4550-a3d6-3d0542680bac"
      },
      "source": [
        "(df['article'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Contributing columnist\\n\\nThe House is on fire. And with each passing day, Donald Trump defiles the office of the president. If only past defrocked presidents could provide a roadmap for this firestorm.\\n\\nAndrew Johnson fought impeachment vigorously and survived removal, but never won reelection. Richard Nixon got in the way of justice, but eventually bowed to the rule of law, accepting his asterisk in the annals of history and resigning before certain removal. Bill Clinton expressed contrition, went on to complete his presidency with high approval ratings and has remained a popular former president.\\n\\nIf you care about democracy, the rule of law and nearly 250 years of constitutional governance, take heed. President Trump is no Clinton or Nixon, or even Johnson. He will not go quietly. It will be ugly. He will betray us and the rule of law in the process  defying subpoenas, withholding documents, blocking witnesses.\\n\\nThis presidency is fouled with disrespect for rules, boundaries and norms. Trump walked away from major agreements negotiated by his predecessors  the Iran nuclear deal, the Paris climate accord  and the United States word as bond is no more. Look at the ease with which he discards supporters  ask former attorney general Jeff Sessions or former secretary of state Rex Tillerson. Ask our allies, here today, gone tomorrow  NATO, the Kurds in Syria.\\n\\nFrom his earliest days as a candidate, Trump voiced appallingly arrogant views about the power of the presidency: Mexico will pay for the wall! ; I alone can fix it; My primary consultant is myself. His possessiveness over people and institutions is also not new: my generals and my military, my African American.\\n\\nOnly months into his presidency, Trump disparaged democratic allies, including Germanys Angela Merkel (ruining Germany) and Britains Theresa May (foolish)  notably, both women  in favor of strong-arm leaders such as North Koreas Kim Jong Un (who wrote him beautiful letters), Saudi Arabias Mohammed bin Salman (very good ally), Turkeys Recep Tayyip Erdogan (great friendship) and the Philippines Rodrigo Duterte (great relationship). Trump heaps praise on Russias Vladimir Putin (hes a strong leader). And, days after revealing his words pressuring Ukrainian President Volodymyr Zelensky to dig up dirt on his opponent, he invited China to do it, too.\\n\\nTrumps campaign for the White House was rotten from the beginning. We glimpsed its depths when his lawyer Michael Cohen pleaded guilty to campaign finance felonies and identified Trump as Individual 1 in a conspiracy to pay off an adult-film star and a former Playboy model to silence them during the height of the 2016 presidential campaign. We got even more evidence of Trumps deception in the dense report prepared by special counsel Robert S. Mueller III on Russias interference in the 2016 election to benefit Trump and try to defeat Hillary Clinton. Mueller laid the groundwork for at least 10 acts of obstruction of justice.\\n\\nEven with all of that, its this still-unraveling Ukraine story that makes clear the bits and pieces that we could only imagine with Trumps pleas to Russia, if youre listening . . . . We have the same threats, lies, subterfuge and obstruction  only this time, we have the presidents unambiguous words to Zelensky: I would like you to do us a favor though. Ukraine represents the same lawlessness that propelled Trump over the finish line in 2016: this time in plain sight, with witnesses, including at least one whistleblower and lots of bit players. From the State Department to the Energy Department to the Justice Department and throughout the White House, Trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening Russian neighbor  all to get manufactured dirt on a political opponent.\\n\\nIts illegal. The evidence is bearing fruit. The time will come. And justice will be served.\\n\\nThe presidents personal approval rating remains low, though stable, but there is growing support for impeachment  a Fox News poll this week found that 51 percent support removing Trump from office. Independents, as well as Democrats, mostly support the impeachment inquiry, while Republicans are mostly holding tight. These things may or may not change.\\n\\nEither way, we will be changed if we do not right this ship of democracy.\\n\\nImpeachment is not about punishment. Impeachment is about cleansing the office. Impeachment is about restoring honor and integrity to the office. We should heed these words, spoken by the 1999 version of Sen. Lindsey O. Graham (R-S.C.). The fire did not start with Ukraine. Nonetheless, Ukraine may give us the water to finally put it out.\\n\\nRead more from Donna F. Edwards's archive.\""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lgPUix2ccTn"
      },
      "source": [
        "Here is the cleaned version of the first article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "aaolsuFXO_LL",
        "outputId": "f0518bcc-4d3e-4528-9672-937fda57bf1f"
      },
      "source": [
        "df['clean_data'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'contributing columnistthe house is on fire and with each passing day donald trump defiles the office of the president if only past defrocked presidents could provide a roadmap for this firestormandrew johnson fought impeachment vigorously and survived removal but never won reelection richard nixon got in the way of justice but eventually bowed to the rule of law accepting his asterisk in the annals of history and resigning before certain removal bill clinton expressed contrition went on to complete his presidency with high approval ratings and has remained a popular former presidentif you care about democracy the rule of law and nearlyyears of constitutional governance take heed president trump is no clinton or nixon or even johnson he will not go quietly it will be ugly he will betray us and the rule of law in the processdefying subpoenas withholding documents blocking witnessesthis presidency is fouled with disrespect for rules boundaries and norms trump walked away from major agreements negotiated by his predecessorsthe iran nuclear deal the paris climate accordand the united states word as bond is no more look at the ease with which he discards supportersask former attorney general jeff sessions or former secretary of state rex tillerson ask our allies here today gone tomorrownato the kurds in syriafrom his earliest days as a candidate trump voiced appallingly arrogant views about the power of the presidency mexico will pay for the walli alone can fix it my primary consultant is myself his possessiveness over people and institutions is also not new my generals and my military my african americanonly months into his presidency trump disparaged democratic allies including germanys angela merkel ruining germany and britains theresa may foolishnotably both womenin favor of strongarm leaders such as north koreas kim jong un who wrote him beautiful letters saudi arabias mohammed bin salman very good ally turkeys recep tayyip erdogan great friendship and the philippines rodrigo duterte great relationship trump heaps praise on russias vladimir putin hes a strong leader and days after revealing his words pressuring ukrainian president volodymyr zelensky to dig up dirt on his opponent he invited china to do it tootrumps campaign for the white house was rotten from the beginning we glimpsed its depths when his lawyer michael cohen pleaded guilty to campaign finance felonies and identified trump as individualin a conspiracy to pay off an adultfilm star and a former playboy model to silence them during the height of thepresidential campaign we got even more evidence of trumps deception in the dense report prepared by special counsel robert s mueller iii on russias interference in theelection to benefit trump and try to defeat hillary clinton mueller laid the groundwork for at leastacts of obstruction of justiceeven with all of that its this stillunraveling ukraine story that makes clear the bits and pieces that we could only imagine with trumps pleas to russia if youre listeningwe have the same threats lies subterfuge and obstructiononly this time we have the presidents unambiguous words to zelensky i would like you to do us a favor though ukraine represents the same lawlessness that propelled trump over the finish line inthis time in plain sight with witnesses including at least one whistleblower and lots of bit players from the state department to the energy department to the justice department and throughout the white house trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening russian neighborall to get manufactured dirt on a political opponentits illegal the evidence is bearing fruit the time will come and justice will be servedthe presidents personal approval rating remains low though stable but there is growing support for impeachmenta fox news poll this week found thatpercent support removing trump from office independents as well as democrats mostly support the impeachment inquiry while republicans are mostly holding tight these things may or may not changeeither way we will be changed if we do not right this ship of democracyimpeachment is not about punishment impeachment is about cleansing the office impeachment is about restoring honor and integrity to the office we should heed these words spoken by theversion of sen lindsey o graham rsc the fire did not start with ukraine nonetheless ukraine may give us the water to finally put it outread more from donna f edwardss archive'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE86rmUicjM_"
      },
      "source": [
        "The `data` is an array containing the articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "mljIx-NSPX3E",
        "outputId": "6ac81b23-f9d0-4cb6-f5ea-7e17d102694c"
      },
      "source": [
        "print(len(data))\n",
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'contributing columnistthe house is on fire and with each passing day donald trump defiles the office of the president if only past defrocked presidents could provide a roadmap for this firestormandrew johnson fought impeachment vigorously and survived removal but never won reelection richard nixon got in the way of justice but eventually bowed to the rule of law accepting his asterisk in the annals of history and resigning before certain removal bill clinton expressed contrition went on to complete his presidency with high approval ratings and has remained a popular former presidentif you care about democracy the rule of law and nearlyyears of constitutional governance take heed president trump is no clinton or nixon or even johnson he will not go quietly it will be ugly he will betray us and the rule of law in the processdefying subpoenas withholding documents blocking witnessesthis presidency is fouled with disrespect for rules boundaries and norms trump walked away from major agreements negotiated by his predecessorsthe iran nuclear deal the paris climate accordand the united states word as bond is no more look at the ease with which he discards supportersask former attorney general jeff sessions or former secretary of state rex tillerson ask our allies here today gone tomorrownato the kurds in syriafrom his earliest days as a candidate trump voiced appallingly arrogant views about the power of the presidency mexico will pay for the walli alone can fix it my primary consultant is myself his possessiveness over people and institutions is also not new my generals and my military my african americanonly months into his presidency trump disparaged democratic allies including germanys angela merkel ruining germany and britains theresa may foolishnotably both womenin favor of strongarm leaders such as north koreas kim jong un who wrote him beautiful letters saudi arabias mohammed bin salman very good ally turkeys recep tayyip erdogan great friendship and the philippines rodrigo duterte great relationship trump heaps praise on russias vladimir putin hes a strong leader and days after revealing his words pressuring ukrainian president volodymyr zelensky to dig up dirt on his opponent he invited china to do it tootrumps campaign for the white house was rotten from the beginning we glimpsed its depths when his lawyer michael cohen pleaded guilty to campaign finance felonies and identified trump as individualin a conspiracy to pay off an adultfilm star and a former playboy model to silence them during the height of thepresidential campaign we got even more evidence of trumps deception in the dense report prepared by special counsel robert s mueller iii on russias interference in theelection to benefit trump and try to defeat hillary clinton mueller laid the groundwork for at leastacts of obstruction of justiceeven with all of that its this stillunraveling ukraine story that makes clear the bits and pieces that we could only imagine with trumps pleas to russia if youre listeningwe have the same threats lies subterfuge and obstructiononly this time we have the presidents unambiguous words to zelensky i would like you to do us a favor though ukraine represents the same lawlessness that propelled trump over the finish line inthis time in plain sight with witnesses including at least one whistleblower and lots of bit players from the state department to the energy department to the justice department and throughout the white house trump is using every bit of the machinery of government and personnel at his disposal to strongarm a small country under the heel of its threatening russian neighborall to get manufactured dirt on a political opponentits illegal the evidence is bearing fruit the time will come and justice will be servedthe presidents personal approval rating remains low though stable but there is growing support for impeachmenta fox news poll this week found thatpercent support removing trump from office independents as well as democrats mostly support the impeachment inquiry while republicans are mostly holding tight these things may or may not changeeither way we will be changed if we do not right this ship of democracyimpeachment is not about punishment impeachment is about cleansing the office impeachment is about restoring honor and integrity to the office we should heed these words spoken by theversion of sen lindsey o graham rsc the fire did not start with ukraine nonetheless ukraine may give us the water to finally put it outread more from donna f edwardss archive'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-8sI4cQv6V"
      },
      "source": [
        "We are chopping each of the 136 documents into 20-character sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufh4culCPqSm",
        "outputId": "f6820af8-955a-4cc0-808c-71d9ee9d41e6"
      },
      "source": [
        "type(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMJb8pGbPunF",
        "outputId": "071d2708-d198-4c3d-c6fb-1a77fbdb82d6"
      },
      "source": [
        "len(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168985"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00qvtpw7c_md",
        "outputId": "86846687-15c5-4538-94c3-9026905968c6"
      },
      "source": [
        "len(x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biFs5ynnWcQO"
      },
      "source": [
        "How is a single character in a sequence represented?<br>\n",
        "-- say, the 10th character in the first sequence?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3GENwB2P477",
        "outputId": "7fafc472-37d1-4e38-8815-02fe0e63d214"
      },
      "source": [
        "print(len(x[0][10]))\n",
        "x[0][10]\n",
        "print(sum(x[0][10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzYuQI60YWnG"
      },
      "source": [
        "Each character is represented as a one-hot encoded vector of length 27, with <br>\n",
        "positions corresponding to the \"vocabulary\" of all the possible characters. <br>\n",
        "There are 27 possible characters, including the space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6a39513d81d87f1b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IOK_p3U9uCL",
        "outputId": "003f55b9-3594-4a0b-9c6b-076b5abc38cd"
      },
      "source": [
        "###BEGIN SOLUTION\n",
        "# this is our encoded doc-term matrix \n",
        "dtm = dctk.sequences\n",
        "\n",
        "# each doc is maxlen values long \n",
        "print(len(dctk.sequences[0]))\n",
        "\n",
        "# want to know what this encoded document actually says?\n",
        "# you'll need to the char-int look up dictionaries \n",
        "print(dctk.sequences[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "[23, 8, 15, 5, 19, 3, 14, 7, 5, 3, 15, 11, 6, 23, 8, 16, 7, 2, 15, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laJUQImBSVJI",
        "outputId": "14e6c5de-901e-44f0-de28-c35d676f3b07"
      },
      "source": [
        "# character to index dictionary\n",
        "# keys are chars\n",
        "# vlaues are ints\n",
        "print(dctk.char_int)\n",
        "\n",
        "# index to char dictionary\n",
        "# keys are ints\n",
        "# values are chars\n",
        "print(dctk.int_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'p': 0, 'a': 1, 'm': 2, 'i': 3, 'h': 4, 't': 5, ' ': 6, 'u': 7, 'o': 8, 'k': 9, 'j': 10, 'g': 11, 'y': 12, 'x': 13, 'b': 14, 'n': 15, 'l': 16, 'f': 17, 'w': 18, 'r': 19, 'v': 20, 'z': 21, 'q': 22, 'c': 23, 'd': 24, 's': 25, 'e': 26}\n",
            "{0: 'p', 1: 'a', 2: 'm', 3: 'i', 4: 'h', 5: 't', 6: ' ', 7: 'u', 8: 'o', 9: 'k', 10: 'j', 11: 'g', 12: 'y', 13: 'x', 14: 'b', 15: 'n', 16: 'l', 17: 'f', 18: 'w', 19: 'r', 20: 'v', 21: 'z', 22: 'q', 23: 'c', 24: 'd', 25: 's', 26: 'e'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUOiUSCuVyrS"
      },
      "source": [
        "#### Check that the character encoding works properly\n",
        "Use the integer-to-character dictionary to map the integer character encodings back to the characters they represent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jb_oqtoSKY9",
        "outputId": "2271b779-0146-4898-8137-4a114bcf30fa"
      },
      "source": [
        "# now we can check to see that our encoding is correct \n",
        "for ind in dctk.sequences[0]:\n",
        "    print (dctk.int_char[ind])\n",
        "    \n",
        "# number of features is the total number of unique chars in our corpos \n",
        "dctk.n_features\n",
        "\n",
        "# (num_seqs, num features)\n",
        "###END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9hrvWPun6xw"
      },
      "source": [
        "Each successive string starts with the 5th character of the last"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QN7InnwnnAJ",
        "outputId": "660610f1-fa4f-48b8-8541-03316788629f"
      },
      "source": [
        "for ind in dctk.sequences[1]:\n",
        "    print (dctk.int_char[ind])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i\n",
            "b\n",
            "u\n",
            "t\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "c\n",
            "o\n",
            "l\n",
            "u\n",
            "m\n",
            "n\n",
            "i\n",
            "s\n",
            "t\n",
            "t\n",
            "h\n",
            "e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed-GMMsU9uCL",
        "outputId": "798f222f-ec04-43aa-bd69-d92e0f400bc7"
      },
      "source": [
        "# (num_seqs, seq length, num features)\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(168985, 20, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkopT0P2dycm"
      },
      "source": [
        "The training labels are encodings of a single character.<br>\n",
        "But what is this character?<br>\n",
        "We are building a language model to predict the next character in a sequence, <br>\n",
        "so each y corresponds to the next character after the 20th character of x!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mUItxKgGlkW",
        "outputId": "95f0c27f-7d47-4d5d-a552-699baf2e301e"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(168985, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Jxlm53Go4e",
        "outputId": "ef06cfba-ee91-4620-959b-3b8cab180f86"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False,  True, False,\n",
              "       False, False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_vesjxzejxT"
      },
      "source": [
        "Let's check this:<br>\n",
        "y[0] should correspond to the first character of x[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bbhYydZpd_v"
      },
      "source": [
        "The code that generates `x` and `y` is in `data_cleaning_toolkit` method `create_X_and_Y()`.<br><br>\n",
        "For the string in the $i\\text{th}$ row of `x`, the character the language model is trying to predict should <br>\n",
        "be the **first** character in the next row of `x`, <br>\n",
        "i.e y[i] should be the first character in row  $i+1$ of `x`<br><br>\n",
        "But it looks like something's wrong, because instead, the code assigns `y` to be the $16\\text{th}$ character in the next row of `x`!<br>\n",
        "This might be the reason the language model below doesn't train...\n",
        "I haven't yet figured out how to fix `create_X_and_Y()` to make it do the right thing.<br><br>\n",
        "\n",
        "Update: The code is **doing the right thing after all**. In the `data_cleaning_toolkit`, you find a `step` parameter which is set to $5$ and means that each sequence starts $5$ characters later than the previous one. So the $16\\text{th}$ character in the $2\\text{nd}$ row is the $21\\text{st}$ character of the data set, which is the next character after the first row. <br><br>\n",
        "\n",
        "**The take-away**: this is a perfect example of why it's important to take the time to *document* your code, so that the people who have to use it don't have to spend hours trying to figure out what it does!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKDU1JaneiyL",
        "outputId": "f5663c71-f8b5-462b-eaf1-b584940dbf22"
      },
      "source": [
        "print(np.argmax(y[0]))\n",
        "print( [np.argmax(x[1,i,:]) for i in range(20) ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "[0, 2, 17, 18, 0, 5, 11, 26, 9, 19, 1, 17, 12, 5, 0, 16, 18, 18, 6, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQtxBVBupByq",
        "outputId": "8cd4dc23-c38d-4a6f-ae87-49abb8827435"
      },
      "source": [
        "print(np.argmax(y[1]))\n",
        "print( [np.argmax(x[2,i,:]) for i in range(20) ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "[5, 11, 26, 9, 19, 1, 17, 12, 5, 0, 16, 18, 18, 6, 7, 26, 6, 19, 17, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEeMZQPJpNi_",
        "outputId": "dc869b4f-22a4-436c-edd0-3bb34ea2968e"
      },
      "source": [
        "print(np.argmax(y[2]))\n",
        "print( [np.argmax(x[3,i,:]) for i in range(20) ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "[1, 17, 12, 5, 0, 16, 18, 18, 6, 7, 26, 6, 19, 17, 16, 7, 26, 0, 16, 26]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7vh28iwo8wJ"
      },
      "source": [
        "### Callback function to gauge progress at the end of each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn8EUXe29uCL"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Helper function to sample an index from a probability array\n",
        "    \"\"\"\n",
        "    # convert preds to array \n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    # scale values \n",
        "    preds = np.log(preds) / temperature\n",
        "    # exponentiate values\n",
        "    exp_preds = np.exp(preds)\n",
        "    # this equation should look familar to you (hint: it's an activation function)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    # Draw samples from a multinomial distribution\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    # return the index that corresponds to the max probability \n",
        "    return np.argmax(probas)\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    \"\"\"\"\n",
        "    Function invoked at end of each epoch. Prints the text generated by our model.\n",
        "    \"\"\"\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "\n",
        "    start_index = random.randint(0, len(text) - dctk.maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + dctk.maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(40):\n",
        "        \n",
        "        x_dims = (1, dctk.maxlen, dctk.n_features)\n",
        "        x_pred = np.zeros(x_dims)\n",
        "        \n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, dctk.char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = dctk.int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        # explore the flush function and make sure that this is what we want \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYl_K89k9uCM"
      },
      "source": [
        "# need this for on_epoch_end()\n",
        "text = \" \".join(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0BFtoKUIM2x"
      },
      "source": [
        "# create callback object that will print out text generation at the end of each epoch \n",
        "# use for real-time monitoring of model performance\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8XJn73bnDE5",
        "outputId": "6646b99f-9465-4d1c-cda5-10f9cb3fe2c9"
      },
      "source": [
        "x[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53AGJKhk9uCM"
      },
      "source": [
        "---------\n",
        "### Build Text Generating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Ql4CF896Vc"
      },
      "source": [
        "Set up the Adam optimizer to allow changing the learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fe9kvNM92k-"
      },
      "source": [
        "# build a 1 layer LSTM language model \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# specify learning rate and optimizer\n",
        "opt = Adam(learning_rate=0.003)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7XeGd0a2MKi",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-0b9d84be1c960668",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9adca4db-6089-41e1-df88-63bb66a3dc2f"
      },
      "source": [
        "%%time\n",
        "### BEGIN SOLUTION\n",
        "## 100 sec for 50 epochs with colab GPU (1 LSTM layer, 256 neurons)\n",
        "\n",
        "\n",
        "# build another model for our task for forecasting what text should follow from our seed string \n",
        "model = Sequential()\n",
        "\n",
        "# hidden layer 1 \n",
        "model.add(LSTM(256, \n",
        "               input_shape=(dctk.maxlen, dctk.n_features), # think of input_shape as implicitly declaring the input layer \n",
        "               return_sequences=False)) # set to true whenever using 2 or more LSTM layers \n",
        "\n",
        "# hidden layer 2 \n",
        "#model.add(LSTM(128))\n",
        "\n",
        "# this is our output layer\n",
        "# recall that n_features = num of nodes in output layer \n",
        "model.add(Dense(dctk.n_features, \n",
        "                activation='softmax'))\n",
        "\n",
        "# notice that we are using categorical_crossentropy this time around - why?\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=opt)\n",
        "\n",
        "# fit the model\n",
        "# x and y are pretty large, consider sub-sampling\n",
        "model.fit(x[:4000], y[:4000],\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          callbacks=[print_callback])\n",
        "### END SOLUTION"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 13ms/step - loss: 3.0322\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"re is a penalty for \"\n",
            "re is a penalty for bog hhbptshehr  ineisncelhrpenkorba fanu\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.7169\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ked by a reporter wh\"\n",
            "ked by a reporter whe ksmoy tro est m d eus oucshuecpiniles \n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 2.5397\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"day at his home in b\"\n",
            "day at his home in be cpawir  bte  fican asy wntos forin fry\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.4432\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"eak from golf to twe\"\n",
            "eak from golf to twendfthitir bl wigrs ofontons an ckedeasy \n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.3696\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"named devon archer a\"\n",
            "named devon archer amlssirathastifofer weund lt as iff oulis\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.3021\n",
            "\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"nd emphatically deni\"\n",
            "nd emphatically denidomm kukr me arn y ruserint at ut tou s \n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.2375\n",
            "\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"a womens prison is t\"\n",
            "a womens prison is thes ay tht shaye coreas mont out s mion \n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.1840\n",
            "\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"for additional infor\"\n",
            "for additional inforppwarnt mela fim wi weain orghivcer pela\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 2.1121\n",
            "\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"n officials saidalth\"\n",
            "n officials saidaltheris igd hime off a folena nonte mhecoup\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 2.0488\n",
            "\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \" at the institute of\"\n",
            " at the institute of avrsalynarts in tormar of chy coucentor\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.9698\n",
            "\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"oses in the precedin\"\n",
            "oses in the precedinet ha prew in umisthiten bat houst as ip\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.8830\n",
            "\n",
            "----- Generating text after Epoch: 11\n",
            "----- Generating with seed: \"nate your access to \"\n",
            "nate your access to for the rukrest is post lr moin wnyer av\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.8013\n",
            "\n",
            "----- Generating text after Epoch: 12\n",
            "----- Generating with seed: \" in an email that al\"\n",
            " in an email that alomed in turkey the gordmeyr undorane ids\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.7134\n",
            "\n",
            "----- Generating text after Epoch: 13\n",
            "----- Generating with seed: \" her and other home \"\n",
            " her and other home the sagertenimenthinchit ro pis enaliont\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.6106\n",
            "\n",
            "----- Generating text after Epoch: 14\n",
            "----- Generating with seed: \"hone call that is at\"\n",
            "hone call that is atter mast arncads wollchmersed iff wice a\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.4884\n",
            "\n",
            "----- Generating text after Epoch: 15\n",
            "----- Generating with seed: \"ecretaries denied th\"\n",
            "ecretaries denied the hil wo last on justirnts ntenm coin un\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.3693\n",
            "\n",
            "----- Generating text after Epoch: 16\n",
            "----- Generating with seed: \"vened on a saturdayt\"\n",
            "vened on a saturdayt an dine toud zesiensoy the rusthin kurs\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.2500\n",
            "\n",
            "----- Generating text after Epoch: 17\n",
            "----- Generating with seed: \"s and technology gro\"\n",
            "s and technology gromen tay  fome ceverament ar concher and \n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1351\n",
            "\n",
            "----- Generating text after Epoch: 18\n",
            "----- Generating with seed: \"iately called up ukr\"\n",
            "iately called up ukreeded kressmany cesters troup ors werkis\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.9960\n",
            "\n",
            "----- Generating text after Epoch: 19\n",
            "----- Generating with seed: \" toward refugees and\"\n",
            " toward refugees ander abroplesicent hel decorm utrian amnon\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.8610\n",
            "\n",
            "----- Generating text after Epoch: 20\n",
            "----- Generating with seed: \"eir banks flooding m\"\n",
            "eir banks flooding mill ofsters veliotans on syrian dilish y\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.7488\n",
            "\n",
            "----- Generating text after Epoch: 21\n",
            "----- Generating with seed: \"al information to en\"\n",
            "al information to entornaly podd by iopliald adpears a near \n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.6480\n",
            "\n",
            "----- Generating text after Epoch: 22\n",
            "----- Generating with seed: \"y los angeles timesd\"\n",
            "y los angeles timesd russian masheerupent off is and isters \n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.5196\n",
            "\n",
            "----- Generating text after Epoch: 23\n",
            "----- Generating with seed: \"ired by law or as ne\"\n",
            "ired by law or as nevelliger white hie grempeather beg toeas\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4475\n",
            "\n",
            "----- Generating text after Epoch: 24\n",
            "----- Generating with seed: \"ell below zero it to\"\n",
            "ell below zero it tollashpear bles a tordish ont theysterion\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3429\n",
            "\n",
            "----- Generating text after Epoch: 25\n",
            "----- Generating with seed: \"nd it was vicious wh\"\n",
            "nd it was vicious whitr apeassid foratershrentcunid by treme\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2926\n",
            "\n",
            "----- Generating text after Epoch: 26\n",
            "----- Generating with seed: \"second way to move b\"\n",
            "second way to move by cold bukrians ir to kulls ir wish digh\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.2313\n",
            "\n",
            "----- Generating text after Epoch: 27\n",
            "----- Generating with seed: \"oo at the zoo at the\"\n",
            "oo at the zoo at the wiit  he couperote tt foe we the report\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1696\n",
            "\n",
            "----- Generating text after Epoch: 28\n",
            "----- Generating with seed: \"s goal to help reade\"\n",
            "s goal to help readentstrulin whier the buklone ledsmertert \n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1325\n",
            "\n",
            "----- Generating text after Epoch: 29\n",
            "----- Generating with seed: \" inwhich is when the\"\n",
            " inwhich is when the rullioverall has woukenttins unatumnian\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1048\n",
            "\n",
            "----- Generating text after Epoch: 30\n",
            "----- Generating with seed: \" linedrive singles a\"\n",
            " linedrive singles ads heive co mol wight of the paivederali\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1419\n",
            "\n",
            "----- Generating text after Epoch: 31\n",
            "----- Generating with seed: \"e president is now r\"\n",
            "e president is now reaus fot on moilalld wikerragy tame whie\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1202\n",
            "\n",
            "----- Generating text after Epoch: 32\n",
            "----- Generating with seed: \"ama note believed to\"\n",
            "ama note believed to cokersonentt rugrimo tulkir syrian agro\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0719\n",
            "\n",
            "----- Generating text after Epoch: 33\n",
            "----- Generating with seed: \"factchecking network\"\n",
            "factchecking network ustin mollihe rutints a for the wnetitb\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0554\n",
            "\n",
            "----- Generating text after Epoch: 34\n",
            "----- Generating with seed: \"ive up and eat a duc\"\n",
            "ive up and eat a duckukl wo kee we ge poche beirnentmin bor \n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0374\n",
            "\n",
            "----- Generating text after Epoch: 35\n",
            "----- Generating with seed: \"tfile photoreutersth\"\n",
            "tfile photoreutersthinoritin ins uriena natt theeceens ffoff\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0256\n",
            "\n",
            "----- Generating text after Epoch: 36\n",
            "----- Generating with seed: \"ed around the corner\"\n",
            "ed around the cornerestot tre pollopp staich louknorith upea\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0215\n",
            "\n",
            "----- Generating text after Epoch: 37\n",
            "----- Generating with seed: \" heard it i said tha\"\n",
            " heard it i said that to bat ovpeate to de pas dechitaim  wh\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0183\n",
            "\n",
            "----- Generating text after Epoch: 38\n",
            "----- Generating with seed: \"ent to the collectio\"\n",
            "ent to the collection op thite trea neart the by torcantsorn\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0184\n",
            "\n",
            "----- Generating text after Epoch: 39\n",
            "----- Generating with seed: \"g that it was only e\"\n",
            "g that it was only eame raly fool the weite fits ane gurne f\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0182\n",
            "\n",
            "----- Generating text after Epoch: 40\n",
            "----- Generating with seed: \"e kurds say they fee\"\n",
            "e kurds say they fees the wiut for eniorili hiv weule have u\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0140\n",
            "\n",
            "----- Generating text after Epoch: 41\n",
            "----- Generating with seed: \"lderly man died minu\"\n",
            "lderly man died minued ad cheericilingrr wook remprivan a fo\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0125\n",
            "\n",
            "----- Generating text after Epoch: 42\n",
            "----- Generating with seed: \" government revenue \"\n",
            " government revenue deflotimy gordiens as treop highrias of \n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0117\n",
            "\n",
            "----- Generating text after Epoch: 43\n",
            "----- Generating with seed: \"o differently from h\"\n",
            "o differently from his levereagenien sy case of the andiial \n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0112\n",
            "\n",
            "----- Generating text after Epoch: 44\n",
            "----- Generating with seed: \"ting fellow at the b\"\n",
            "ting fellow at the by tollitanill has wiit dowhrurkish intur\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0099\n",
            "\n",
            "----- Generating text after Epoch: 45\n",
            "----- Generating with seed: \"lled by kurdish forc\"\n",
            "lled by kurdish force ruspian oftit the caum los to gucis to\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0104\n",
            "\n",
            "----- Generating text after Epoch: 46\n",
            "----- Generating with seed: \"of the world that ev\"\n",
            "of the world that eveccill by tay the will heiger to lousker\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0089\n",
            "\n",
            "----- Generating text after Epoch: 47\n",
            "----- Generating with seed: \"int the following da\"\n",
            "int the following dawlisithithitaly gond the ansed peed the \n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0080\n",
            "\n",
            "----- Generating text after Epoch: 48\n",
            "----- Generating with seed: \"creator a user known\"\n",
            "creator a user known ha newith shaladst thrueritions as adna\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0076\n",
            "\n",
            "----- Generating text after Epoch: 49\n",
            "----- Generating with seed: \"tatement that you ha\"\n",
            "tatement that you ha beire at meroid of the uslamicislinstre\n",
            "CPU times: user 1min 55s, sys: 7.82 s, total: 2min 3s\n",
            "Wall time: 2min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBt5ugHKIM21"
      },
      "source": [
        "-------------\n",
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ger33u0CIM22"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}