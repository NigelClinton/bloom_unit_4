{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_423_Tune_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "\n",
        "\n",
        "# Tune Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "# Gridsearch Hyperparameters\n",
        "\n",
        "In the guided project, you learned how to use sklearn's GridsearchCV and keras-tuner library to tune the hyperparameters of a neural network model. For your module project, you'll continue using these two libraries; however, we will make things a little more interesting for you. \n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. \n",
        "\n",
        "\n",
        "\n",
        "**Don't forget to switch to GPU on Colab!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lzoonloI0Ot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "6247f123-e0c0-48ee-c00a-2d70efe81c62"
      },
      "source": [
        "# native python libraries imports \n",
        "import math\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# sklearn imports \n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# keras imports \n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization, Sklearn\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "from keras.activations import relu, sigmoid\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import get_file\n",
        "\n",
        "# required for compatibility between sklearn and keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1fc2993abd59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxXxCMJpI0Ou"
      },
      "source": [
        "def load_quickdraw10():\n",
        "    \"\"\"\n",
        "    Fill out this docstring, and comment the code for practice in writing the kind of code that will get you hired. \n",
        "    \"\"\"\n",
        "    \n",
        "    URL_ = \"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\n",
        "    \n",
        "    path_to_zip = get_file('quickdraw10.npz', origin=URL_, extract=False)\n",
        "\n",
        "    data = np.load(path_to_zip)\n",
        "    \n",
        "    # normalize your image data\n",
        "    max_pixel_value = 255\n",
        "    X = data['arr_0']/max_pixel_value\n",
        "    Y = data['arr_1']\n",
        "        \n",
        "    return train_test_split(X, Y, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45m5XaCFI0Ou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "5f81a408-b2d3-477e-dbc1-f2779dd90072"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_quickdraw10()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-79bf4264065c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_quickdraw10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-6a8c1aa6b237>\u001b[0m in \u001b[0;36mload_quickdraw10\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mURL_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://github.com/LambdaSchool/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/quickdraw10.npz?raw=true\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpath_to_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quickdraw10.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mURL_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf11zxcCI0Ov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "90d89f73-84d9-4718-dacf-03f1fcc2f641"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d2ba684acd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CoZCMoII0Ov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "40388f82-b314-4427-dc41-a01e76c9db7f"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-30602697b5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pugKBJQ2I0Ow"
      },
      "source": [
        "_____\n",
        "\n",
        "# Experiment 1\n",
        "\n",
        "## Tune Hyperparameters Using Enhanced GridsearchCV \n",
        "\n",
        "We will use GridsearchCV again to tune a deep learning model; however, we will add some additional functionality to our gridsearch. Specifically, we will automate away the generation of how many nodes to use in a layer and how many layers to use in a model!\n",
        "\n",
        "By the way, yes, there is a function within a function. Try not to let that bother you. An alternative to this would be to create a class. If you're up for the challenge, give it a shot. However, consider this a stretch goal that you come back to after going through this assignment. \n",
        "\n",
        "\n",
        "### Objective \n",
        "\n",
        "This experiment aims to show you how to automate the generation of layers and layer nodes for gridsearch. Up until now, we've been manually selecting the number of layers and layer nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy"
      },
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
        "    \"\"\"\"\n",
        "    Returns a complied keras model \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_layers: int \n",
        "        number of hidden layers in the model \n",
        "        To be clear, this excludes the input and output layers.\n",
        "        \n",
        "    first_layer_nodes: int\n",
        "        Number of nodes in the first hidden layer \n",
        "\n",
        "    last_layer_nodes: int\n",
        "        Number of nodes in the last hidden layer (this is the layer before the output layer)\n",
        "        \n",
        "     act_funct: string \n",
        "         Name of activation function to use in hidden layers (this excludes the output layer)\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    model: keras object \n",
        "    \"\"\"\n",
        "    \n",
        "    def gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation=True):\n",
        "        \"\"\"\n",
        "        Generates and returns the number of nodes in each hidden layer. \n",
        "        To be clear, this excludes the input and output layers. \n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        The number of nodes in each layer is linearly incremented. \n",
        "        For example, gen_layer_nodes(5, 500, 100) will generate [500, 400, 300, 200, 100]\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_layers: int\n",
        "            The number of hidden layers\n",
        "            These values should be 2 or greater \n",
        "\n",
        "        first_layer_nodes: int\n",
        "\n",
        "        last_layer_nodes: int\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        layers: list of ints\n",
        "            Contains the number of nodes for each layer \n",
        "        \"\"\"\n",
        "\n",
        "        # throws an error if n_layers is less than 2 \n",
        "        assert n_layers >= 2, \"n_layers must be 2 or greater\"\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # PROTIP: IF YOU WANT THE NODE INCREMENTATION TO BE SPACED DIFFERENTLY\n",
        "        # THEN YOU'LL NEED TO CHANGE THE WAY THAT IT'S CALCULATED - HAVE FUN!\n",
        "        # when set to True number of nodes, are decreased for subsequent layers \n",
        "        if negative_node_incrementation:\n",
        "            # subtract this amount from the previous layer's nodes to increment towards smaller numbers \n",
        "            nodes_increment = (last_layer_nodes - first_layer_nodes)/ (n_layers-1)\n",
        "            \n",
        "        # when set to False number of nodes are increased for subsequent layers\n",
        "        else:\n",
        "            # add this amount from previous layer's nodes in order to increment towards larger numbers \n",
        "            nodes_increment = (first_layer_nodes - last_layer_nodes)/ (n_layers-1)\n",
        "\n",
        "        nodes = first_layer_nodes\n",
        "\n",
        "        for i in range(1, n_layers+1):\n",
        "\n",
        "            layers.append(math.ceil(nodes))\n",
        "\n",
        "            # increment nodes for next layer \n",
        "            nodes = nodes + nodes_increment\n",
        "\n",
        "        return layers\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    n_nodes = gen_layer_nodes(n_layers, first_layer_nodes, last_layer_nodes, negative_node_incrementation)\n",
        "    \n",
        "    for i in range(1, n_layers):\n",
        "        if i==1:\n",
        "            model.add(Dense(first_layer_nodes, input_dim=X_train.shape[1], activation=act_funct))\n",
        "        else:\n",
        "            model.add(Dense(n_nodes[i-1], activation=act_funct))\n",
        "            \n",
        "            \n",
        "    # output layer \n",
        "    model.add(Dense(10, # 10 unit/neurons in output layer because we have 10 possible labels to predict  \n",
        "                    activation='softmax')) # use softmax for a label set greater than 2            \n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='adam', # adam is a good default optimizer \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # do not include model.fit() inside the create_model function\n",
        "    # KerasClassifier is expecting a compiled model \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLJcMMvDI0Oz"
      },
      "source": [
        "## Explore Create_Model\n",
        "\n",
        "Let's build a few different models to understand how the above code works in practice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2MXQbEjI0Oz"
      },
      "source": [
        "### Build Model \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 10` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5dcf5c585f07629a03086cf57ba53615",
          "grade": false,
          "grade_id": "cell-86d63e89a21223de",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "gHH9RRINI0O0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "5175b1fc-b03a-4cac-9d30-234f14fedd89"
      },
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
        "\n",
        "create_model(10, 500, 100, \"relu\", True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-74b0b70ac684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact_funct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative_node_incrementation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-1a7154755a75>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(n_layers, first_layer_nodes, last_layer_nodes, act_funct, negative_node_incrementation)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mn_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_layer_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_layer_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_layer_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_node_incrementation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwUyuxOiI0O0"
      },
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "# Notice in the model summary how the number of nodes has been linearly incremented in decreasing values. \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhqcE5zEI0O0"
      },
      "source": [
        "### Build Model \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 10` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e0722533c325d699f4842e874e43720e",
          "grade": false,
          "grade_id": "cell-99d563a291231a7b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xtjvYSjCI0O1"
      },
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# def create_model(n_layers,  first_layer_nodes, last_layer_nodes, act_funct =\"relu\", negative_node_incrementation=True):\n",
        "\n",
        "create_model(10, 500, 100, \"relu\", True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-A5IJJUI0O1"
      },
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "# Notice in the model summary how the number of nodes has been linearly incremented in increasing values.\n",
        "# The output layer must have 10 nodes because there are 10 labels to predict \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXCjnun6I0O1"
      },
      "source": [
        "# feel free to play around with parameters to gain additional insight as to how the create_model function works \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxaShY_-I0O2"
      },
      "source": [
        "Ok, now that we've played around a bit with  `create_model` to understand how it works, let's build a much simpler model that we'll be running gridsearches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9oHYqblI0O2"
      },
      "source": [
        "### Build Model \n",
        "\n",
        "Use `create_model` to build a model. \n",
        "\n",
        "- Set `n_layers = 2` \n",
        "- Set `first_layer_nodes = 500`\n",
        "- Set `last_layer_nodes = 100`\n",
        "- Set `act_funct = \"relu\"`\n",
        "- Make sure that `negative_node_incrementation = True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "606b85d0ba4531836f97caf6850297f8",
          "grade": false,
          "grade_id": "cell-4ca6c5e51302fd10",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "5UpVuVk2I0O2"
      },
      "source": [
        "# use create_model to create a model \n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjNMxvG4I0O2"
      },
      "source": [
        "# run model.summary() and make sure that you understand the model architecture that you just built \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1XFAIRsI0O2"
      },
      "source": [
        "# define the grid search parameters\n",
        "param_grid = {'n_layers': [2, 3],\n",
        "              'epochs': [3], \n",
        "              \"first_layer_nodes\": [500, 300],\n",
        "              \"last_layer_nodes\": [100, 50]\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EJCj9myI0O3"
      },
      "source": [
        "model = KerasClassifier(create_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGJhDcxFI0O3"
      },
      "source": [
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urhe6JWmI0O4"
      },
      "source": [
        "best_model = grid_result.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO0TkEJ0I0O4"
      },
      "source": [
        "best_model.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cydDGYdYI0O4"
      },
      "source": [
        "-----\n",
        "\n",
        "# Experiment 2\n",
        "\n",
        "## Benchmark Different Optimization Algorithms \n",
        "\n",
        "In this section, we are going to use the same model and dataset to benchmark 3 different gridsearch approaches: \n",
        "\n",
        "- Random Search\n",
        "- Bayesian Optimization\n",
        "- Brute Force Gridsearch\n",
        "\n",
        "Our goal in this experiment is two-fold. We want to see which approach: \n",
        "\n",
        "- Scores the highest accuracy\n",
        "- Has the shortest run time \n",
        "\n",
        "We want to see how these 3 gridsearch approaches handle these trade-offs and give you a sense of those trade-offs.\n",
        "\n",
        "### Trade-Offs\n",
        "\n",
        "`Brute Force Gridsearch` will train a model on every unique hyperparameter combination; this guarantees that you'll get the highest possible accuracy from your parameter set, but your gridsearch might have a very long run-time.\n",
        "\n",
        "`Random Search` will randomly sample from your parameter set, which, depending on how many samples, the run-time might be significantly cut down. Still, you might or might not sample the parameters that correspond to the highest possible accuracies.\n",
        "\n",
        "`Bayesian Optimization` has a bit of intelligence built into its search algorithm, but you must manually select some parameters that greatly influence the model learning outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oreSpsCWI0O4"
      },
      "source": [
        "-------\n",
        "### Build our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drNaKnp8I0O4"
      },
      "source": [
        "# because gridsearching can take a lot of time, and we are bench-marking 3 different approaches\n",
        "# let's build a simple model to minimize run time \n",
        "\n",
        "def build_model(hp):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a compiled keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=hp.get('units'),activation=hp.get(\"activation\")))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(hp.get('learning_rate')),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLpWzs86I0O5"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hp = HyperParameters()\n",
        "hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3])\n",
        "hp.Choice('activation',values=[\"relu\", \"sigmoid\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJN2yATmI0O5"
      },
      "source": [
        "------\n",
        "# Run the Gridsearch Algorithms \n",
        "\n",
        "### Random Search\n",
        "\n",
        "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `RandomSearch` tuner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "aaff9aae33845f374e15f2381719d83a",
          "grade": false,
          "grade_id": "cell-8c1dfb9b6d12bea2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "I6fWPOeyI0O5"
      },
      "source": [
        "# how many unique hyperparameter combinations do we have? \n",
        "# HINT: take the product of the number of possible values for each hyperparameter \n",
        "# save your answer to n_unique_hparam_combos\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9d628451e83431e1b52da10eccf2c00",
          "grade": false,
          "grade_id": "cell-1fa83950bb2d5f92",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "-c7AUuMkI0O5"
      },
      "source": [
        "# how many of these do we want to randomly sample?\n",
        "# let's pick 25% of n_unique_hparam_combos param combos to sample\n",
        "# save this number to n_param_combos_to_sample\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB05gTlII0O5"
      },
      "source": [
        "random_tuner = RandomSearch(\n",
        "            build_model,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=n_param_combos_to_sample, # number of times to sample the parameter set and build a model \n",
        "            seed=1234,\n",
        "            hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "            directory='./keras-tuner-trial',\n",
        "            project_name='random_search')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsQ0Cf2KI0O5"
      },
      "source": [
        "# take note of Total elapsed time in print out\n",
        "random_tuner.search(X_train, y_train,\n",
        "                    epochs=3,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f80fCuyfI0O5"
      },
      "source": [
        "# identify the best score and hyperparameter (should be at the top since scores are ranked)\n",
        "random_tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "2-22HMaYI0O6"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the best performing hyperparameter combination and model score. Note that because this is a random search, multiple runs might have slightly different outcomes.\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f084b5d373f8589a1de8d6d4473b974a",
          "grade": true,
          "grade_id": "cell-5527738b6382c164",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "uVtC1cIQI0O6"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5LxscSjI0O6"
      },
      "source": [
        "------\n",
        "### Bayesian Optimization\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/0/02/GpParBayesAnimationSmall.gif)\n",
        "\n",
        "Be sure to check out the [**docs for Keras-Tuner**](https://keras-team.github.io/keras-tuner/documentation/tuners/). Here you can read about the input parameters for the `BayesianOptimization` tuner.\n",
        "\n",
        "Pay special attention to these `BayesianOptimization` parameters: `num_initial_points` and `beta`. \n",
        "\n",
        "`num_initial_points`: \n",
        "\n",
        "Number of randomly selected hyperparameter combinations to try before applying Bayesian probability to determine the likelihood of which param combo to try next based on expected improvement\n",
        "\n",
        "\n",
        "`beta`: \n",
        "\n",
        "Larger values mean more willingness to explore new hyperparameter combinations (analogous to searching for the global minimum in gradient descent). Conversely, smaller values mean less willingness to try new hyperparameter combinations (analogous to getting stuck in a local minimum in gradient descent). \n",
        "\n",
        "As a start, err on the side of larger values. What defines a small or large value, you ask? That question would pull us into the mathematical intricacies of Bayesian Optimization and Gaussian Processes. For simplicity, notice that the default value is 2.6 and work from there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_lv5tqyI0O6"
      },
      "source": [
        "# we know that 24 samples is about 25% of 96 possible hyper-parameter combos\n",
        "# because BO isn't random (after num_initial_points number of trails) let's see if 15 max trials gives good results\n",
        "# feel free to play with any of these numbers\n",
        "max_trials=15\n",
        "num_initial_points=5\n",
        "beta=5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xCtk3nVI0O6"
      },
      "source": [
        "bayesian_tuner = BayesianOptimization(\n",
        "                    build_model,\n",
        "                    objective='val_accuracy',\n",
        "                    max_trials=max_trials,\n",
        "                    hyperparameters=hp, # pass in our hyperparameter dictionary\n",
        "                    num_initial_points=num_initial_points, \n",
        "                    beta=beta, \n",
        "                    seed=1234,\n",
        "                    directory='./keras-tuner-trial',\n",
        "                    project_name='bayesian_optimization_4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myq4RDSgI0O6"
      },
      "source": [
        "bayesian_tuner.search(X_train, y_train,\n",
        "               epochs=3,\n",
        "               validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "4xQX_EUKI0O6"
      },
      "source": [
        "bayesian_tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R33cbZ26I0O7"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the best performing hyperparameter combination and model score. Note that because this is Bayesian Optimization, multiple runs might have slightly different outcomes.\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1badcdca408cdd49bc2e409dca3bac5a",
          "grade": true,
          "grade_id": "cell-ff95600bf745f40f",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Z7cbqTgNI0O7"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMwSVnUJI0O7"
      },
      "source": [
        "---------\n",
        "## Brute Force Gridsearch Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0W4bCd_I0O7"
      },
      "source": [
        "### Populate a Sklearn Compatible Parameter Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT_ytR-uI0O7"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hyper_parameters = {\n",
        "    # BUG Fix: cast array as list otherwise GridSearchCV will throw error\n",
        "    \"units\": np.arange(32, 544, 32).tolist(),\n",
        "    \"learning_rate\": [1e-1, 1e-2, 1e-3],\n",
        "    \"activation\":[\"relu\", \"sigmoid\"]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC6we-hhI0O7"
      },
      "source": [
        "hyper_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c8p4RjII0O7"
      },
      "source": [
        "### Build a Sklearn Compatible Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irzGZqpHI0O7"
      },
      "source": [
        "def build_model(units, learning_rate, activation):\n",
        "    \n",
        "    \"\"\"\n",
        "    Returns a compile keras model ready for keras-tuner gridsearch algorithms \n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units, activation=activation))\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGGbBttyI0O7"
      },
      "source": [
        "model = KerasClassifier(build_fn = build_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "-6xsKyfLI0O7"
      },
      "source": [
        "# save start time \n",
        "start = time()\n",
        "\n",
        "# Create Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# save end time \n",
        "end = time()\n",
        "\n",
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9xIXvLHI0O8"
      },
      "source": [
        "# total run time \n",
        "total_run_time_in_minutes = (end - start)/60\n",
        "total_run_time_in_minutes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDhmB1KCI0O8"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfKXnHB5I0O8"
      },
      "source": [
        "# because all other optimization approaches are reporting test set score\n",
        "# let's calculate the test set score in this case \n",
        "best_model = grid_result.best_estimator_\n",
        "test_acc = best_model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFg1V-6JI0O8"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6aG0L0hI0O8"
      },
      "source": [
        " ### Results\n",
        " \n",
        "Identify and write the best performing hyperparameter combination and model score.\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9577db883482c6cded3836e5cfbf5a74",
          "grade": true,
          "grade_id": "cell-eb06d682d2790f6e",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Kd07_qtdI0O8"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkIWTM_RI0O8"
      },
      "source": [
        "_______\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "The spirit of this experiment is to expose you to the idea of benchmarking and comparing the trade-offs of various gridsearch approaches. \n",
        "\n",
        "Even if we found a way to pass the original test set into GridSearchCV, we could see that both Random Search and Bayesian Optimization are arguably better alternatives to a brute force grid search. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5hq4bEgI0O8"
      },
      "source": [
        "----\n",
        "\n",
        "# Stretch Goals\n",
        "\n",
        "- Feel free to run whatever gridsearch experiments on whatever models you like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9jYKevI0O8"
      },
      "source": [
        "# this is your open playground - be free to explore as you wish "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}