{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "LS_DS_413_Document_Classification_Assignment_Guide.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "b56204e04fac71cbe4e15d7b3dab17d89d2f24d87d00adcaa585640e5d78c50d"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RIaw2IDPGfBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Classification (Assignment)\n",
        "\n",
        "This notebook is for you to practice skills during lecture.\n",
        "\n",
        "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a [kaggle competition](https://www.kaggle.com/c/whiskey-201911/) We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today's all about having fun and practicing your skills.\n",
        "\n",
        "## Sections\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
        "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
      ],
      "metadata": {
        "id": "X-0cqJc8GfBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ],
      "metadata": {
        "id": "I7YZNjEbGfBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to run increasingly sophisticated classification models on our whisky reviews in parts 1, 2, and 3. For each of parts 1, 2, and 3, submit your best model's results to the Kaggle competition to measure `generalization accuracy` -- i.e. how well the model performs on new data."
      ],
      "metadata": {
        "id": "tfAUasgKoKVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Classifier based on TfIdf vectorization of reviews"
      ],
      "metadata": {
        "id": "-v3SlXgD5Tk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ],
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "DpfX8zyJGfBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.0 Setup"
      ],
      "metadata": {
        "id": "iUrJ2rARmfkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.0.1 Get spacy and restart runtime"
      ],
      "metadata": {
        "id": "PWCleLr4lyP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#YOUR CODE HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "ysPkqrmcl2I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.0.2 import necessary packages, load spacy"
      ],
      "metadata": {
        "id": "RNImGQB1l56U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "import pandas as pd\r\n",
        "import re\r\n",
        "\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\r\n",
        "import xgboost as xgb\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "from sklearn.decomposition import TruncatedSVD\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "import spacy\r\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "l4KcM3TcMO-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load `spacy`"
      ],
      "metadata": {
        "id": "KsNq7a5WP_Tw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def clean_data(text):\r\n",
        "    \"\"\"\r\n",
        "    Accepts a single text document and performs several regex substitutions in order to clean the document. \r\n",
        "    \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    text: string or object \r\n",
        "    \r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    text: string or object\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    # order of operations - apply the expression from top to bottom\r\n",
        "    email_regex = r\"From: \\S*@\\S*\\s?\"\r\n",
        "    non_alpha = '[^a-zA-Z]'\r\n",
        "    multi_white_spaces = \"[ ]{2,}\"\r\n",
        "    \r\n",
        "    text = re.sub(email_regex, \"\", text)\r\n",
        "    text = re.sub(non_alpha, ' ', text)\r\n",
        "    text = re.sub(multi_white_spaces, \" \", text)\r\n",
        "    \r\n",
        "    # apply case normalization \r\n",
        "    return text.lower().lstrip().rstrip()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#YOUR CODE HERE\r\n",
        "vect = Tf\r\n",
        "(list(v)[0] for v in X.values)"
      ],
      "outputs": [],
      "metadata": {
        "id": "e1V3ApAvMDYx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# svd = TruncatedSVD(n_components=2, # number of topics to generate (also the size of the new feature space)\r\n",
        "#                    algorithm='randomized',\r\n",
        "#                    n_iter=10)\r\n",
        "\r\n",
        "# tf_vectorizer = CountVectorizer()\r\n",
        "# tfm = tf_vectorizer.fit_transform(data)\r\n",
        "# tfm = pd.DataFrame(data=tfm.toarray(), columns=tf_vectorizer.get_feature_names())\r\n",
        "\r\n",
        "# tfm.index = data\r\n",
        "# tfm"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.0.3 Load Kaggle Whisky Competition Data"
      ],
      "metadata": {
        "id": "UimXwG9tGfBs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# !!!!! You may need to change the path !!!!!\r\n",
        "# You can download these datasets from the Kaggle in-class \r\n",
        "# competition for your cohort. \r\n",
        " \r\n",
        "train = pd.read_csv('train.csv',usecols=['description','category'])\r\n",
        "test = pd.read_csv('test.csv',usecols=['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Nf-b1D-wGfBt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "test.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 288 entries, 0 to 287\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   id           288 non-null    int64 \n",
            " 1   description  288 non-null    object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 4.6+ KB\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "test.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>955</td>\n",
              "      <td>Think carnival aromas—the good ones, anyway—me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3532</td>\n",
              "      <td>A blend of three bourbons, between 6 and 12 ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1390</td>\n",
              "      <td>The nose is focused on cereal, hints of fresh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1024</td>\n",
              "      <td>Swiss-based Chapter 7 released this 19 year ol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1902</td>\n",
              "      <td>Valkyrie replaces the current Dark Origins exp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                        description\n",
              "0   955  Think carnival aromas—the good ones, anyway—me...\n",
              "1  3532  A blend of three bourbons, between 6 and 12 ye...\n",
              "2  1390  The nose is focused on cereal, hints of fresh ...\n",
              "3  1024  Swiss-based Chapter 7 released this 19 year ol...\n",
              "4  1902  Valkyrie replaces the current Dark Origins exp..."
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>There have been some legendary Bowmores from t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This bottling celebrates master distiller Park...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What impresses me most is how this whisky evol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description  category\n",
              "0  A marriage of 13 and 18 year old bourbons. A m...         2\n",
              "1  There have been some legendary Bowmores from t...         1\n",
              "2  This bottling celebrates master distiller Park...         2\n",
              "3  What impresses me most is how this whisky evol...         1\n",
              "4  A caramel-laden fruit bouquet, followed by une...         2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LnMkWvxdGfBu",
        "outputId": "33933d8e-efab-4908-b570-7a92c7f0964b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Clean Text"
      ],
      "metadata": {
        "id": "9uPjYRcHMa7N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "train['description'][0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a marriage of and year old bourbons a mature yet very elegant whiskey with a silky texture and so easy to embrace with a splash of water balanced notes of honeyed vanilla soft caramel a basket of complex orchard fruit blackberry papaya and a dusting of cocoa and nutmeg smooth finish sophisticated stylish with well defined flavors a classic'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "LU3Dvu_7MmSQ",
        "outputId": "5e53a3ae-00fd-4130-903d-7f472bb04d24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Split training data into Feature Matrix and Target Vector"
      ],
      "metadata": {
        "id": "zdqYMpmFMvto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "%%time\r\n",
        "\r\n",
        "def clean_doc(text):\r\n",
        "  # COMPLETE THE CODE IN THIS CELL\r\n",
        "  # remove new line characters\r\n",
        "  text = text.replace('\\\\n', ' ')\r\n",
        "\r\n",
        "  # remove numbers for the text\r\n",
        "  non_alpha = '[^a-zA-Z]'\r\n",
        "  multi_white_spaces = \"[ ]{2,}\"\r\n",
        "  \r\n",
        "  text = re.sub(non_alpha, ' ', text)\r\n",
        "  text = re.sub(multi_white_spaces, \" \", text)\r\n",
        "\r\n",
        "  # case normalize and strip extra white spaces on the far left and right hand side\r\n",
        "  return text.lower().lstrip().rstrip()\r\n",
        "\r\n",
        "train['description'] = train['description'].apply(clean_doc)\r\n",
        "test['description'] = test['description'].apply(clean_doc)\r\n",
        "\r\n",
        "\r\n",
        "###BEGIN SOLUTION\r\n",
        "# build a model that is trained on word vectors\r\n",
        "def get_word_vectors(docs):\r\n",
        "    \"\"\"\r\n",
        "    This serves as both our tokenizer and vectorizer. \r\n",
        "    Returns a list of word vectors, i.e. our doc-term matrix\r\n",
        "    \"\"\"\r\n",
        "    return [nlp(doc).vector for doc in docs]\r\n",
        "\r\n",
        "# You may need to change the path\r\n",
        "#train = pd.read_csv('./Kaggle Data/train.csv')\r\n",
        "#test = pd.read_csv('./Kaggle Data/test.csv')\r\n",
        "\r\n",
        "# create our doc-term matrices \r\n",
        "\r\n",
        "# raw text data for train and test sets\r\n",
        "X_train_text = train[\"description\"]\r\n",
        "X_test_text = test[\"description\"]\r\n",
        "\r\n",
        "# transform raw data into doc-term matrices for train and test sets \r\n",
        "X_train = get_word_vectors(X_train_text)\r\n",
        "X_test = get_word_vectors(X_test_text)\r\n",
        "\r\n",
        "# save ratings to y vector\r\n",
        "y_train = train[\"category\"]\r\n",
        "\r\n",
        "# create RF model, use out-of-bag (oob) score\r\n",
        "rfc = RandomForestClassifier(oob_score=True)\r\n",
        "\r\n",
        "rfc.fit(X_train, y_train)\r\n",
        "###END SOLUTION"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall time: 38.8 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(oob_score=True)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# CREATE Term-Frequency matrix \r\n",
        "\r\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\", tokenizer=None) # data transformer \r\n",
        "rfc = RandomForestClassifier(random_state=42) # estimator\r\n",
        "\r\n",
        "###BEGIN SOLUTION\r\n",
        "# use CountVectorizer to create a Term-Frequency matrix (a.k.a. Doc-Term Matrix )\r\n",
        "tf_vectorizer = CountVectorizer()\r\n",
        "tfm = tf_vectorizer.fit_transform(data)\r\n",
        "tfm = pd.DataFrame(data=tfm.toarray(), columns=tf_vectorizer.get_feature_names())\r\n",
        "\r\n",
        "# switch integer indicies with terms\r\n",
        "tfm.index = data\r\n",
        "tfm\r\n",
        "###END SOLUTION"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Define Pipeline Components\n",
        "We can try`RandomForestClassifier()`,  `GradientBoostingClassifier()` from the `sklearn` library, and `XGBClassifier()` from the `xgboost` library."
      ],
      "metadata": {
        "id": "5IHzPRZ2GfBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "# limiting max_features to 500 to speed up training on Colab.\r\n",
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "rfc = RandomForestClassifier(oob_score=True)\r\n",
        "\r\n",
        "svd = TruncatedSVD(n_components=2, # number of topics to generate (also the size of the new feature space)\r\n",
        "                   algorithm='randomized',\r\n",
        "                   n_iter=10)\r\n",
        "\r\n",
        "vect = TfidfVectorizer(stop_words=\"english\", tokenizer=None)\r\n",
        "\r\n",
        "lsi = Pipeline([(\"vect\", vect), # creating our term-doc matrix\r\n",
        "                (\"svd\", svd)]) # apply svd to our term-doc matrix \r\n",
        "\r\n",
        "pipe = Pipeline([(\"lsi\", lsi), # data transform\r\n",
        "                 (\"clf\", rfc)]) # estimator "
      ],
      "outputs": [],
      "metadata": {
        "id": "Ju6TgtdzGfBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ],
      "metadata": {
        "id": "clooAQkiGfBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "\r\n",
        "\r\n",
        "# Parameters to search in dictionary \r\n",
        "parameters = {\r\n",
        "    'lsi__vect__max_df':[.9,  1.0],\r\n",
        "    'clf__n_estimators':[10, 100, 250], \r\n",
        "    'clf__max_depth':(15, 20)\r\n",
        "}\r\n",
        "\r\n",
        "# Implement a grid search with cross-validation\r\n",
        "grid_search = GridSearchCV(pipe,\r\n",
        "                  param_grid=parameters, \r\n",
        "                  cv=3, \r\n",
        "                  n_jobs=-2, \r\n",
        "                  verbose=1)\r\n",
        "\r\n",
        "grid_search.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Display the best score from the grid search\r\n",
        "grid_search.best_score_"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'lower'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13716/2947284276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                   verbose=1)\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Display the best score from the grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \"\"\"\n\u001b[0;32m    377\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1844\u001b[0m         \"\"\"\n\u001b[0;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1846\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3R9iNggGfBx",
        "outputId": "d5136d65-9bc5-488f-99bf-fe8de19bc22f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Display the best parameters from the grid search\r\n",
        "print(grid_search.best_params_)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__max_depth': 20, 'vect__max_df': 0.75}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGd5eDV6PC3X",
        "outputId": "13c20cf0-54e3-4125-9715-b406117e3781"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Make a Submission File\n",
        "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so only submit when your predicted test accuracy is the highest you can make it. For this competition the max daily submissions are capped at **20**.  The submission file is made from the results of running your best model on the test data set, for which we don't get the targets."
      ],
      "metadata": {
        "id": "lK4r904hGfBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "# Predictions on **test** sample\r\n",
        "pred = grid_search.predict(...)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gEQo7ikVGfBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "submission = pd.DataFrame({... : ..., ...: ...})\r\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "VtE6ZpNnGfBy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Make Sure the Category is an Integer\r\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MrkTTtjoGfBz",
        "outputId": "7d0d5c2f-495c-4d65-f02b-9b8ffd00ec89"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Save your Submission File\r\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\r\n",
        "submission_number = 0\r\n",
        "\r\n",
        "submission.to_csv(f'submission{submission_number}.csv', index=False)\r\n",
        "submission_number += 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "hUACBAiMGfB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Download submission if in Google Colab\r\n",
        "from google.colab import files\r\n",
        "files.download(f'submission{submission_number}.csv')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "download(\"download_6ff1ecda-3e7b-44ed-a81f-83ad1381654f\", \"submission1.csv\", 6986)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3N-lBN63PUa9",
        "outputId": "7482108b-8b9c-4027-b854-ed45f140c8db"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve a minimum of 75% Accuracy on your model."
      ],
      "metadata": {
        "id": "hpg3M7vDGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Add Latent Semantic Indexing to pipeline (Learn)\n",
        "<a id=\"p2\"></a>"
      ],
      "metadata": {
        "id": "7rwWt0TNGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ],
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "PZXSsX8rGfB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Define Pipeline Components\n",
        "\n",
        "Nest pipelines to perform SVD on our vectorization (LSA)"
      ],
      "metadata": {
        "id": "75X-i44lGfB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "# Transforming our Vectorization with SVD is how LSA generates topic columns\r\n",
        "svd = ...\r\n",
        "\r\n",
        "# vectorizer and classifier like before\r\n",
        "vect = TfidfVectorizer(...)\r\n",
        "clf = XGBClassifier()\r\n",
        "\r\n",
        "# LSA pipeline with vectorizer & truncated SVD\r\n",
        "lsa = Pipeline(???)\r\n",
        "\r\n",
        "# combine LSA pipeline together with classifier\r\n",
        "pipe = Pipeline([('lsa', lsa), ('clf', clf)])"
      ],
      "outputs": [],
      "metadata": {
        "id": "QG_lFmOyGfB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Define Your grid search space and run a grid search with cross-validation\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ],
      "metadata": {
        "id": "uF7_arccGfB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "parameters = {\r\n",
        "    'lsa__svd__n_components': [...],\r\n",
        "    'lsa__vect__max_df': (...),\r\n",
        "    'clf__max_depth': (...)\r\n",
        "}\r\n",
        "\r\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=3, n_jobs=-1, verbose=1)\r\n",
        "grid_search.fit(..., ...)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.6min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('lsa',\n",
              "                                        Pipeline(memory=None,\n",
              "                                                 steps=[('vect',\n",
              "                                                         TfidfVectorizer(analyzer='word',\n",
              "                                                                         binary=False,\n",
              "                                                                         decode_error='strict',\n",
              "                                                                         dtype=<class 'numpy.float64'>,\n",
              "                                                                         encoding='utf-8',\n",
              "                                                                         input='content',\n",
              "                                                                         lowercase=True,\n",
              "                                                                         max_df=1.0,\n",
              "                                                                         max_features=500,\n",
              "                                                                         min_df=1,\n",
              "                                                                         ngram_range=(1,\n",
              "                                                                                      1),\n",
              "                                                                         norm='l2',\n",
              "                                                                         preprocessor=None,\n",
              "                                                                         smooth_i...\n",
              "                                                      objective='binary:logistic',\n",
              "                                                      random_state=0,\n",
              "                                                      reg_alpha=0, reg_lambda=1,\n",
              "                                                      scale_pos_weight=1,\n",
              "                                                      seed=None, silent=None,\n",
              "                                                      subsample=1,\n",
              "                                                      verbosity=1))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': (15, 20),\n",
              "                         'lsa__svd__n_components': [50, 100],\n",
              "                         'lsa__vect__max_df': (0.75, 1.0)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANy4UkVeGfB1",
        "outputId": "8acdd38d-2d77-49b7-e31c-e605aafac48a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "grid_search.best_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7337908122828017"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAXQ0qZfRNWu",
        "outputId": "7d9e537b-7e65-4e70-f141-ff4ee501c374"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "grid_search.best_params_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__max_depth': 20, 'lsa__svd__n_components': 100, 'lsa__vect__max_df': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oVwOkS9RPLY",
        "outputId": "5d0836ff-d150-4422-c434-69514295720e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Make a Submission File"
      ],
      "metadata": {
        "id": "0xZotkIEGfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Predictions on test sample\r\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "25fSUB-7GfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\r\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "uAawXel0GfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Make Sure the Category is an Integer\r\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ratingCategory</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2604</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3764</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ratingCategory\n",
              "0  3461               1\n",
              "1  2604               1\n",
              "2  3341               1\n",
              "3  3764               1\n",
              "4  2306               1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1VxekvAdGfB2",
        "outputId": "87e6b868-e27c-4a40-b940-eb4b9392e94e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Save your Submission File\r\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\r\n",
        "\r\n",
        "submission.to_csv(f'submission{submission_number}.csv', index=False)\r\n",
        "submission_number +=1"
      ],
      "outputs": [],
      "metadata": {
        "id": "mirtMVSWGfB2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Download submission if in Google Colab\r\n",
        "from google.colab import files\r\n",
        "files.download(f'submission{submission_number}.csv')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": "download(\"download_52cc0614-23af-4760-8327-dd9ff5209b0a\", \"submission2.csv\", 6986)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "i1_gHQfLTu5T",
        "outputId": "21bef41c-a5f2-4b10-f2cd-5fc74c2f008f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ],
      "metadata": {
        "id": "FLtOAlokGfB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Add Spacy Word Embeddings\n",
        "<a id=\"p3\"></a>"
      ],
      "metadata": {
        "id": "l_6YzbjHGfB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Process the data set with spacy"
      ],
      "metadata": {
        "id": "voankIL7GfB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Apply to your Dataset\r\n",
        "\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "from scipy.stats import randint\r\n",
        "\r\n",
        "param_dist = {\r\n",
        "    \r\n",
        "    'max_depth' : randint(3,10),\r\n",
        "    'min_samples_leaf': randint(2,15)\r\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "sTE0VTyMGfB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Continue Word Embedding Work Here\r\n",
        "nlp = spacy.load(\"en_core_web_md\")\r\n",
        "\r\n",
        "def get_word_vectors(docs):\r\n",
        "    # YOUR CODE HERE\r\n",
        "    return \r\n",
        "\r\n",
        "X_train_emb = get_word_vectors(train['description'])\r\n",
        "X_test_emb = get_word_vectors(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "rxESV0tdGfB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rfc = RandomForestClassifier(oob_score=True)\r\n",
        "\r\n",
        "rfc.fit(X_train_emb, y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=True, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duovxl3NUQWk",
        "outputId": "4ab14f9d-80c0-4cfe-e02a-073a38c261e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# massively overfit with the Random Forest\r\n",
        "print('Training Accuracy: ', rfc.score(X_train_emb, y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9997553217518963\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sErmIzPmUcb4",
        "outputId": "7fe144f0-cf53-409e-bbe3-33238be36f32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use oob_score_ (out-of-bag score) as a **proxy** for the test score;<br>\n",
        "for your submission, you will predict on the test set, as before"
      ],
      "metadata": {
        "id": "E6gj2dtAsojE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# validation looks decent without any tuning\r\n",
        "\r\n",
        "rfc.oob_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7230242231465622"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emXFzc-EUkIo",
        "outputId": "3a916c27-bdaa-4358-dbfb-1e03bddfd54c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Make a Submission File"
      ],
      "metadata": {
        "id": "HNUdL4rtGfB4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# YOUR CODE HERE\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "--t3j2Hn_reu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Make a submission to Kaggle "
      ],
      "metadata": {
        "id": "OuAIyBRPGfB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Post Lecture Assignment\n",
        "<a id=\"p4\"></a>\n",
        "\n",
        "Your primary assignment this afternoon is to achieve a minimum of 75% accuracy on the Kaggle competition. <br>\n",
        "Once you have achieved that goal, please explore a few of the following topics: \n",
        "\n",
        "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
        "    - What is \"Sentiment Analysis\"? \n",
        "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
        "    - How do you create labeled sentiment data? Are those labels really sentiment?\n",
        "    - What are common applications of sentiment analysis?\n",
        "2. Research why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
        "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
        "    - Neural Networks are becoming more popular for document classification. Why is that the case?\n",
        "\n",
        "3. Research Singular Value Decomposition (SVD), one of the most important and powerful methods in Applied Mathematics and in all of Machine Learning.  Principal Components Analysis (PCA) -- which we used in Module 2 -- is closely releated to SVD.<br>\n",
        "\n",
        "* [Daniela Witten](https://www.danielawitten.com/), a Professor of Mathematical Statistics at the University of Washington, recently penned a highly amusing and informative [tweetstorm](https://twitter.com/WomenInStat/status/1285611042446413824) about SVD, well worth reading!<br>\n",
        "* [Stanford University Lecture on SVD](https://www.youtube.com/watch?v=P5mlg91as1c) <br>\n",
        "* [StatQuest Principal Components Analysis](https://www.youtube.com/watch?v=FgakZw6K1QQ)<br>\n",
        "* [Luis Serrano Principal Components Analysis](https://www.youtube.com/watch?v=g-Hb26agBFg)<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "1gM_zN5zGfB5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "q8xSIsjGtE84"
      }
    }
  ]
}