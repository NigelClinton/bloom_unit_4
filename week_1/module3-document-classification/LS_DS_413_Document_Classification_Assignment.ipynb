{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "LS_DS_413_Document_Classification_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "b56204e04fac71cbe4e15d7b3dab17d89d2f24d87d00adcaa585640e5d78c50d"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanleeallred/DS-Unit-4-Sprint-1-NLP/blob/main/module3-document-classification/LS_DS_413_Document_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 1, Module 3*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qdT3bV_yynnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Classification (Assignment)\n",
        "\n",
        "This notebook is for you to practice skills during lectures.\n",
        "\n",
        "Today's guided module project and assignment will be different. You already know how to do classification. You already know how to extract features from documents. So? That means you're ready to combine and practice those skills in a Kaggle competition. We will open with a five-minute sprint explaining the competition and then give you 25 minutes to work. After those twenty-five minutes are up, I will give a 5-minute demo of an NLP technique to help you with document classification (*and **maybe** the competition*).\n",
        "\n",
        "Today is all about having fun and practicing your skills.\n",
        "\n",
        "## Sections\n",
        "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
        "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
        "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
        "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
      ],
      "metadata": {
        "id": "U7DcSisAynnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Feature Extraction & Classification Pipelines (Learn)\n",
        "<a id=\"p1\"></a>"
      ],
      "metadata": {
        "id": "v88jsjeRynnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Follow Along \n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model (try using the pipe method I just demoed)"
      ],
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "QNN2ergBynno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Competition Data"
      ],
      "metadata": {
        "id": "3b90FDvoynno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import pandas as pd\r\n",
        "import re\r\n",
        "\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\r\n",
        "import xgboost as xgb\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "from sklearn.decomposition import TruncatedSVD\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "import spacy\r\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "# You may need to change the path\r\n",
        "train = pd.read_csv('train.csv',usecols=['description','category'])\r\n",
        "test = pd.read_csv('test.csv',usecols=['description'])\r\n",
        "\r\n",
        "submission_test=pd.read_csv('test.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "f0jHWhFjynno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A marriage of 13 and 18 year old bourbons. A m...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>There have been some legendary Bowmores from t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This bottling celebrates master distiller Park...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What impresses me most is how this whisky evol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A caramel-laden fruit bouquet, followed by une...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         description  category\n",
              "0  A marriage of 13 and 18 year old bourbons. A m...         2\n",
              "1  There have been some legendary Bowmores from t...         1\n",
              "2  This bottling celebrates master distiller Park...         2\n",
              "3  What impresses me most is how this whisky evol...         1\n",
              "4  A caramel-laden fruit bouquet, followed by une...         2"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "metadata": {
        "id": "TwPYvN8Tynnp",
        "outputId": "0e1aad4f-3112-4927-a32f-4e347ed018ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Pipeline Components"
      ],
      "metadata": {
        "id": "yFpBtrfKynnr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def clean_text(text):\r\n",
        "  # COMPLETE THE CODE IN THIS CELL\r\n",
        "  # remove new line characters\r\n",
        "  text = text.replace('\\\\n', ' ')\r\n",
        "\r\n",
        "  # remove numbers for the text\r\n",
        "  non_alpha = '[^a-zA-Z]'\r\n",
        "  multi_white_spaces = \"[ ]{2,}\"\r\n",
        "  \r\n",
        "  text = re.sub(non_alpha, ' ', text)\r\n",
        "  text = re.sub(multi_white_spaces, \" \", text)\r\n",
        "\r\n",
        "  # case normalize and strip extra white spaces on the far left and right hand side\r\n",
        "  return text.lower().lstrip().rstrip()\r\n",
        "\r\n",
        "train['description'] = train['description'].apply(clean_text)\r\n",
        "test['description'] = test['description'].apply(clean_text)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# prep data, instantiate a model, create pipeline object, and run a gridsearch \r\n",
        "\r\n",
        "###BEGIN SOLUTION\r\n",
        "\r\n",
        "target = 'category'\r\n",
        "# COMPLETE THE CODE IN THIS CELL\r\n",
        "y, X = train[target], train.drop(columns=target)\r\n",
        "\r\n",
        "X = [list(v)[0] for v in X.values]\r\n",
        "\r\n",
        "# Create Pipeline Components\r\n",
        "\r\n",
        "# create vectorizer\r\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\", tokenizer=None) # data transformer \r\n",
        "\r\n",
        "# create classifier\r\n",
        "rfc = RandomForestClassifier(random_state=42) # estimator \r\n",
        "\r\n",
        "# Instantiate a pipeline object\r\n",
        "pipe = Pipeline([(\"vect\", tfidf), # data transformer\r\n",
        "                 (\"clf\", rfc)])   # classifier "
      ],
      "outputs": [],
      "metadata": {
        "id": "QvgC1g7wynns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ],
      "metadata": {
        "id": "ZgwbuHd-ynns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "parameters = {\r\n",
        "    'vect__max_df': (0.75, 1.0),\r\n",
        "    'clf__max_depth':(5,10,15,20)\r\n",
        "}\r\n",
        "\r\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\r\n",
        "grid_search.fit(X, y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        TfidfVectorizer(stop_words='english')),\n",
              "                                       ('clf',\n",
              "                                        RandomForestClassifier(random_state=42))]),\n",
              "             n_jobs=4,\n",
              "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
              "                         'vect__max_df': (0.75, 1.0)},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {
        "id": "mEcWhPYBynnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "grid_search.best_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7757085352830033"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a Submission File\n",
        "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition, the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
      ],
      "metadata": {
        "id": "O2qG92Ewynnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# Predictions on test sample\r\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "RyGgXUP_ynnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "source": [
        "submission = pd.DataFrame({'id': submission_test['id'], 'category':pred})\r\n",
        "submission['category'] = submission['category'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "NxWPtarJynnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "# Make Sure the Category is an Integer\r\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>955</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3532</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1390</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1024</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  category\n",
              "0   955         2\n",
              "1  3532         2\n",
              "2  1390         1\n",
              "3  1024         1\n",
              "4  1902         1"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "metadata": {
        "id": "ipQUEatEynnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "subNumber = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "biyru9ZTynnv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "# Save your Submission File\r\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\r\n",
        "\r\n",
        "submission.to_csv(f'.submission{subNumber}.csv', index=False)\r\n",
        "subNumber += 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "XyAMgFA7ynnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "You're trying to achieve a minimum of 80% Accuracy on your model."
      ],
      "metadata": {
        "id": "wItHuwrJynnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Semantic Indexing (Learn)\n",
        "<a id=\"p2\"></a>"
      ],
      "metadata": {
        "id": "72yYHOwlynnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Follow Along\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores i.e., `lsi__svd__n_components`\n",
        "4. Make a submission to Kaggle \n"
      ],
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "8PLDgih8ynnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Pipeline Components"
      ],
      "metadata": {
        "id": "grhmgVvRynnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "svd = TruncatedSVD(n_components=2, # number of topics to generate (also the size of the new feature space)\r\n",
        "                   algorithm='randomized',\r\n",
        "                   n_iter=10)\r\n",
        "\r\n",
        "vect = TfidfVectorizer(stop_words=\"english\", tokenizer=None)\r\n",
        "\r\n",
        "lsi = Pipeline([(\"vect\", vect), # creating our term-doc matrix\r\n",
        "                (\"svd\", svd)]) # apply svd to our term-doc matrix \r\n",
        "\r\n",
        "clf = XGBClassifier()\r\n",
        "\r\n",
        "pipe = Pipeline([('lsi', lsi), ('clf', clf)])"
      ],
      "outputs": [],
      "metadata": {
        "id": "GfvhHmjJynnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Your Search Space\n",
        "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
      ],
      "metadata": {
        "id": "rjoGQezpynnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "parameters = {\r\n",
        "    'lsi__svd__n_components': [10,100,250],\r\n",
        "    'lsi__vect__max_df': (0.75, 1.0),\r\n",
        "    'clf__max_depth':(5,10,15,20)\r\n",
        "}\r\n",
        "\r\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=5, n_jobs=4, verbose=1)\r\n",
        "grid_search.fit(X, y)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\nigel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
            "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01:06:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('lsi',\n",
              "                                        Pipeline(steps=[('vect',\n",
              "                                                         TfidfVectorizer(stop_words='english')),\n",
              "                                                        ('svd',\n",
              "                                                         TruncatedSVD(n_iter=10))])),\n",
              "                                       ('clf',\n",
              "                                        XGBClassifier(base_score=None,\n",
              "                                                      booster=None,\n",
              "                                                      colsample_bylevel=None,\n",
              "                                                      colsample_bynode=None,\n",
              "                                                      colsample_bytree=None,\n",
              "                                                      gamma=None, gpu_id=None,\n",
              "                                                      importance_type='gain',\n",
              "                                                      interaction_constraints=None,\n",
              "                                                      learning_...\n",
              "                                                      monotone_constraints=None,\n",
              "                                                      n_estimators=100,\n",
              "                                                      n_jobs=None,\n",
              "                                                      num_parallel_tree=None,\n",
              "                                                      random_state=None,\n",
              "                                                      reg_alpha=None,\n",
              "                                                      reg_lambda=None,\n",
              "                                                      scale_pos_weight=None,\n",
              "                                                      subsample=None,\n",
              "                                                      tree_method=None,\n",
              "                                                      validate_parameters=None,\n",
              "                                                      verbosity=None))]),\n",
              "             n_jobs=4,\n",
              "             param_grid={'clf__max_depth': (5, 10, 15, 20),\n",
              "                         'lsi__svd__n_components': [10, 100, 250],\n",
              "                         'lsi__vect__max_df': (0.75, 1.0)},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "metadata": {
        "id": "Ql1JBSD-ynnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a Submission File"
      ],
      "metadata": {
        "id": "jRqe2TARynnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "grid_search.best_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9176299261405644"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "print(grid_search.best_params_)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clf__max_depth': 5, 'lsi__svd__n_components': 100, 'lsi__vect__max_df': 0.75}\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Predictions on test sample\r\n",
        "pred = grid_search.predict(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "pyctLRoNynnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "submission = pd.DataFrame({'id': submission_test['id'], 'category':pred})\r\n",
        "submission['category'] = submission['category'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "J1NpGfmRynnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "# Make Sure the Category is an Integer\r\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>955</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3532</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1390</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1024</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  category\n",
              "0   955         2\n",
              "1  3532         2\n",
              "2  1390         1\n",
              "3  1024         1\n",
              "4  1902         1"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "metadata": {
        "id": "KPUfsiw4ynnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "# Save your Submission File\r\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\r\n",
        "\r\n",
        "submission.to_csv(f'.submission{subNumber}.csv', index=False)\r\n",
        "subNumber += 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "4Wg0gFAZynnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
      ],
      "metadata": {
        "id": "ztKBHR7Fynnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings with Spacy (Learn)\n",
        "<a id=\"p3\"></a>"
      ],
      "metadata": {
        "id": "g72I8pUFynnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Follow Along"
      ],
      "metadata": {
        "id": "bH074Cmrynnx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "# Apply to your Dataset\r\n",
        "\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "from scipy.stats import randint\r\n",
        "\r\n",
        "param_dist = {\r\n",
        "    \r\n",
        "    'max_depth' : randint(3,10),\r\n",
        "    'min_samples_leaf': randint(2,15)\r\n",
        "}"
      ],
      "outputs": [],
      "metadata": {
        "id": "YrW0sDHUynny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "# Continue Word Embedding Work Here\r\n",
        "nlp = spacy.load(\"en_core_web_md\")\r\n",
        "\r\n",
        "def get_word_vectors(text):\r\n",
        "    \"\"\"\r\n",
        "    This serves as both our tokenizer and vectorizer. \r\n",
        "    Returns a list of word vectors, i.e. our doc-term matrix\r\n",
        "    \"\"\"\r\n",
        "    return [nlp(doc).vector for doc in text]\r\n",
        "\r\n",
        "X_train_emb = get_word_vectors(train['description'])\r\n",
        "X_test_emb = get_word_vectors(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "rFukF5laynny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "rfc = RandomForestClassifier(oob_score=True)\r\n",
        "\r\n",
        "rfc.fit(X_train_emb, y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(oob_score=True)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "print('Training Accuracy: ', rfc.score(X_train_emb, y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  1.0\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "rfc.oob_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7269914926527455"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a Submission File"
      ],
      "metadata": {
        "id": "BMRIyedTynny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Predictions on test sample\r\n",
        "pred = ...predict(test['description'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "KFxKFNI3ynny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\r\n",
        "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
      ],
      "outputs": [],
      "metadata": {
        "id": "eP8EJiFOynnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Make Sure the Category is an Integer\r\n",
        "submission.head()"
      ],
      "outputs": [],
      "metadata": {
        "id": "aCYGwKHNynnz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Save your Submission File\r\n",
        "# Best to Use an Integer or Timestamp for different versions of your model\r\n",
        "\r\n",
        "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\r\n",
        "subNumber += 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "n4inG1uVynnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge\n",
        "\n",
        "What you should be doing now:\n",
        "1. Join the Kaggle Competition\n",
        "2. Download the data\n",
        "3. Train a model & try: \n",
        "    - Creating a Text Extraction & Classification Pipeline\n",
        "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
        "    - Add some Latent Semantic Indexing (LSI) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores i.e., `lsi__svd__n_components`\n",
        "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
        "4. Submit to Kaggle "
      ],
      "metadata": {
        "id": "tuGrfMlpynnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post Lecture Assignment\n",
        "<a id=\"p4\"></a>\n",
        "\n",
        "Your primary assignment this afternoon is to achieve a minimum of 80% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
        "\n",
        "1. Research \"Sentiment Analysis.\" Provide answers in markdown to the following questions: \n",
        "    - What is \"Sentiment Analysis?\" \n",
        "    - Is Document Classification different than \"Sentiment Analysis?\" Provide evidence for your response\n",
        "    - How do you create labeled sentiment data? Are those labels sentiment?\n",
        "    - What are common applications of sentiment analysis?\n",
        "2. Research why word embeddings worked better for the lecture notebook than for the whiskey competition.\n",
        "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest.\n",
        "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
      ],
      "metadata": {
        "id": "Rwl1YEeCynnz"
      }
    }
  ]
}