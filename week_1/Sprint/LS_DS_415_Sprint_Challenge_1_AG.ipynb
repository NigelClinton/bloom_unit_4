{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "Successfully complete all these objectives to earn full credit. \n",
    "\n",
    "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
    "\n",
    "Each unit test that you pass is 1 point. \n",
    "\n",
    "There are 5 total possible points in this sprint challenge. \n",
    "\n",
    "\n",
    "There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
    "\n",
    "____\n",
    "\n",
    "# Before you submit your notebook you must first\n",
    "\n",
    "1) Restart your notebook's Kernel\n",
    "\n",
    "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
    "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
    "\n",
    "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section). \n",
    "____"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### Import Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "# Load reviews from URL\r\n",
    "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\r\n",
    "\r\n",
    "# Import data into a DataFrame named df\r\n",
    "# YOUR CODE HERE\r\n",
    "df = pd.read_json(data_url, lines = True)"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
     "grade": false,
     "grade_id": "cell-395851cd95d17235",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1h3ysSuSazvXc1aeLiiOew</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-07 10:57:15</td>\n",
       "      <td>1</td>\n",
       "      <td>kAYnguBAJ2Ovzz5s49fMcQ</td>\n",
       "      <td>1</td>\n",
       "      <td>My family and I were hungry and this Subway is...</td>\n",
       "      <td>1</td>\n",
       "      <td>QFYqAk8n5Z1O3t7zwjA7Hg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Rwahe1zbFpw6VIjb5ngZeg</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-18 15:52:52</td>\n",
       "      <td>0</td>\n",
       "      <td>5Huai3nJAaeN8X0vCXqOew</td>\n",
       "      <td>3</td>\n",
       "      <td>My wife and I came here with a a couple of fri...</td>\n",
       "      <td>0</td>\n",
       "      <td>X7jQ-4788irfe5ABZNvYcA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8itGZAOBMiTbHKOwLuh4_Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-26 02:53:21</td>\n",
       "      <td>0</td>\n",
       "      <td>wmRCto8yNnmMCNc_nfL5Dg</td>\n",
       "      <td>2</td>\n",
       "      <td>The food was just OK and not anything to brag ...</td>\n",
       "      <td>0</td>\n",
       "      <td>_pi5J_1CIQWceLhTJkx_yA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>A5Rkh7UymKm0_Rxm9K2PJw</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-23 23:36:07</td>\n",
       "      <td>0</td>\n",
       "      <td>zlIU9GEI3MP5LXBpEM5qsw</td>\n",
       "      <td>4</td>\n",
       "      <td>Today's visit is great!! Love and enjoy Town S...</td>\n",
       "      <td>0</td>\n",
       "      <td>PP1K311ZKbpDgTjwic3u5Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>xtYiHTmunjfCN2sUaQxBjA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-02 23:37:51</td>\n",
       "      <td>0</td>\n",
       "      <td>_656ilBKoc-ZjjA5dRRoyw</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the absolute worst place I have ever s...</td>\n",
       "      <td>0</td>\n",
       "      <td>Y1tHSar3k-_clZVCM7JBZQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  cool                date  funny  \\\n",
       "0     nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1     eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2     6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3     k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4     6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "...                      ...   ...                 ...    ...   \n",
       "9995  1h3ysSuSazvXc1aeLiiOew     0 2017-10-07 10:57:15      1   \n",
       "9996  Rwahe1zbFpw6VIjb5ngZeg     0 2014-01-18 15:52:52      0   \n",
       "9997  8itGZAOBMiTbHKOwLuh4_Q     0 2018-08-26 02:53:21      0   \n",
       "9998  A5Rkh7UymKm0_Rxm9K2PJw     0 2018-04-23 23:36:07      0   \n",
       "9999  xtYiHTmunjfCN2sUaQxBjA     0 2016-06-02 23:37:51      0   \n",
       "\n",
       "                   review_id  stars  \\\n",
       "0     eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1     DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2     DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3     LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4     zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "...                      ...    ...   \n",
       "9995  kAYnguBAJ2Ovzz5s49fMcQ      1   \n",
       "9996  5Huai3nJAaeN8X0vCXqOew      3   \n",
       "9997  wmRCto8yNnmMCNc_nfL5Dg      2   \n",
       "9998  zlIU9GEI3MP5LXBpEM5qsw      4   \n",
       "9999  _656ilBKoc-ZjjA5dRRoyw      1   \n",
       "\n",
       "                                                   text  useful  \\\n",
       "0     BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1     Came here for lunch Togo. Service was quick. S...       0   \n",
       "2     I've been to Vegas dozens of times and had nev...       2   \n",
       "3     We went here on a night where they closed off ...       5   \n",
       "4     3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "...                                                 ...     ...   \n",
       "9995  My family and I were hungry and this Subway is...       1   \n",
       "9996  My wife and I came here with a a couple of fri...       0   \n",
       "9997  The food was just OK and not anything to brag ...       0   \n",
       "9998  Today's visit is great!! Love and enjoy Town S...       0   \n",
       "9999  This is the absolute worst place I have ever s...       0   \n",
       "\n",
       "                     user_id  \n",
       "0     n1LM36qNg4rqGXIcvVXv8w  \n",
       "1     5CgjjDAic2-FAvCtiHpytA  \n",
       "2     BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3     cZZnBqh4gAEy4CdNvJailQ  \n",
       "4     n9QO4ClYAS7h9fpQwa5bhA  \n",
       "...                      ...  \n",
       "9995  QFYqAk8n5Z1O3t7zwjA7Hg  \n",
       "9996  X7jQ-4788irfe5ABZNvYcA  \n",
       "9997  _pi5J_1CIQWceLhTJkx_yA  \n",
       "9998  PP1K311ZKbpDgTjwic3u5Q  \n",
       "9999  Y1tHSar3k-_clZVCM7JBZQ  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Visible Testing\r\n",
    "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\r\n",
    "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "356579363f311da83f4ef7abaf3c9212",
     "grade": true,
     "grade_id": "cell-cb5006475e42b8f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\r\n",
    "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\r\n",
    "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\r\n",
    "import spacy\r\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def tokenize(text):\r\n",
    "    \"\"\"\r\n",
    "    Takes text and returns a list of tokens in the form of lemmas.\r\n",
    "    This will not include puncuation, or stop words.\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    doc = nlp(text)\r\n",
    "    \r\n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]\r\n",
    "\r\n",
    "df[\"lemmas\"] = df['text'].apply(tokenize)"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4837ed2a1cc13057ba40203859d46ff6",
     "grade": false,
     "grade_id": "cell-3d570d5a1cd6cb64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "df['lemmas']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       [beware, fake, fake, fake, small, business, Lo...\n",
       "1       [come, lunch, Togo, Service, quick, staff, fri...\n",
       "2       [Vegas, dozen, time, step, foot, Circus, Circu...\n",
       "3       [go, night, close, street, party, good, actual...\n",
       "4       [3.5, 4, star, , bad, price, $, 12.99, lunch, ...\n",
       "                              ...                        \n",
       "9995    [family, hungry, Subway, open, 24, hour, guy, ...\n",
       "9996    [wife, come, couple, friend, sever, excited, p...\n",
       "9997    [food, ok, brag, food, hot, item, tasty, horri...\n",
       "9998    [today, visit, great, love, enjoy, Town, Squar...\n",
       "9999    [absolute, bad, place, stay, 43, year, life, ,...\n",
       "Name: lemmas, Length: 10000, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "'''Testing'''\r\n",
    "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2181ca9d36070260b1f75dcfd9e58965",
     "grade": true,
     "grade_id": "cell-02da164f6fbe730a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
    "2. Write a fake review and query for the 10 most similar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, use `NearestNeighbors` model for this. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "%%time\r\n",
    "# Create a vector representation of the reviews \r\n",
    "# Name that doc-term matrix \"dtm\"\r\n",
    "\r\n",
    "# YOUR CODE HERE\r\n",
    "\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "# tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\r\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2),\r\n",
    "                        max_df=.97,\r\n",
    "                        min_df=.02,\r\n",
    "                        tokenizer=tokenize)\r\n",
    "                        \r\n",
    "dtm = tfidf.fit_transform(df['new'][0])\r\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\r\n",
    "dtm.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 248 ms\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>fake</th>\n",
       "      <th>leave</th>\n",
       "      <th>message</th>\n",
       "      <th>number</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business  fake  leave  message  number  phone\n",
       "0       0.0   0.0    0.0      0.0     0.0    0.0\n",
       "1       0.0   1.0    0.0      0.0     0.0    0.0\n",
       "2       0.0   1.0    0.0      0.0     0.0    0.0\n",
       "3       0.0   1.0    0.0      0.0     0.0    0.0\n",
       "4       0.0   0.0    0.0      0.0     0.0    0.0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d70a0a1a96cf8406c60b17e50b255a1a",
     "grade": false,
     "grade_id": "cell-0e96491cb529202c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Create and fit a NearestNeighbors model named \"nn\"\r\n",
    "from sklearn.neighbors import NearestNeighbors\r\n",
    "\r\n",
    "# YOUR CODE HERE\r\n",
    "nn = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\r\n",
    "nn.fit(dtm)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', n_neighbors=10)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
     "grade": false,
     "grade_id": "cell-3d5bc610a8ec6b24",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "'''Testing.'''\r\n",
    "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\r\n",
    "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
     "grade": true,
     "grade_id": "cell-c43704dcff67e99b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a fake review and find the 10 most similar reviews\r\n",
    "\r\n",
    "# YOUR CODE HERE\r\n"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
     "grade": false,
     "grade_id": "cell-496203e8746296ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
    "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
    "    - Use that Pipeline to predict a star rating for your fake review from Part 2. \n",
    "\n",
    "\n",
    "\n",
    "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
    "    - Include 2 possible values for each parameter\n",
    "    - **Use `n_jobs` = 1** \n",
    "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
    "    \n",
    "    \n",
    "3. Train the entire pipeline with a GridSearch\n",
    "    - Name your GridSearch object as `gs`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "# Name the gridsearch instance \"gs\"\r\n",
    "\r\n",
    "# YOUR CODE HERE\r\n",
    "target = 'category'\r\n",
    "\r\n",
    "y, X = train[target], train.drop(columns=target)\r\n",
    "\r\n",
    "X = [list(v)[0] for v in X.values]\r\n",
    "\r\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", tokenizer=None) # data transformer\r\n",
    "rfc = RandomForestClassifier(random_state=42) # estimator\r\n",
    "pipe = Pipeline([(\"vect\", tfidf), # data transformer\r\n",
    "                 (\"clf\", rfc)])   # classifier \r\n",
    "parameters = {\r\n",
    "    'vect__max_df': (0.75, 1.0),\r\n",
    "    'clf__max_depth':(5,10,15,20)\r\n",
    "}\r\n",
    "grid_search = GridSearchCV(pipe,parameters, n_jobs=1)\r\n",
    "grid_search.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
     "grade": false,
     "grade_id": "cell-e2beb0252d274bba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visible Testing\r\n",
    "prediction = gs.predict([\"I wish dogs knew how to speak English.\"])[0]\r\n",
    "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9e2378efb868f104a4eb39e4f25563c",
     "grade": true,
     "grade_id": "cell-d07134c6fe5d056e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 4: Topic Modeling\r\n",
    "\r\n",
    "Let's find out what those yelp reviews are saying! :D\r\n",
    "\r\n",
    "1. Estimate a LDA topic model of the review text\r\n",
    "    - Set num_topics to `5`\r\n",
    "    - Name your LDA model `lda`\r\n",
    "2. Create 1-2 visualizations of the results\r\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \r\n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\r\n",
    "\r\n",
    "When you instantiate your LDA model, it should look like this: \r\n",
    "\r\n",
    "```python\r\n",
    "lda = LdaModel(corpus=corpus,\r\n",
    "               id2word=id2word,\r\n",
    "               random_state=723812,\r\n",
    "               num_topics = num_topics,\r\n",
    "               passes=1\r\n",
    "              )\r\n",
    "\r\n",
    "```\r\n",
    "\r\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Note about  pyLDAvis\n",
    "\n",
    "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
    "\n",
    "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
    "\n",
    "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "from gensim import corpora\r\n",
    "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA \r\n",
    "from gensim.models.ldamodel import LdaModel\r\n",
    "import gensim\r\n",
    "import re\r\n",
    "import pyLDAvis\r\n",
    "from pandarallel import pandarallel\r\n",
    "# we must initalize pandarallel before we can use it\r\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=10)\r\n",
    "# so that the progress bars will work\r\n",
    "from pandarallel.utils import progress_bars\r\n",
    "progress_bars.is_notebook_lab = lambda : True"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Estimate a LDA topic model of the review tex"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clean_text(text):\r\n",
    "    \"\"\"\r\n",
    "    Accepts a single text document and performs several regex substitutions in order to clean the document. \r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    text: string or object \r\n",
    "    \r\n",
    "    Returns\r\n",
    "    -------\r\n",
    "    text: string or object\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # order of operations - apply the expression from top to bottom\r\n",
    "    email_regex = r\"From: \\S*@\\S*\\s?\"\r\n",
    "    non_alpha = '[^a-zA-Z]'\r\n",
    "    multi_white_spaces = \"[ ]{2,}\"\r\n",
    "    \r\n",
    "    text = re.sub(email_regex, \"\", text)\r\n",
    "    text = re.sub(non_alpha, ' ', text)\r\n",
    "    text = re.sub(multi_white_spaces, \" \", text)\r\n",
    "    \r\n",
    "    # apply case normalization \r\n",
    "    return text.lower().lstrip().rstrip()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "df[\"clean_data\"] = df[\"text\"].apply(clean_text)\r\n",
    "df['lemmas'] = df['clean_data'].parallel_map(lambda x: [token.lemma_ for token in nlp(x) if (token.is_stop != True) and (token.is_punct != True)])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SystemError",
     "evalue": "Python version should be 3.{5, 6, 7}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9288/3052045981.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"clean_data\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lemmas'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_punct\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandarallel\\pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0mqueue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         workers_args, chunk_lengths, input_files, output_files = get_workers_args(\n\u001b[0m\u001b[0;32m    427\u001b[0m             \u001b[0muse_memory_fs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mnb_requested_workers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandarallel\\pandarallel.py\u001b[0m in \u001b[0;36mget_workers_args\u001b[1;34m(use_memory_fs, nb_workers, progress_bar, chunks, worker_meta_args, queue, func, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         workers_args, chunk_lengths = zip(\n\u001b[1;32m--> 306\u001b[1;33m             *[\n\u001b[0m\u001b[0;32m    307\u001b[0m                 (\n\u001b[0;32m    308\u001b[0m                     (\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandarallel\\pandarallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    313\u001b[0m                         \u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                         dill.dumps(\n\u001b[1;32m--> 315\u001b[1;33m                             progress_wrapper(\n\u001b[0m\u001b[0;32m    316\u001b[0m                                 \u001b[0mprogress_bar\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPROGRESS_IN_FUNC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m                                 \u001b[0mqueue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandarallel\\pandarallel.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             wrapped_func = inline(\n\u001b[0m\u001b[0;32m    201\u001b[0m                 \u001b[0mprogress_pre_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandarallel\\utils\\inliner.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mpython_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpython_version\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajor\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpython_version\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminor\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Python version should be 3.{5, 6, 7}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: Python version should be 3.{5, 6, 7}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\r\n",
    "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\r\n",
    "\r\n",
    "# don't change this value \r\n",
    "num_topics = 5\r\n",
    "\r\n",
    "# use tokenize function you created earlier to create tokens \r\n",
    "\r\n",
    "# create a id2word object (hint: use corpora.Dictionary)\r\n",
    "\r\n",
    "# create a corpus object (hint: id2word.doc2bow)\r\n",
    "\r\n",
    "# instantiate an lda model\r\n",
    "\r\n",
    "# YOUR CODE HERE\r\n",
    "def filter_lemmas(lemmas):\r\n",
    "    \"\"\"\r\n",
    "    Filter out any lemmas that are 2 characters or smaller\r\n",
    "    \"\"\"\r\n",
    "    return [lemma for lemma in lemmas if len(lemma) > 2]\r\n",
    "\r\n",
    "df[\"filtered_lemmas\"] = df[\"lemmas\"].parallel_map(filter_lemmas)\r\n",
    "\r\n",
    "df['lemmas'] = df[\"filtered_lemmas\"]\r\n",
    "\r\n",
    "id2word = corpora.Dictionary(df['lemmas'])\r\n",
    "\r\n",
    "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'prepare_worker.<locals>.closure.<locals>.wrapper'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9288/1270783181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlemma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"filtered_lemmas\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lemmas\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_lemmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lemmas'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"filtered_lemmas\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandarallel\\pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             pool = Pool(\n\u001b[0m\u001b[0;32m    442\u001b[0m                 \u001b[0mnb_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworker_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprepare_worker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_memory_fs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mPool\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;34m'''Returns a process pool object'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         return Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0m\u001b[0;32m    120\u001b[0m                     context=self.get_context())\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repopulate_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         return self._repopulate_pool_static(self._ctx, self.Process,\n\u001b[0m\u001b[0;32m    304\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inqueue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m_repopulate_pool_static\u001b[1;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Process'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PoolWorker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'added worker'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'prepare_worker.<locals>.closure.<locals>.wrapper'"
     ]
    }
   ],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9514841e71735eaa255bccc53b257896",
     "grade": false,
     "grade_id": "cell-66331a185ff52f15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visible Testing\r\n",
    "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
     "grade": true,
     "grade_id": "cell-5a3c181311134fa9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Create 1-2 visualizations of the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Use pyLDAvis (or a ploting tool of your choice) to visualize your results \r\n",
    "\r\n",
    "# YOUR CODE HERE\r\n",
    "raise NotImplementedError()"
   ],
   "outputs": [],
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "189591ed7b9e6e6146d59761fb418268",
     "grade": false,
     "grade_id": "cell-9b043e992fbd218c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model"
   ],
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f44a26c754500ff0bf585296075bf754",
     "grade": false,
     "grade_id": "cell-bf9e63d9645bba84",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   }
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "u4-s1-nlp"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "toc-autonumbering": false,
  "interpreter": {
   "hash": "b56204e04fac71cbe4e15d7b3dab17d89d2f24d87d00adcaa585640e5d78c50d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}